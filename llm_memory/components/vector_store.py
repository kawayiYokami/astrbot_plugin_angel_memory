"""
å‘é‡å­˜å‚¨ç»„ä»¶ã€‚

å°è£…æ‰€æœ‰ä¸ChromaDBå‘é‡æ•°æ®åº“å’ŒåµŒå…¥æ¨¡å‹çš„äº¤äº’ã€‚
"""

import chromadb
from sentence_transformers import SentenceTransformer
from typing import List, Optional, Tuple
import traceback

# å¯¼å…¥æ—¥å¿—è®°å½•å™¨
from astrbot.api import logger
from ..models.data_models import BaseMemory
from ..config.system_config import system_config
from .bm25_retriever import BM25Retriever

class VectorStore:
    """
    å‘é‡å­˜å‚¨ç±»ã€‚

    è´Ÿè´£è®°å¿†çš„å‘é‡åŒ–å’Œå­˜å‚¨ï¼Œä½¿ç”¨ChromaDBä½œä¸ºåç«¯ã€‚
    å®ç°ä¸ºå•ä¾‹æ¨¡å¼ï¼Œç¡®ä¿å…¨å±€åªåŠ è½½ä¸€æ¬¡åµŒå…¥æ¨¡å‹ã€‚
    """

    def __init__(self, model_name: str = None, db_path: str = None):
        """
        åˆå§‹åŒ–å‘é‡å­˜å‚¨ã€‚æ¯æ¬¡è°ƒç”¨éƒ½ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„å®ä¾‹ã€‚
        ä¸å†ä½¿ç”¨å•ä¾‹æ¨¡å¼ã€‚

        Args:
            model_name: åµŒå…¥æ¨¡å‹åç§°ã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™ä»ç³»ç»Ÿé…ç½®ä¸­è·å–ã€‚
            db_path: æ•°æ®åº“å­˜å‚¨è·¯å¾„ã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™ä»ç³»ç»Ÿé…ç½®ä¸­è·å–ã€‚
        """
        self.logger = logger
        self.model_name = model_name or system_config.embedding_model
        self.db_path = db_path or str(system_config.get_database_path())

        # åŠ è½½åµŒå…¥æ¨¡å‹
        self.logger.info(f"æ­£åœ¨ä¸ºæ–°å®ä¾‹åŠ è½½åµŒå…¥æ¨¡å‹: {self.model_name}")
        try:
            self.embedding_model = SentenceTransformer(self.model_name)
            self.logger.info(f"æ¨¡å‹åŠ è½½å®Œæˆ: {self.model_name}")
        except Exception as e:
            self.logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

        # åˆ›å»ºChromaDBå®¢æˆ·ç«¯
        self.client = chromadb.PersistentClient(path=self.db_path)
        self.logger.info(f"å·²ä¸ºæ–°å®ä¾‹åˆ›å»ºChromaDBå®¢æˆ·ç«¯ï¼Œè·¯å¾„: {self.db_path}")

        # å®ä¾‹å˜é‡
        self.collections = {}

        # ChromaDBæ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œä¸éœ€è¦é¢å¤–çš„çº¿ç¨‹é”
        # ç§»é™¤äº† self._db_lock = threading.RLock()

        # BM25æ£€ç´¢å™¨ç»„ä»¶
        self.bm25_retriever: Optional[BM25Retriever] = None
        self.hybrid_search_enabled = True
        self.vector_weight = 0.7
        self.bm25_weight = 0.3

        # åˆå§‹åŒ–BM25æ£€ç´¢å™¨
        self._init_bm25_retriever()

    def _post_initialization_verification(self):
        """åˆå§‹åŒ–å®ŒæˆåéªŒè¯"""
        try:
            self.logger.info("å¼€å§‹åˆå§‹åŒ–åéªŒè¯...")

            # éªŒè¯æ¨¡å‹ç»´åº¦
            model_dimension = self.embedding_model.get_sentence_embedding_dimension()
            self.logger.info(f"éªŒè¯æ¨¡å‹ç»´åº¦: {model_dimension}")

            # éªŒè¯é»˜è®¤é›†åˆ
            if hasattr(self, 'collection') and self.collection:
                collection_name = self.collection.name
                self.logger.info(f"éªŒè¯é»˜è®¤é›†åˆ: {collection_name}")
                self._verify_collection_dimension(self.collection, model_dimension)

            # éªŒè¯æ‰€æœ‰å·²åˆ›å»ºçš„é›†åˆ
            for collection_name, collection in self.collections.items():
                self.logger.info(f"éªŒè¯é›†åˆ: {collection_name}")
                self._verify_collection_dimension(collection, model_dimension)

            self.logger.info("åˆå§‹åŒ–åéªŒè¯å®Œæˆ")

        except Exception as e:
            self.logger.error(f"åˆå§‹åŒ–åéªŒè¯å¤±è´¥: {e}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _verify_collection_dimension(self, collection, expected_dimension):
        """
        éªŒè¯é›†åˆç»´åº¦

        Args:
            collection: ChromaDBé›†åˆ
            expected_dimension: æœŸæœ›çš„ç»´åº¦
        """
        try:
            # å°è¯•ç”¨æœŸæœ›ç»´åº¦çš„å‘é‡æŸ¥è¯¢
            dummy_vector = [0.0] * expected_dimension
            collection.query(
                query_embeddings=[dummy_vector],
                n_results=1
            )
            self.logger.info(f"  âœ“ é›†åˆ {collection.name} ç»´åº¦æ­£ç¡® ({expected_dimension})")
        except Exception as e:
            if "dimension" in str(e).lower():
                self.logger.error(f"  âœ— é›†åˆ {collection.name} ç»´åº¦ä¸åŒ¹é…: {e}")
                # è®°å½•é›†åˆå½“å‰çš„è®°å½•æ•°
                count = collection.count()
                self.logger.info(f"  é›†åˆ {collection.name} å½“å‰è®°å½•æ•°: {count}")
            else:
                # å…¶ä»–é”™è¯¯ï¼Œå¯èƒ½æ˜¯ç©ºé›†åˆç­‰
                self.logger.info(f"  âœ“ é›†åˆ {collection.name} (æ–°åˆ›å»ºæˆ–ç©ºé›†åˆ)")

    def set_storage_path(self, new_path: str):
        """
        è®¾ç½®æ–°çš„å­˜å‚¨è·¯å¾„å¹¶é‡æ–°åˆå§‹åŒ–ChromaDBå®¢æˆ·ç«¯ã€‚

        æ³¨æ„ï¼šè¿™å°†åˆ›å»ºä¸€ä¸ªæ–°çš„ChromaDBå®¢æˆ·ç«¯ï¼Œä¹‹å‰çš„æ•°æ®ä»åœ¨åŸè·¯å¾„ä¸­ã€‚
        å¦‚æœéœ€è¦è¿ç§»æ•°æ®ï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶æ•°æ®åº“æ–‡ä»¶ã€‚

        Args:
            new_path: æ–°çš„å­˜å‚¨è·¯å¾„
        """
        try:
            # åˆ›å»ºæ–°çš„ChromaDBå®¢æˆ·ç«¯
            self.logger.info(f"æ­£åœ¨åˆ‡æ¢å­˜å‚¨è·¯å¾„åˆ°: {new_path}")
            new_client = chromadb.PersistentClient(path=new_path)

            # æ›´æ–°å…±äº«å®¢æˆ·ç«¯
            VectorStore._client = new_client
            self.client = new_client

            # é‡æ–°åˆ›å»ºé›†åˆ
            self.collection = self.client.get_or_create_collection(name=self.collection.name)

            self.logger.info(f"å­˜å‚¨è·¯å¾„å·²æˆåŠŸåˆ‡æ¢åˆ°: {new_path}")

        except Exception as e:
            self.logger.error(f"åˆ‡æ¢å­˜å‚¨è·¯å¾„å¤±è´¥: {e}")
            raise

    # ===== ç¬”è®°æœåŠ¡ä¸“ç”¨æ–¹æ³• =====

    def get_note_collection(self, collection_name: str = "notes_collection"):
        """
        è·å–ç¬”è®°ä¸“ç”¨é›†åˆ

        Args:
            collection_name: é›†åˆåç§°

        Returns:
            ChromaDBé›†åˆå¯¹è±¡
        """
        if collection_name not in self.collections:
            self.collections[collection_name] = self.get_or_create_collection_with_dimension_check(collection_name)
        return self.collections[collection_name]


    def remember(self, collection, memory: BaseMemory):
        """
        è®°ä½ä¸€æ¡æ–°è®°å¿†ã€‚

        Args:
            collection: ç›®æ ‡ ChromaDB é›†åˆã€‚
            memory: è¦è®°ä½çš„è®°å¿†å¯¹è±¡ï¼ˆä»»ä½• BaseMemory çš„å­ç±»ï¼‰
        """
        try:
            # è·å–ç”¨äºå‘é‡åŒ–çš„è¯­ä¹‰æ ¸å¿ƒæ–‡æœ¬
            semantic_core = memory.get_semantic_core()

            # è·å–è®°å¿†çš„å†…å®¹æ–‡æœ¬ï¼ˆç”¨äºæ–‡æ¡£å­˜å‚¨ï¼‰
            content_text = ""
            if hasattr(memory, 'content'):
                content_text = memory.content
            elif hasattr(memory, 'definition'):
                content_text = memory.definition
            elif hasattr(memory, 'procedure'):
                content_text = memory.procedure
            else:
                content_text = semantic_core  # å…œåº•æ–¹æ¡ˆ

            # ä½¿ç”¨é«˜çº§æŠ½è±¡æ–¹æ³•å­˜å‚¨è®°å¿†
            self.upsert_documents(
                collection=collection,
                ids=memory.id,
                embedding_texts=semantic_core,  # ç”¨äºå‘é‡åŒ–çš„è¯­ä¹‰æ ¸å¿ƒ
                documents=content_text,  # å®é™…å­˜å‚¨çš„å†…å®¹
                metadatas=memory.to_dict()
            )

            self.logger.debug(f"å‘é‡å†™å…¥æˆåŠŸ - è®°å¿†ID: {memory.id}, è¯­ä¹‰æ ¸å¿ƒ: {semantic_core[:100]}...")

            # é€æ˜æ›´æ–°BM25ç´¢å¼•
            if self._is_hybrid_search_enabled():
                collection_name = collection.name
                self.bm25_retriever.add_document(collection_name, memory.id, content_text)
                self.logger.debug(f"BM25ç´¢å¼•æ›´æ–°æˆåŠŸ - è®°å¿†ID: {memory.id}")

        except Exception:
            # å¼‚å¸¸ä¼šè¢«è£…é¥°å™¨è‡ªåŠ¨è®°å½•
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸

    def recall(self, collection, query: str, limit: int = 10, where_filter: Optional[dict] = None) -> List[BaseMemory]:
        """
        æ ¹æ®æŸ¥è¯¢å›å¿†ç›¸å…³è®°å¿†ï¼Œæ”¯æŒå¤æ‚çš„å…ƒæ•°æ®è¿‡æ»¤ã€‚

        Args:
            collection: ç›®æ ‡ ChromaDB é›†åˆã€‚
            query: æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²
            limit: è¿”å›ç»“æœçš„æœ€å¤§æ•°é‡
            where_filter: å¯é€‰çš„å…ƒæ•°æ®è¿‡æ»¤å™¨å­—å…¸ (e.g., {"memory_type": "EventMemory", "is_consolidated": False})

        Returns:
            ç›¸å…³çš„è®°å¿†å¯¹è±¡åˆ—è¡¨ï¼ˆBaseMemory çš„å­ç±»ï¼‰
        """
        try:
            # æ˜¾å¼ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_embedding = self.embed_single_document(query)

            # æ„å»ºæŸ¥è¯¢å‚æ•°
            query_params = {
                "query_embeddings": [query_embedding],  # ä½¿ç”¨æ˜¾å¼ç”Ÿæˆçš„å‘é‡
                "n_results": limit
            }

            # å¦‚æœæä¾›äº†è¿‡æ»¤å™¨ï¼Œåˆ™æ·»åŠ åˆ°æŸ¥è¯¢å‚æ•°
            if where_filter:
                if len(where_filter) == 1:
                    # å•ä¸ªæ¡ä»¶
                    query_params["where"] = where_filter
                else:
                    # å¤šä¸ªæ¡ä»¶ï¼Œä½¿ç”¨ $and æ“ä½œç¬¦
                    query_params["where"] = {"$and": [{k: v} for k, v in where_filter.items()]}

            # åœ¨ChromaDBä¸­è¿›è¡Œå‘é‡ç›¸ä¼¼åº¦æœç´¢
            results = collection.query(**query_params)

            # å°†ç»“æœè½¬æ¢ä¸ºè®°å¿†å¯¹è±¡
            vector_results = []
            if results and results['metadatas'] and len(results['metadatas']) > 0:
                for meta in results['metadatas'][0]:
                    if meta:  # ç¡®ä¿å…ƒæ•°æ®ä¸ä¸ºç©º
                        vector_results.append(BaseMemory.from_dict(meta))

            # æ··åˆæ£€ç´¢ï¼šç»“åˆBM25ç»“æœ
            if self._is_hybrid_search_enabled():
                collection_name = collection.name
                # å¦‚æœé›†åˆè¿˜æ²¡æœ‰åŒæ­¥åˆ°BM25ï¼Œå…ˆåŒæ­¥
                if self.bm25_retriever.get_document_count(collection_name) == 0:
                    self._sync_collection_to_bm25(collection_name, collection)

                # BM25æ£€ç´¢
                bm25_results = self.bm25_retriever.search(collection_name, query, limit)

                # èåˆç»“æœ
                final_results = self._merge_results(vector_results, bm25_results, collection)

                self.logger.debug(f"æ··åˆæ£€ç´¢å®Œæˆ - å‘é‡ç»“æœ: {len(vector_results)}, BM25ç»“æœ: {len(bm25_results)}, æœ€ç»ˆç»“æœ: {len(final_results)}")
            else:
                final_results = vector_results

        except Exception:
            # å¼‚å¸¸ä¼šè¢«è£…é¥°å™¨è‡ªåŠ¨è®°å½•
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸

        return final_results

    def update_memory(self, collection, memory_id: str, updates: dict):
        """
        æ›´æ–°è®°å¿†çš„å…ƒæ•°æ®ã€‚

        Args:
            collection: ç›®æ ‡ ChromaDB é›†åˆã€‚
            memory_id: è¦æ›´æ–°çš„è®°å¿†ID
            updates: è¦æ›´æ–°çš„å­—æ®µå­—å…¸ (e.g., {"is_consolidated": True, "strength": 5})
        """
        try:
            # è·å–å½“å‰è®°å¿†çš„å®Œæ•´ä¿¡æ¯
            current_data = collection.get(ids=[memory_id])
            if not current_data or not current_data['metadatas']:
                raise ValueError(f"Memory with id {memory_id} not found")

            current_meta = current_data['metadatas'][0]
            current_document = current_data['documents'][0] if current_data['documents'] else ""

            # ä»å…ƒæ•°æ®ä¸­é‡æ–°æ„é€ è¯­ä¹‰æ ¸å¿ƒç”¨äºå‘é‡åŒ–
            semantic_core = current_meta.get('judgment', '') + ' ' + current_meta.get('tags', '')

            # åº”ç”¨æ›´æ–°
            current_meta.update(updates)

            # ä½¿ç”¨é«˜çº§æŠ½è±¡æ–¹æ³•é‡æ–°å­˜å‚¨
            self.upsert_documents(
                collection=collection,
                ids=memory_id,
                embedding_texts=semantic_core,  # é‡æ–°ç”ŸæˆåµŒå…¥
                documents=current_document,
                metadatas=current_meta
            )

        except Exception as e:
            self.logger.error(f"æ›´æ–°è®°å¿† {memory_id} å¤±è´¥: {str(e)}")
            raise

    def delete_memories(self, collection, where_filter: dict, exclude_associations: bool = False):
        """
        æ ¹æ®æ¡ä»¶åˆ é™¤è®°å¿†ã€‚

        Args:
            collection: ç›®æ ‡ ChromaDB é›†åˆã€‚
            where_filter: åˆ é™¤æ¡ä»¶ (e.g., {"strength": {"$lt": 2}})
            exclude_associations: æ˜¯å¦æ’é™¤å…³è”è®°å¿†ä¸åˆ é™¤
        """
        try:
            # å¤„ç†å¤šä¸ªæ¡ä»¶çš„æŸ¥è¯¢
            if len(where_filter) > 1:
                # ä½¿ç”¨ $and æ“ä½œç¬¦å¤„ç†å¤šä¸ªæ¡ä»¶
                base_filter = {"$and": [{k: v} for k, v in where_filter.items()]}
            else:
                base_filter = where_filter

            # å¦‚æœéœ€è¦æ’é™¤å…³è”ï¼Œæ·»åŠ é¢å¤–çš„æ¡ä»¶
            if exclude_associations:
                if "$and" in base_filter:
                    base_filter["$and"].append({"memory_type": {"$ne": "Association"}})
                else:
                    base_filter = {"$and": [base_filter, {"memory_type": {"$ne": "Association"}}]}

            # è·å–ç¬¦åˆæ¡ä»¶çš„è®°å¿†ID
            results = collection.get(where=base_filter)
            ids_to_delete = results['ids']

            if ids_to_delete:
                collection.delete(ids=ids_to_delete)
                self.logger.info(f"Deleted {len(ids_to_delete)} memories with filter: {where_filter}")

        except Exception as e:
            self.logger.error(f"Failed to delete memories: {str(e)}")
            raise
    def clear_collection(self, collection):
        """æ¸…ç©ºæŒ‡å®šé›†åˆã€‚"""
        try:
            collection_name = collection.name
            self.client.delete_collection(collection_name)
            # é‡æ–°åˆ›å»ºé›†åˆï¼Œç¡®ä¿ embedding_function ç­‰å…ƒæ•°æ®è¢«ä¿ç•™
            self.get_or_create_collection_with_dimension_check(name=collection_name)
        except Exception as e:
            self.logger.error(f"æ¸…ç©ºæ‰€æœ‰è®°å¿†å¤±è´¥: {e}")
            raise

    def upsert_documents(
        self,
        collection,
        *,
        ids,
        embedding_texts,
        documents,
        metadatas=None
    ):
        """
        é«˜çº§ upsert æ–¹æ³•ï¼Œå®ƒæ¥å—ç”¨äºå‘é‡åŒ–çš„æ–‡æœ¬å’Œç”¨äºå­˜å‚¨çš„æ–‡æ¡£ä½œä¸ºä¸åŒçš„å‚æ•°ã€‚
        è¿™ä¸ªæ–¹æ³•æ˜¯å‘å‘é‡æ•°æ®åº“æ·»åŠ æˆ–æ›´æ–°å†…å®¹çš„ä¸»è¦æ¥å£ã€‚

        Args:
            collection: ç›®æ ‡ ChromaDB é›†åˆã€‚
            ids: æ–‡æ¡£IDæˆ–IDåˆ—è¡¨ã€‚
            embedding_texts: ç”¨äºç”Ÿæˆå‘é‡çš„æ–‡æœ¬æˆ–æ–‡æœ¬åˆ—è¡¨ã€‚
            documents: å®é™…å­˜å‚¨åœ¨æ•°æ®åº“ä¸­çš„æ–‡æ¡£å†…å®¹æˆ–åˆ—è¡¨ã€‚
            metadatas: ä¸æ–‡æ¡£å…³è”çš„å…ƒæ•°æ®æˆ–å…ƒæ•°æ®åˆ—è¡¨ã€‚
        """
        # ç»Ÿä¸€å¤„ç†è¾“å…¥ä¸ºåˆ—è¡¨
        ids_list = [ids] if isinstance(ids, str) else ids
        embedding_texts_list = [embedding_texts] if isinstance(embedding_texts, str) else embedding_texts
        documents_list = [documents] if isinstance(documents, str) else documents
        metadatas_list = [metadatas] if isinstance(metadatas, dict) else metadatas

        if not ids_list:
            return

        # 1. ä½¿ç”¨å†…éƒ¨æ–¹æ³•ä»æºæ–‡æœ¬ç”Ÿæˆ embeddings
        embeddings = self.embed_documents(embedding_texts_list)

        # 2. è°ƒç”¨åº•å±‚çš„ upsert
        upsert_params = {
            'ids': ids_list,
            'embeddings': embeddings,
            'documents': documents_list
        }

        if metadatas_list is not None:
            upsert_params['metadatas'] = metadatas_list

        collection.upsert(**upsert_params)

    def embed_documents(self, documents: List[str]) -> List[List[float]]:
        """
        ä½¿ç”¨åŠ è½½çš„ sentence-transformer æ¨¡å‹ä¸ºæ–‡æ¡£åˆ—è¡¨ç”Ÿæˆå‘é‡åµŒå…¥ã€‚

        Args:
            documents: éœ€è¦è¿›è¡Œå‘é‡åŒ–çš„æ–‡æ¡£å­—ç¬¦ä¸²åˆ—è¡¨ã€‚

        Returns:
            ä¸€ä¸ªç”±å‘é‡ï¼ˆæµ®ç‚¹æ•°åˆ—è¡¨ï¼‰ç»„æˆçš„åˆ—è¡¨ã€‚
        """
        if not documents:
            return []

        # æœ€ç»ˆä¿®å¤ï¼šå¼ºåˆ¶è¾“å‡ºä¸º numpy æ•°ç»„ï¼Œç„¶åè½¬æ¢ä¸º listã€‚è¿™æ˜¯æœ€å¯é çš„æ–¹å¼ã€‚
        embeddings_numpy = self.embedding_model.encode(documents, convert_to_numpy=True)

        # numpy æ•°ç»„æ€»æ˜¯æœ‰ .tolist() æ–¹æ³•
        embeddings = embeddings_numpy.tolist()

        return embeddings

    def embed_single_document(self, document: str) -> List[float]:
        """
        ä¸ºå•ä¸ªæ–‡æ¡£ç”Ÿæˆå‘é‡åµŒå…¥ã€‚
        """
        return self.embed_documents([document])[0]

    def clear_all(self):
        """æ¸…ç©ºæ‰€æœ‰è®°å¿†ã€‚"""
        try:
            collection_name = self.collection.name
            self.client.delete_collection(collection_name)
            self.collection = self.client.get_or_create_collection(name=collection_name)
        except Exception as e:
            self.logger.error(f"æ¸…ç©ºæ‰€æœ‰è®°å¿†å¤±è´¥: {e}")
            raise

    def _check_collection_dimension(self, collection, expected_dimension):
        """
        æ£€æŸ¥é›†åˆçš„ç»´åº¦æ˜¯å¦ä¸æ¨¡å‹åŒ¹é…

        Args:
            collection: ChromaDBé›†åˆ
            expected_dimension: æœŸæœ›çš„ç»´åº¦
        """
        try:
            # å°è¯•ç”¨æœŸæœ›ç»´åº¦çš„å‘é‡æŸ¥è¯¢
            dummy_vector = [0.0] * expected_dimension
            collection.query(
                query_embeddings=[dummy_vector],
                n_results=1
            )
            return True
        except Exception as e:
            error_msg = str(e)
            if "dimension" in error_msg.lower():
                # è§£æé”™è¯¯ä¿¡æ¯ä¸­çš„å®é™…ç»´åº¦
                actual_dimension = None
                expected_dimension_in_error = None

                # å°è¯•ä»é”™è¯¯ä¿¡æ¯ä¸­æå–ç»´åº¦ä¿¡æ¯
                import re
                dimension_pattern = r"dimension of (\d+), got (\d+)"
                match = re.search(dimension_pattern, error_msg.lower())
                if match:
                    expected_dimension_in_error = int(match.group(1))
                    actual_dimension = int(match.group(2))
                    self.logger.error(f"ğŸš¨ ç»´åº¦ç²¾ç¡®ä¸åŒ¹é…: é›†åˆæœŸæœ›{expected_dimension_in_error}ç»´ï¼Œæäº¤äº†{actual_dimension}ç»´")
                else:
                    # æ— æ³•è§£æç»´åº¦ä¿¡æ¯ï¼Œåªè®°å½•åŸå§‹é”™è¯¯
                    self.logger.warning(f"é›†åˆ {collection.name} ç»´åº¦ä¸åŒ¹é…: {e}")

                return False
            else:
                # å…¶ä»–é”™è¯¯ï¼Œå¯èƒ½æ˜¯ç©ºé›†åˆç­‰
                self.logger.info(f"é›†åˆ {collection.name} ç»´åº¦æ£€æŸ¥é‡åˆ°å…¶ä»–é”™è¯¯: {e}")
                return True

    def get_or_create_collection_with_dimension_check(self, name: str):
        """
        è·å–æˆ–åˆ›å»ºé›†åˆï¼Œå¹¶æ£€æŸ¥ç»´åº¦æ˜¯å¦åŒ¹é…

        Args:
            name: é›†åˆåç§°

        Returns:
            ChromaDBé›†åˆå¯¹è±¡
        """
        # è·å–é›†åˆå‰å…ˆè®°å½•è¯¦ç»†ä¿¡æ¯
        self.logger.info(f"æ­£åœ¨è·å–æˆ–åˆ›å»ºé›†åˆ: {name}")
        self.logger.info(f"å®¢æˆ·ç«¯ä¿¡æ¯: {self.client}")

        from chromadb.utils import embedding_functions
        embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=self.model_name)
        collection = self.client.get_or_create_collection(
            name=name,
            embedding_function=embedding_function
        )

        # è¾“å‡ºé›†åˆçš„è¯¦ç»†ä¿¡æ¯
        self.logger.info(f"é›†åˆä¿¡æ¯ - åç§°: {collection.name}, å…ƒæ•°æ®: {collection.metadata}")

        # è·å–æ¨¡å‹ç»´åº¦
        model_dimension = self.embedding_model.get_sentence_embedding_dimension()
        self.logger.info(f"æ¨¡å‹ç»´åº¦: {model_dimension}")

        # æ£€æŸ¥é›†åˆç»´åº¦
        if self._check_collection_dimension(collection, model_dimension):
            self.logger.info(f"é›†åˆ {name} ç»´åº¦åŒ¹é… ({model_dimension})")
        else:
            self.logger.error(f"é›†åˆ {name} ç»´åº¦ä¸åŒ¹é…ï¼æœŸæœ› {model_dimension} ç»´åº¦")
            # è®°å½•é›†åˆå½“å‰çš„è®°å½•æ•°
            try:
                count = collection.count()
                self.logger.info(f"é›†åˆ {name} å½“å‰è®°å½•æ•°: {count}")

                # å¦‚æœé›†åˆä¸ä¸ºç©ºï¼Œè¿™æ˜¯ä¸€ä¸ªä¸¥é‡é—®é¢˜
                if count > 0:
                    self.logger.error("è­¦å‘Šï¼šéç©ºé›†åˆç»´åº¦ä¸åŒ¹é…ï¼Œæ•°æ®å¯èƒ½ä¸ä¸€è‡´ï¼")
                else:
                    self.logger.info("ç©ºé›†åˆç»´åº¦ä¸åŒ¹é…ï¼Œå°†åœ¨é¦–æ¬¡æ’å…¥æ—¶è‡ªåŠ¨ä¿®å¤")
            except Exception as e:
                self.logger.error(f"è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")

        return collection

    # ===== BM25æ··åˆæ£€ç´¢é›†æˆæ–¹æ³• =====

    def _init_bm25_retriever(self) -> bool:
        """åˆå§‹åŒ–BM25æ£€ç´¢å™¨"""
        try:
            self.bm25_retriever = BM25Retriever(k1=1.2, b=0.75)
            if self.bm25_retriever.is_available():
                self.logger.info("BM25æ£€ç´¢å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ··åˆæ£€ç´¢å·²å¯ç”¨")
                return True
            else:
                self.logger.warning("rank_bm25åº“æœªå®‰è£…ï¼Œå°†ä»…ä½¿ç”¨å‘é‡æ£€ç´¢")
                self.hybrid_search_enabled = False
                self.bm25_retriever = None
                return False
        except Exception as e:
            self.logger.error(f"BM25æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.bm25_retriever = None
            return False

    def _is_hybrid_search_enabled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨æ··åˆæ£€ç´¢"""
        return (self.hybrid_search_enabled and
                self.bm25_retriever is not None and
                self.bm25_retriever.is_available() and
                (self.vector_weight > 0 and self.bm25_weight > 0))

    def _merge_results(self, vector_results: List[BaseMemory], bm25_results: List[Tuple[str, float]], collection) -> List[BaseMemory]:
        """èåˆå‘é‡æ£€ç´¢å’ŒBM25æ£€ç´¢ç»“æœ"""
        if not vector_results and not bm25_results:
            return []

        if not bm25_results or not self._is_hybrid_search_enabled():
            return vector_results

        if not vector_results:
            # åªæœ‰BM25ç»“æœï¼Œéœ€è¦æ ¹æ®doc_idæŸ¥æ‰¾BaseMemoryå¯¹è±¡
            return self._get_memories_by_ids(collection, [doc_id for doc_id, _ in bm25_results])

        # åˆ›å»ºæ–‡æ¡£IDåˆ°BaseMemoryå¯¹è±¡çš„æ˜ å°„
        vector_memories_map = {}
        for memory in vector_results:
            vector_memories_map[memory.id] = memory

        # æ ‡å‡†åŒ–åˆ†æ•°åˆ°[0,1]åŒºé—´
        vector_scores = {}
        if vector_results:
            # å‘é‡æ£€ç´¢ç»“æœæŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œåˆ†é…é€’å‡åˆ†æ•°
            for i, memory in enumerate(vector_results):
                vector_scores[memory.id] = 1.0 - (i * 0.1)  # ç®€å•çº¿æ€§é€’å‡

        bm25_scores = {}
        if bm25_results:
            max_score = max(score for _, score in bm25_results) if bm25_results else 1.0
            for doc_id, score in bm25_results:
                if max_score > 0:
                    bm25_scores[doc_id] = score / max_score
                else:
                    bm25_scores[doc_id] = 0.0

        # åˆå¹¶åˆ†æ•°
        combined_scores = {}
        for doc_id, score in vector_scores.items():
            combined_scores[doc_id] = self.vector_weight * score

        for doc_id, score in bm25_scores.items():
            combined_scores[doc_id] = combined_scores.get(doc_id, 0) + self.bm25_weight * score

        # æ·»åŠ çº¯å‘é‡æ£€ç´¢ä¸­å­˜åœ¨ä½†BM25ä¸­æ²¡æœ‰çš„ç»“æœ
        for doc_id in vector_memories_map:
            if doc_id not in combined_scores:
                combined_scores[doc_id] = self.vector_weight * 0.5  # ç»™äºˆä¸­ç­‰åˆ†æ•°

        # æŒ‰åˆå¹¶åˆ†æ•°æ’åº
        sorted_results = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)

        # è¿”å›æ’åºåçš„BaseMemoryå¯¹è±¡
        final_memories = []
        memory_ids_to_get = [doc_id for doc_id, _ in sorted_results[:len(vector_results)]]

        # éœ€è¦ä»æ•°æ®åº“å®Œæ•´è·å–è¿™äº›è®°å¿†ï¼ˆå› ä¸ºBM25ç»“æœä¸­æ²¡æœ‰å®Œæ•´çš„è®°å¿†å¯¹è±¡ï¼‰
        if len(memory_ids_to_get) > len(vector_memories_map):
            additional_memories = self._get_memories_by_ids(collection,
                [doc_id for doc_id in memory_ids_to_get if doc_id not in vector_memories_map])
            # åˆå¹¶ç»“æœ
            all_memories_map = vector_memories_map.copy()
            for memory in additional_memories:
                all_memories_map[memory.id] = memory
        else:
            all_memories_map = vector_memories_map

        for doc_id, _ in sorted_results[:len(vector_results)]:
            if doc_id in all_memories_map:
                final_memories.append(all_memories_map[doc_id])

        return final_memories

    def _get_memories_by_ids(self, collection, doc_ids: List[str]) -> List[BaseMemory]:
        """æ ¹æ®æ–‡æ¡£IDåˆ—è¡¨è·å–è®°å¿†å¯¹è±¡"""
        try:
            if not doc_ids:
                return []

            # ä½¿ç”¨ChromaDBçš„getæ–¹æ³•è·å–æŒ‡å®šIDçš„æ–‡æ¡£
            retrieved_docs = collection.get(ids=doc_ids)
            if not retrieved_docs or not retrieved_docs['metadatas']:
                return []

            memories = []
            for meta in retrieved_docs['metadatas']:
                if meta:
                    memories.append(BaseMemory.from_dict(meta))

            return memories

        except Exception as e:
            self.logger.error(f"æ ¹æ®IDè·å–è®°å¿†å¤±è´¥: {e}")
            return []

    def _sync_collection_to_bm25(self, collection_name: str, collection) -> bool:
        """åŒæ­¥ChromaDBé›†åˆæ•°æ®åˆ°BM25ç´¢å¼•"""
        if not self._is_hybrid_search_enabled():
            return True

        try:
            # è·å–é›†åˆä¸­çš„æ‰€æœ‰æ•°æ®
            all_data = collection.get()
            if not all_data or not all_data['documents']:
                return True

            # å‡†å¤‡æ•°æ®
            doc_ids = all_data['ids']
            texts = all_data['documents']

            # è¿‡æ»¤ç©ºæ–‡æ¡£
            valid_pairs = [(doc_id, text) for doc_id, text in zip(doc_ids, texts) if text]
            if not valid_pairs:
                return True

            valid_ids, valid_texts = zip(*valid_pairs)

            # æ‰¹é‡æ·»åŠ åˆ°BM25
            return self.bm25_retriever.add_documents(collection_name, list(valid_ids), list(valid_texts))

        except Exception as e:
            self.logger.error(f"åŒæ­¥é›†åˆåˆ°BM25å¤±è´¥ {collection_name}: {e}")
            return False

    # ===== æ··åˆæ£€ç´¢é…ç½®æ–¹æ³• =====

    def enable_hybrid_search(self, vector_weight: float = 0.7, bm25_weight: float = 0.3) -> bool:
        """
        å¯ç”¨æ··åˆæ£€ç´¢åŠŸèƒ½ã€‚

        Args:
            vector_weight: å‘é‡æ£€ç´¢æƒé‡ (0.0-1.0)
            bm25_weight: BM25æ£€ç´¢æƒé‡ (0.0-1.0)

        Returns:
            æ˜¯å¦æˆåŠŸå¯ç”¨
        """
        if not (0.0 <= vector_weight <= 1.0 and 0.0 <= bm25_weight <= 1.0):
            self.logger.error("æƒé‡å‚æ•°å¿…é¡»åœ¨0.0åˆ°1.0ä¹‹é—´")
            return False

        if self.bm25_retriever is None or not self.bm25_retriever.is_available():
            self.logger.warning("BM25ç»„ä»¶ä¸å¯ç”¨ï¼Œæ— æ³•å¯ç”¨æ··åˆæ£€ç´¢")
            return False

        # å½’ä¸€åŒ–æƒé‡
        total_weight = vector_weight + bm25_weight
        if total_weight > 0:
            self.vector_weight = vector_weight / total_weight
            self.bm25_weight = bm25_weight / total_weight

        self.hybrid_search_enabled = True
        self.logger.info(f"æ··åˆæ£€ç´¢å·²å¯ç”¨ - å‘é‡æƒé‡: {self.vector_weight:.2f}, BM25æƒé‡: {self.bm25_weight:.2f}")
        return True

    def disable_hybrid_search(self):
        """ç¦ç”¨æ··åˆæ£€ç´¢ï¼Œä»…ä½¿ç”¨å‘é‡æ£€ç´¢ã€‚"""
        self.hybrid_search_enabled = False
        self.logger.info("æ··åˆæ£€ç´¢å·²ç¦ç”¨ï¼Œå°†ä»…ä½¿ç”¨å‘é‡æ£€ç´¢")

    def set_hybrid_weights(self, vector_weight: float, bm25_weight: float) -> bool:
        """
        è®¾ç½®æ··åˆæ£€ç´¢æƒé‡ã€‚

        Args:
            vector_weight: å‘é‡æ£€ç´¢æƒé‡
            bm25_weight: BM25æ£€ç´¢æƒé‡

        Returns:
            æ˜¯å¦æˆåŠŸè®¾ç½®
        """
        if not (0.0 <= vector_weight <= 1.0 and 0.0 <= bm25_weight <= 1.0):
            self.logger.error("æƒé‡å‚æ•°å¿…é¡»åœ¨0.0åˆ°1.0ä¹‹é—´")
            return False

        # å½’ä¸€åŒ–æƒé‡
        total_weight = vector_weight + bm25_weight
        if total_weight > 0:
            self.vector_weight = vector_weight / total_weight
            self.bm25_weight = bm25_weight / total_weight
        else:
            self.logger.error("æƒé‡æ€»å’Œä¸èƒ½ä¸º0")
            return False

        self.logger.info(f"æ··åˆæ£€ç´¢æƒé‡å·²æ›´æ–° - å‘é‡æƒé‡: {self.vector_weight:.2f}, BM25æƒé‡: {self.bm25_weight:.2f}")
        return True

    def get_hybrid_search_status(self) -> dict:
        """
        è·å–æ··åˆæ£€ç´¢çŠ¶æ€ä¿¡æ¯ã€‚

        Returns:
            çŠ¶æ€ä¿¡æ¯å­—å…¸
        """
        return {
            'hybrid_search_enabled': self.hybrid_search_enabled,
            'bm25_available': self.bm25_retriever is not None and self.bm25_retriever.is_available(),
            'vector_weight': self.vector_weight,
            'bm25_weight': self.bm25_weight,
            'bm25_collections': len(self.bm25_retriever.get_collection_names()) if self.bm25_retriever else 0
        }

    def force_reload_bm25_index(self, collection_name: str, collection = None) -> bool:
        """
        å¼ºåˆ¶é‡æ–°åŠ è½½æŒ‡å®šé›†åˆçš„BM25ç´¢å¼•ã€‚

        Args:
            collection_name: é›†åˆåç§°
            collection: ChromaDBé›†åˆå¯¹è±¡ï¼ˆå¯é€‰ï¼‰

        Returns:
            æ˜¯å¦æˆåŠŸé‡æ–°åŠ è½½
        """
        if not self._is_hybrid_search_enabled():
            self.logger.warning("æ··åˆæ£€ç´¢æœªå¯ç”¨ï¼Œè·³è¿‡BM25ç´¢å¼•é‡æ–°åŠ è½½")
            return False

        try:
            if collection is None:
                collection = self.collections.get(collection_name)
                if collection is None:
                    collection = self.get_or_create_collection_with_dimension_check(collection_name)

            # æ¸…ç©ºç°æœ‰BM25ç´¢å¼•
            self.bm25_retriever.clear_collection(collection_name)

            # é‡æ–°åŒæ­¥
            return self._sync_collection_to_bm25(collection_name, collection)

        except Exception as e:
            self.logger.error(f"å¼ºåˆ¶é‡æ–°åŠ è½½BM25ç´¢å¼•å¤±è´¥ {collection_name}: {e}")
            return False

    