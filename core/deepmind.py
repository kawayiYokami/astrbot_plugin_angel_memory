"""
DeepMindæ½œæ„è¯†æ ¸å¿ƒæ¨¡å—

è¿™æ˜¯AIçš„æ½œæ„è¯†ç³»ç»Ÿï¼Œåœ¨åå°é»˜é»˜å¸®ä½ ç®¡ç†è®°å¿†ï¼š
- çœ‹åˆ°æ¶ˆæ¯æ—¶è‡ªåŠ¨å›å¿†ç›¸å…³å†…å®¹
- ç­›é€‰å‡ºæœ‰ç”¨çš„è®°å¿†å–‚ç»™ä¸»æ„è¯†
- å®šæœŸæ•´ç†è®°å¿†ï¼Œè®©é‡è¦å†…å®¹ä¸å®¹æ˜“å¿˜è®°
- å°±åƒäººç¡è§‰æ—¶æ•´ç†è®°å¿†ä¸€æ ·
"""

import time
import json
import threading
from typing import List, Dict, Any, Optional
from astrbot.api.event import AstrMessageEvent
from astrbot.api.provider import ProviderRequest

from ..llm_memory import CognitiveService
from ..llm_memory.utils.json_parser import JsonParser
from .session_memory import SessionMemoryManager
from .utils import SmallModelPromptBuilder, MemoryInjector, MemoryIDResolver
from .utils.feedback_queue import get_feedback_queue
from .utils.note_context_builder import NoteContextBuilder
from .utils.query_processor import get_query_processor
try:
    from astrbot.api import logger
except ImportError:
    import logging
    logger = logging.getLogger(__name__)


class DeepMind:
    """AIçš„æ½œæ„è¯†ç³»ç»Ÿ

    è¿™æ˜¯AIçš„æ½œæ„è¯†ï¼Œé…åˆä¸»æ„è¯†ï¼ˆLLMï¼‰å·¥ä½œï¼š
    - è§‚å¯Ÿé˜¶æ®µï¼šæ³¨æ„ç”¨æˆ·è¯´äº†ä»€ä¹ˆï¼Œå¼€å§‹å›å¿†ç›¸å…³å†…å®¹
    - å›å¿†é˜¶æ®µï¼šä»è®°å¿†åº“é‡Œæ‰¾å‡ºæœ‰ç”¨çš„ä¿¡æ¯
    - åé¦ˆé˜¶æ®µï¼šå¥½è®°æ€§åŠ å¼ºï¼Œåè®°æ€§æ·˜æ±°
    - ç¡çœ é˜¶æ®µï¼šå®šæœŸæ•´ç†è®°å¿†ï¼Œå·©å›ºé‡è¦å†…å®¹

    æ½œæ„è¯†çš„å·¥ä½œæ–¹å¼ï¼š
    1. åªç®¡ä¼šè¯çŠ¶æ€ï¼Œå…·ä½“è®°å¿†å­˜å‚¨äº¤ç»™åº•å±‚ç³»ç»Ÿ
    2. å‡ºé”™äº†ä¹Ÿä¸å½±å“ä½ æ­£å¸¸èŠå¤©
    3. æ²¡æœ‰é…ç½®AIåŠ©æ‰‹æ—¶è‡ªåŠ¨å…³é—­ï¼Œä¸æ¶ˆè€—èµ„æº
    4. åƒäººçš„æ½œè¯†ä¸€æ ·ï¼Œé»˜é»˜å·¥ä½œï¼Œä¸æ‰“æ‰°ä¸»æ„è¯†æ€è€ƒ
    """

    # æ½œæ„è¯†å›å¿†çš„è§„åˆ™
    CHAINED_RECALL_PER_TYPE_LIMIT = 7  # æ¯ç§è®°å¿†æœ€å¤šæƒ³7æ¡ï¼Œé˜²æ­¢ä¿¡æ¯è¿‡è½½
    CHAINED_RECALL_FINAL_LIMIT = 7     # æœ€ç»ˆç»™ä¸»æ„è¯†æœ€å¤š7æ¡è®°å¿†
    NOTE_CANDIDATE_COUNT = 50          # å…ˆæ‰¾50æ¡ç¬”è®°ï¼Œè®©å°AIå¸®å¿™ç­›é€‰æœ‰ç”¨çš„

    def __init__(self, config, context, vector_store, note_service, provider_id: str = "", cognitive_service=None):
        """
        åˆå§‹åŒ–AIçš„æ½œæ„è¯†ç³»ç»Ÿ

        Args:
            config: é…ç½®ä¿¡æ¯ï¼ˆæ¯”å¦‚å¤šä¹…ç¡ä¸€æ¬¡è§‰æ•´ç†è®°å¿†ï¼‰
            context: èŠå¤©æœºå™¨äººçš„å¤§è„‘ï¼ˆä¸»æ„è¯†ï¼‰
            vector_store: è®°å¿†æ•°æ®åº“ï¼ˆå­˜æ‰€æœ‰é•¿æœŸè®°å¿†çš„åœ°æ–¹ï¼‰
            note_service: ç¬”è®°ç®¡ç†å™¨ï¼ˆé‡è¦ä¿¡æ¯ä¸“é—¨å­˜æ”¾å¤„ï¼‰
            provider_id: AIåŠ©æ‰‹çš„IDï¼Œæ²¡æœ‰çš„è¯æ½œæ„è¯†å°±ç¡è§‰ä¸å¹²æ´»
            cognitive_service: è®°å¿†ç®¡ç†æœåŠ¡ï¼ˆå¯é€‰ï¼Œå¦‚æœå¤–é¢å·²ç»æœ‰äº†å°±ç›´æ¥ç”¨ï¼‰
        """
        self.config = config
        self.memory_system: Optional[CognitiveService] = cognitive_service  # ä½¿ç”¨æ³¨å…¥çš„å®ä¾‹
        self.note_service = note_service
        self.context = context
        self.vector_store = vector_store
        self.provider_id = provider_id
        # ä»å…¨å±€å®¹å™¨è·å–logger
        self.logger = logger
        self.json_parser = JsonParser()

        # è·å–é…ç½®å€¼
        self.min_message_length = getattr(config, 'min_message_length', 5)
        self.short_term_memory_capacity = getattr(config, 'short_term_memory_capacity', 1.0)
        self.sleep_interval = getattr(config, 'sleep_interval', 3600)  # é»˜è®¤1å°æ—¶
        self.small_model_note_budget = getattr(config, 'small_model_note_budget', 8000)
        self.large_model_note_budget = getattr(config, 'large_model_note_budget', 12000)

        # åˆå§‹åŒ–çŸ­æœŸè®°å¿†ç®¡ç†å™¨
        self.session_memory_manager = SessionMemoryManager(
            capacity_multiplier=self.short_term_memory_capacity
        )

        # åˆå§‹åŒ–å·¥å…·ç±»
        self.prompt_builder = SmallModelPromptBuilder()
        self.memory_injector = MemoryInjector()
        self.query_processor = get_query_processor()

        # ç¡çœ ç›¸å…³
        self._sleep_timer = None
        self._stop_sleep_event = threading.Event()  # ä½¿ç”¨Eventæ›¿ä»£å¸ƒå°”æ ‡å¿—ï¼Œé¿å…ç«æ€æ¡ä»¶

        # åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿï¼ˆå¦‚æœæ²¡æœ‰é€šè¿‡ä¾èµ–æ³¨å…¥æä¾›ï¼‰
        self._init_memory_system()

    def _init_memory_system(self) -> None:
        """åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ"""
        # å¦‚æœå·²ç»æœ‰äº†æ³¨å…¥çš„è®¤çŸ¥æœåŠ¡ï¼Œç›´æ¥ä½¿ç”¨
        if self.memory_system is not None:
            self.logger.info("Using injected CognitiveService instance")
            # åˆå§‹åŒ–æ—¶æ‰§è¡Œä¸€æ¬¡ç¡çœ 
            self._sleep()
            # å¯åŠ¨å®šæœŸç¡çœ 
            self._start_periodic_sleep()
            return

        # å¦åˆ™åˆ›å»ºæ–°çš„è®¤çŸ¥æœåŠ¡å®ä¾‹ï¼ˆå‘åå…¼å®¹ï¼‰
        try:
            self.memory_system = CognitiveService(vector_store=self.vector_store)
            self.logger.info("Memory system initialized successfully")

            # åˆå§‹åŒ–æ—¶æ‰§è¡Œä¸€æ¬¡ç¡çœ 
            self._sleep()

            # å¯åŠ¨å®šæœŸç¡çœ 
            self._start_periodic_sleep()

        except Exception as e:
            self.logger.error(f"Memory system initialization failed: {e}")
            self.memory_system = None

    def is_enabled(self) -> bool:
        """æ£€æŸ¥è®°å¿†ç³»ç»Ÿæ˜¯å¦å¯ç”¨"""
        return self.memory_system is not None

    def should_process_message(self, event: AstrMessageEvent) -> bool:
        """
        åˆ¤æ–­è¿™æ¡æ¶ˆæ¯æ˜¯å¦å€¼å¾—è®°ä½

        Args:
            event: ç”¨æˆ·å‘æ¥çš„æ¶ˆæ¯

        Returns:
            True=å€¼å¾—è®°ä½ï¼ŒFalse=ä¸ç”¨è®°
        """
        if not self.is_enabled():
            self.logger.debug("æ¶ˆæ¯è¢«è¿‡æ»¤: è®°å¿†ç³»ç»Ÿæœªå¯ç”¨")
            return False

        # ä»äº‹ä»¶ä¸­æå–æ¶ˆæ¯æ–‡æœ¬
        message_text = self._extract_message_text(event)
        if not message_text:
            self.logger.debug("æ¶ˆæ¯è¢«è¿‡æ»¤: æ–‡æœ¬ä¸ºç©º")
            return False

        message_text = message_text.strip()

        # æ£€æŸ¥æœ€å°æ¶ˆæ¯é•¿åº¦
        if len(message_text) < self.min_message_length:
            self.logger.debug(f"æ¶ˆæ¯è¢«è¿‡æ»¤: é•¿åº¦è¿‡çŸ­ ({len(message_text)} < {self.min_message_length})")
            return False

        # å¿½ç•¥çº¯æŒ‡ä»¤æ¶ˆæ¯ï¼ˆä»¥/å¼€å¤´ï¼‰
        if message_text.startswith('/'):
            self.logger.debug("æ¶ˆæ¯è¢«è¿‡æ»¤: ä»¥'/'å¼€å¤´")
            return False

        return True

    def inject_initial_memories(self, event: AstrMessageEvent):
        """
        äº‹ä»¶åˆ°è¾¾æ—¶æ³¨å…¥åˆå§‹è®°å¿†

        Args:
            event: æ¶ˆæ¯äº‹ä»¶
        """
        if not self.should_process_message(event):
            return

        session_id = self._get_session_id(event)

        try:
            # 1. ä»å¤©ä½¿ä¹‹å¿ƒè·å–å®Œæ•´å¯¹è¯å†å²
            chat_records = []
            if hasattr(event, 'angelheart_context'):
                try:
                    angelheart_data = json.loads(event.angelheart_context)
                    chat_records = angelheart_data.get('chat_records', [])
                except (json.JSONDecodeError, KeyError):
                    self.logger.warning(f"Failed to parse angelheart_context for session {session_id}")

            # åˆå§‹åŒ– user_list ä¸ºç©ºåˆ—è¡¨
            user_list = []

            # å¦‚æœæ²¡æœ‰å¯¹è¯è®°å½•ï¼Œä½¿ç”¨å½“å‰æ¶ˆæ¯æ–‡æœ¬
            if not chat_records:
                message_text = self._extract_message_text(event)
                query = message_text if message_text else ""
            else:
               # 2. æ ¼å¼åŒ–å¯¹è¯å†å²ä¸ºæŸ¥è¯¢å­—ç¬¦ä¸²
               query, user_list = self.prompt_builder.format_chat_records(chat_records)

            # 3. è¯»å–ä¸»æ„è¯†çš„çŸ­æœŸè®°å¿†ï¼ˆä¾›å…¶ä»–æ¨¡å—å‚è€ƒï¼Œä¸è¿›è¡Œé•¿æœŸè®°å¿†å¬å›ï¼‰
            session_memories = self.session_memory_manager.get_session_memories(session_id)

            # 4. è½¬æ¢ä¸ºJSONæ ¼å¼
            memories_json = self._memories_to_json(session_memories)

            # æ³¨å…¥åˆ°äº‹ä»¶ä¸­ï¼ˆä½¿ç”¨angelmemory_contextï¼‰
            event.angelmemory_context = json.dumps({
                'memories': memories_json,
                'recall_query': query,  # ä¿ç•™æŸ¥è¯¢å­—ç¬¦ä¸²ä¾›åç»­ä½¿ç”¨
                'recall_time': time.time(),
                'session_id': session_id,
                'user_list': user_list  # å°†æ–°ç”Ÿæˆçš„"ç”¨æˆ·æ¸…å•"å­˜å…¥ä¸Šä¸‹æ–‡
            })

        except Exception as e:
            self.logger.error(f"Memory recall failed for session {session_id}: {e}")

    def _parse_memory_context(self, event: AstrMessageEvent) -> Optional[Dict[str, Any]]:
        """
        è§£æäº‹ä»¶ä¸­çš„è®°å¿†ä¸Šä¸‹æ–‡æ•°æ®

        Args:
            event: æ¶ˆæ¯äº‹ä»¶

        Returns:
            åŒ…å« session_id, query, user_list çš„å­—å…¸ï¼Œè§£æå¤±è´¥è¿”å› None
        """
        if not hasattr(event, 'angelmemory_context'):
            return None

        try:
            context_data = json.loads(event.angelmemory_context)
            return {
                'session_id': context_data['session_id'],
                'query': context_data.get('recall_query', ''),
                'user_list': context_data.get('user_list', [])
            }
        except (json.JSONDecodeError, KeyError) as e:
            self.logger.warning(f"Failed to parse memory context: {e}")
            return None

    def _retrieve_memories_and_notes(
        self,
        event: AstrMessageEvent,
        query: str
    ) -> Dict[str, Any]:
        """
        æ£€ç´¢é•¿æœŸè®°å¿†å’Œå€™é€‰ç¬”è®°

        Args:
            event: æ¶ˆæ¯äº‹ä»¶
            query: æŸ¥è¯¢å­—ç¬¦ä¸²

        Returns:
            åŒ…å« long_term_memories, candidate_notes, note_id_mapping, secretary_decision çš„å­—å…¸
        """
        from .timing_diagnostics import timing_log, log_checkpoint

        log_checkpoint("å¼€å§‹é“¾å¼å¬å›")

        # 1. é¢„å¤„ç†è®°å¿†æ£€ç´¢æŸ¥è¯¢è¯
        memory_query = self.query_processor.process_query_for_memory(query, event)

        # 1. ä½¿ç”¨é“¾å¼å¬å›ä»é•¿æœŸè®°å¿†æ£€ç´¢ç›¸å…³è®°å¿†
        with timing_log("é“¾å¼å¬å›(chained_recall)", threshold_ms=5000):
            long_term_memories = self.memory_system.chained_recall(
                query=memory_query,
                per_type_limit=self.CHAINED_RECALL_PER_TYPE_LIMIT,
                final_limit=self.CHAINED_RECALL_FINAL_LIMIT
            )

        log_checkpoint(f"é“¾å¼å¬å›å®Œæˆï¼Œè·å¾—{len(long_term_memories)}æ¡è®°å¿†")

        # 2. è·å– secretary_decision ä¿¡æ¯
        secretary_decision = {}
        try:
            if hasattr(event, 'angelheart_context'):
                angelheart_data = json.loads(event.angelheart_context)
                secretary_decision = angelheart_data.get('secretary_decision', {})
        except (json.JSONDecodeError, KeyError):
            self.logger.debug("æ— æ³•è·å– secretary_decision ä¿¡æ¯")

        # 3. ä¼˜å…ˆä½¿ç”¨å¤©ä½¿ä¹‹å¿ƒæ ¸å¿ƒè¯é¢˜è¿›è¡Œç¬”è®°æ£€ç´¢
        core_topic = self._extract_core_topic(event)
        note_query = core_topic if core_topic and core_topic.strip() else query

        # åº”ç”¨ç»Ÿä¸€çš„æ£€ç´¢è¯é¢„å¤„ç†
        note_query = self.query_processor.process_query_for_notes(note_query, event)

        if core_topic and core_topic.strip():
            self.logger.info(f"ä½¿ç”¨æ ¸å¿ƒè¯é¢˜è¿›è¡Œç¬”è®°æ£€ç´¢: {note_query}")
        else:
            self.logger.debug(f"æœªæ‰¾åˆ°æ ¸å¿ƒè¯é¢˜ï¼Œä½¿ç”¨èŠå¤©è®°å½•æŸ¥è¯¢: {note_query}")

        log_checkpoint("å¼€å§‹ç¬”è®°æ£€ç´¢")

        # 4. è·å–å€™é€‰ç¬”è®°ï¼ˆç”¨äºå°æ¨¡å‹çš„é€‰æ‹©ï¼‰
        with timing_log("ç¬”è®°æ£€ç´¢(search_notes_by_token_limit)", threshold_ms=5000):
            candidate_notes = self.note_service.search_notes_by_token_limit(
                query=note_query,
                max_tokens=self.small_model_note_budget,
                recall_count=self.NOTE_CANDIDATE_COUNT
            )

        log_checkpoint(f"ç¬”è®°æ£€ç´¢å®Œæˆï¼Œè·å¾—{len(candidate_notes)}æ¡ç¬”è®°")

        # 5. åˆ›å»ºçŸ­IDåˆ°å®Œæ•´IDçš„æ˜ å°„ï¼ˆç”¨äºåç»­ä¸Šä¸‹æ–‡æ‰©å±•ï¼‰
        note_id_mapping = {}
        for note in candidate_notes:
            note_id = note.get('id')
            if note_id:
                short_id = MemoryIDResolver.generate_short_id(note_id)
                note_id_mapping[short_id] = note_id
            else:
                self.logger.warning(f"ğŸ” [DEBUG] è·³è¿‡æ— IDçš„ç¬”è®°: {note}")

        # 6. åˆ›å»ºçŸ­æœŸè®°å¿†IDæ˜ å°„è¡¨ï¼ˆç”¨äºè§£æ useful_memory_idsï¼‰
        memory_id_mapping = {}
        if long_term_memories:
            memory_id_mapping = MemoryIDResolver.generate_id_mapping(
                [memory.to_dict() for memory in long_term_memories], 'id'
            )
        else:
            self.logger.warning("ğŸ” [DEBUG] æ²¡æœ‰é•¿æœŸè®°å¿†ï¼Œmemory_id_mappingä¸ºç©º")

        return {
            'long_term_memories': long_term_memories,
            'candidate_notes': candidate_notes,
            'note_id_mapping': note_id_mapping,
            'memory_id_mapping': memory_id_mapping,
            'secretary_decision': secretary_decision,
            'core_topic': core_topic
        }

    async def _filter_memories_with_llm(
        self,
        query: str,
        long_term_memories: List,
        user_list: List,
        candidate_notes: List,
        secretary_decision: Dict,
        note_id_mapping: Dict[str, str],
        memory_id_mapping: Dict[str, str],
        session_id: str,
        core_topic: str = None
    ) -> Optional[Dict[str, Any]]:
        """
        ä½¿ç”¨LLMç­›é€‰è®°å¿†å’Œç¬”è®°

        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            long_term_memories: é•¿æœŸè®°å¿†åˆ—è¡¨
            user_list: ç”¨æˆ·åˆ—è¡¨
            candidate_notes: å€™é€‰ç¬”è®°åˆ—è¡¨
            secretary_decision: ç§˜ä¹¦å†³ç­–ä¿¡æ¯
            note_id_mapping: ç¬”è®°IDæ˜ å°„
            memory_id_mapping: çŸ­æœŸè®°å¿†IDæ˜ å°„
            session_id: ä¼šè¯ID
            core_topic: å½“å‰å¯¹è¯çš„æ ¸å¿ƒè¯é¢˜

        Returns:
            åŒ…å« feedback_data, useful_note_short_ids, note_context çš„å­—å…¸ï¼Œå¤±è´¥è¿”å› None
        """
        # 1. æ„å»ºå°æ¨¡å‹æç¤ºè¯
        prompt = self.prompt_builder.build_memory_prompt(
            query, long_term_memories, user_list, candidate_notes, secretary_decision, core_topic
        )

        # è°ƒè¯•æ—¥å¿—ï¼šè®°å½•æç¤ºè¯å’Œå€™é€‰ç¬”è®°
        if not candidate_notes:
            self.logger.warning("ğŸ” [DEBUG] å€™é€‰ç¬”è®°ä¸ºç©ºï¼")

        # è¾“å‡ºå°æ¨¡å‹çš„è¯·æ±‚å†…å®¹
        self.logger.debug(f"Small model request content for session {session_id}:\n{prompt}")

        # 2. è·å– LLM æä¾›å•†
        provider = self.context.get_provider_by_id(self.provider_id)
        if not provider:
            self.logger.error(f"Provider not found: {self.provider_id} for session {session_id}")
            return None

        # 3. è°ƒç”¨ LLMï¼ˆæ·»åŠ 5ç§’è¶…æ—¶ï¼‰
        import asyncio
        try:
            llm_response = await asyncio.wait_for(
                provider.text_chat(prompt=prompt),
                timeout=30.0  # 30ç§’è¶…æ—¶ï¼Œé€‚åˆå®æ—¶å¯¹è¯
            )
        except asyncio.TimeoutError:
            self.logger.warning(f"â±ï¸ LLMè°ƒç”¨è¶…æ—¶(30ç§’) for session {session_id}ï¼Œè·³è¿‡è®°å¿†æ•´ç†")
            return None

        if not llm_response or not llm_response.completion_text:
            self.logger.error(f"LLM API call failed for session {session_id}")
            return None

        # 4. æå–å“åº”æ–‡æœ¬
        response_text = llm_response.completion_text

        # è¾“å‡ºå°æ¨¡å‹çš„åŸå§‹å“åº”
        self.logger.info(f"Small model raw response for session {session_id}:\n{response_text}")

        # 5. è§£æå®Œæ•´çš„ç»“æ„åŒ–è¾“å‡º
        full_json_data = self.json_parser.extract_json(response_text)
        self.logger.debug(f"Parsed full_json_data: {full_json_data}")

        if not isinstance(full_json_data, dict):
            self.logger.error(f"JSON parsing failed or did not return a dict for session {session_id}")
            return None

        # 6. åˆ†åˆ«æå– useful_notes å’Œ feedback_data
        useful_note_short_ids = full_json_data.get('useful_notes', [])
        feedback_data = full_json_data.get('feedback_data', {})

        # 7. IDè§£æï¼šä½¿ç”¨æ­£ç¡®çš„æ˜ å°„è§£æID (ç°åœ¨ä½œç”¨äº feedback_data)
        if 'useful_memory_ids' in feedback_data:
            # ä½¿ç”¨çŸ­æœŸè®°å¿†æ˜ å°„è§£æ useful_memory_ids
            feedback_data['useful_memory_ids'] = MemoryIDResolver.resolve_memory_ids(
                feedback_data.get('useful_memory_ids', []),
                long_term_memories,
                self.logger
            )
        else:
            self.logger.warning("ğŸ” [DEBUG] feedback_dataä¸­æ²¡æœ‰useful_memory_idså­—æ®µ")

        if not isinstance(feedback_data, dict):
            self.logger.error(f"feedback_data is not a dict, it's {type(feedback_data)}: {feedback_data}")
            feedback_data = {}  # å®‰å…¨é™çº§

        # 8. å¤„ç†é€‰ä¸­çš„ç¬”è®°IDï¼Œè¿›è¡Œä¸Šä¸‹æ–‡æ‰©å±•
        note_context = ""
        if useful_note_short_ids:

            # è¿›è¡Œä¸Šä¸‹æ–‡æ‰©å±•
            note_context = NoteContextBuilder.expand_context_from_note_ids(
                useful_note_short_ids,
                self.note_service,
                self.large_model_note_budget,
                note_id_mapping
            )

        return {
            'feedback_data': feedback_data,
            'useful_note_short_ids': useful_note_short_ids,
            'note_context': note_context
        }

    def _inject_memories_to_request(
        self,
        request: ProviderRequest,
        session_id: str,
        note_context: str
    ) -> None:
        """
        å°†è®°å¿†æ³¨å…¥åˆ°LLMè¯·æ±‚ä¸­

        Args:
            request: LLMè¯·æ±‚å¯¹è±¡
            session_id: ä¼šè¯ID
            note_context: ç¬”è®°ä¸Šä¸‹æ–‡
        """
        # 1. ä»çŸ­æœŸè®°å¿†æ¨é€ç»™ä¸»æ„è¯†ï¼ˆæ½œæ„è¯†ç­›é€‰åçš„ç²¾é€‰è®°å¿†ï¼‰
        short_term_memories = self.session_memory_manager.get_session_memories(session_id)

        memory_context = self.memory_injector.format_fifo_memories_for_prompt(short_term_memories)

        # 2. åˆå¹¶è®°å¿†å’Œç¬”è®°ä¸Šä¸‹æ–‡
        if memory_context or note_context:
            combined_context = ""
            if memory_context:
                combined_context += memory_context
            if note_context:
                if combined_context:
                    combined_context += "\n\n---\n\n"
                combined_context += f"ç›¸å…³ç¬”è®°ä¸Šä¸‹æ–‡ï¼š\n{note_context}"

            # 3. æ³¨å…¥åˆ°ç³»ç»Ÿæç¤ºè¯
            request.system_prompt = self.memory_injector.inject_into_system_prompt(
                request.system_prompt,
                combined_context
            )

    def _update_memory_system(
        self,
        feedback_data: Dict[str, Any],
        long_term_memories: List,
        session_id: str
    ) -> None:
        """
        æ›´æ–°çŸ­æœŸè®°å¿†å¹¶å°†é•¿æœŸåé¦ˆä»»åŠ¡åŠ å…¥åå°é˜Ÿåˆ—

        Args:
            feedback_data: LLMåé¦ˆæ•°æ®
            long_term_memories: é•¿æœŸè®°å¿†åˆ—è¡¨
            session_id: ä¼šè¯ID
        """
        useful_memory_ids = feedback_data.get('useful_memory_ids', [])
        new_memories_raw = feedback_data.get('new_memories', {})
        merge_groups_raw = feedback_data.get('merge_groups', [])

        # 1. åŒæ­¥æ›´æ–°çŸ­æœŸè®°å¿†ï¼Œç¡®ä¿æœ¬æ¬¡è¯·æ±‚å³å¯ä½¿ç”¨
        if useful_memory_ids:
            memory_map = {memory.id: memory for memory in long_term_memories}
            useful_long_term_memories = [
                memory_map[memory_id]
                for memory_id in useful_memory_ids
                if memory_id in memory_map
            ]

            if useful_long_term_memories:
                self.session_memory_manager.add_memories_to_session(session_id, useful_long_term_memories)
                self.logger.debug(
                    "æ½œæ„è¯†ç­›é€‰ï¼š%dæ¡æœ‰ç”¨è®°å¿†è¿›å…¥çŸ­æœŸè®°å¿†",
                    len(useful_long_term_memories)
                )

        # 2. åå°å¼‚æ­¥å¤„ç†é•¿æœŸè®°å¿†åé¦ˆ
        new_memories = MemoryIDResolver.normalize_new_memories_format(new_memories_raw, self.logger)
        merge_groups = MemoryIDResolver.normalize_merge_groups_format(merge_groups_raw)

        if useful_memory_ids or new_memories or merge_groups:
            task_payload = {
                'feedback_fn': self._execute_feedback_task,
                'session_id': session_id,
                'payload': {
                    'useful_memory_ids': list(useful_memory_ids),
                    'new_memories': new_memories,
                    'merge_groups': merge_groups,
                    'session_id': session_id
                }
            }
            get_feedback_queue().submit(task_payload)
            self.logger.debug(
                "å·²æäº¤è®°å¿†åé¦ˆä»»åŠ¡ï¼ˆsession=%s, useful=%d, new=%d, merge=%dï¼‰",
                session_id,
                len(useful_memory_ids),
                len(new_memories),
                len(merge_groups)
            )
        else:
            self.logger.debug("è®°å¿†åé¦ˆæ— å¾…å¤„ç†å†…å®¹ï¼Œè·³è¿‡")

        self.logger.info(
            "è®°å¿†æ•´ç†æäº¤å®Œæˆï¼ˆä¼šè¯ %sï¼‰ï¼šæ½œæ„è¯†ç­›é€‰å‡º %d æ¡æœ‰ç”¨è®°å¿†è¿›å…¥çŸ­æœŸè®°å¿†",
            session_id,
            len(useful_memory_ids)
        )

    def _execute_feedback_task(
        self,
        useful_memory_ids: List[str],
        new_memories: List[Dict[str, Any]],
        merge_groups: List[List[str]],
        session_id: str
    ) -> None:
        """åå°çº¿ç¨‹æ‰§è¡Œçš„é•¿æœŸè®°å¿†åé¦ˆã€‚"""
        self.logger.debug(
            "[feedback_queue] session=%s å¼€å§‹å¤„ç†åé¦ˆ: useful=%d new=%d merge=%d",
            session_id,
            len(useful_memory_ids),
            len(new_memories),
            len(merge_groups)
        )

        self.memory_system.feedback(
            useful_memory_ids=useful_memory_ids,
            new_memories=new_memories,
            merge_groups=merge_groups
        )

        self.logger.debug("[feedback_queue] session=%s åé¦ˆä»»åŠ¡å®Œæˆ", session_id)

    def _extract_core_topic(self, event: AstrMessageEvent) -> str:
        """
        ä»å¤©ä½¿ä¹‹å¿ƒä¸Šä¸‹æ–‡ä¸­æå–æ ¸å¿ƒè¯é¢˜

        Args:
            event: æ¶ˆæ¯äº‹ä»¶

        Returns:
            æ ¸å¿ƒè¯é¢˜å­—ç¬¦ä¸²ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        try:
            if hasattr(event, 'angelheart_context'):
                angelheart_data = json.loads(event.angelheart_context)
                secretary_decision = angelheart_data.get('secretary_decision', {})
                core_topic = secretary_decision.get('topic', '')

                if core_topic and core_topic.strip():
                    return core_topic.strip()
        except (json.JSONDecodeError, KeyError) as e:
            self.logger.debug(f"æ— æ³•æå–æ ¸å¿ƒè¯é¢˜: {e}")

        return ""

    async def organize_and_inject_memories(self, event: AstrMessageEvent, request: ProviderRequest):
        """
        æ½œæ„è¯†çš„æ ¸å¿ƒå·¥ä½œï¼šæ•´ç†ç›¸å…³è®°å¿†å–‚ç»™ä¸»æ„è¯†

        å·¥ä½œæµç¨‹ï¼š
        1. ä»è®°å¿†åº“æ‰¾å‡ºç›¸å…³çš„å†…å®¹
        2. é—®å°AIå“ªäº›ä¿¡æ¯æœ‰ç”¨
        3. æŠŠæœ‰ç”¨çš„è®°å¿†åŒ…è£…æˆè®°å¿†åŒ…
        4. å–‚ç»™ä¸»æ„è¯†ï¼ˆLLMï¼‰å¸®åŠ©ä»–æ€è€ƒ

        Args:
            event: ç”¨æˆ·çš„æ¶ˆæ¯ï¼ˆè§¦å‘å›å¿†çš„çº¿ç´¢ï¼‰
            request: å³å°†å‘ç»™ä¸»æ„è¯†çš„è¯·æ±‚ï¼ˆæˆ‘ä»¬è¦å¾€é‡Œé¢å¡è®°å¿†ï¼‰
        """
        from .timing_diagnostics import timing_log, log_checkpoint

        # å¦‚æœæœªé…ç½® provider_idï¼Œè·³è¿‡è®°å¿†æ•´ç†
        if not self.provider_id:
            return

        # è§£æè®°å¿†ä¸Šä¸‹æ–‡æ•°æ®
        with timing_log("è§£æè®°å¿†ä¸Šä¸‹æ–‡", threshold_ms=10):
            context_data = self._parse_memory_context(event)
            if not context_data:
                return

        session_id = context_data['session_id']
        query = context_data['query']
        user_list = context_data['user_list']

        log_checkpoint(f"å¼€å§‹æ£€ç´¢è®°å¿† - session={session_id}")

        # æ£€ç´¢é•¿æœŸè®°å¿†å’Œå€™é€‰ç¬”è®°
        with timing_log("æ£€ç´¢é•¿æœŸè®°å¿†å’Œç¬”è®°", threshold_ms=1000):
            retrieval_data = self._retrieve_memories_and_notes(event, query)
        long_term_memories = retrieval_data['long_term_memories']
        candidate_notes = retrieval_data['candidate_notes']
        note_id_mapping = retrieval_data['note_id_mapping']
        memory_id_mapping = retrieval_data['memory_id_mapping']
        secretary_decision = retrieval_data['secretary_decision']
        core_topic = retrieval_data['core_topic']

        try:
            # ä½¿ç”¨LLMç­›é€‰è®°å¿†å’Œç¬”è®°
            filter_result = await self._filter_memories_with_llm(
                query, long_term_memories, user_list, candidate_notes,
                secretary_decision, note_id_mapping, memory_id_mapping, session_id, core_topic
            )

            if not filter_result:
                return

            feedback_data = filter_result['feedback_data']
            note_context = filter_result['note_context']

            # å°†åé¦ˆæ•°æ®ä¿å­˜åˆ°äº‹ä»¶ä¸­ï¼Œä¾›åç»­æ›´æ–°ä½¿ç”¨
            event.memory_feedback = {
                'feedback_data': feedback_data,
                'session_id': session_id
            }

            # æ›´æ–°è®°å¿†ç³»ç»Ÿï¼ˆå°†ç­›é€‰å‡ºçš„è®°å¿†åŒæ­¥åŠ å…¥çŸ­æœŸè®°å¿†ï¼‰
            self._update_memory_system(feedback_data, long_term_memories, session_id)

            # æ³¨å…¥è®°å¿†åˆ°è¯·æ±‚ï¼ˆä»çŸ­æœŸè®°å¿†ä¸­è¯»å–å¹¶æ³¨å…¥ï¼‰
            self._inject_memories_to_request(request, session_id, note_context)

        except Exception as e:
            import traceback
            self.logger.error(f"Memory organization failed for session {session_id}: {e}")
            self.logger.error(f"Traceback: {traceback.format_exc()}")



    def _extract_message_text(self, event: AstrMessageEvent) -> Optional[str]:
        """
        ä»äº‹ä»¶ä¸­æå–æ¶ˆæ¯æ–‡æœ¬ (ä½¿ç”¨æ ‡å‡†æ–¹æ³•)

        Args:
            event: æ¶ˆæ¯äº‹ä»¶

        Returns:
            æ¶ˆæ¯æ–‡æœ¬ï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å›None
        """
        try:
            # å‚ç…§ AngelHeart çš„æ­£ç¡®å®ç°
            return event.get_message_outline()
        except Exception as e:
            self.logger.warning(f"Deepæ€ç»´: è°ƒç”¨ event.get_message_outline() å¤±è´¥: {e}")
            return None

    def _get_session_id(self, event: AstrMessageEvent) -> str:
        """è·å–ä¼šè¯IDï¼Œç»Ÿä¸€ä½¿ç”¨ event.unified_msg_origin"""
        try:
            session_id = str(event.unified_msg_origin)
            if not session_id:
                self.logger.error("event.unified_msg_origin ä¸ºç©ºå€¼ï¼Œæ— æ³•å¤„ç†ä¼šè¯ï¼")
                raise ValueError("Cannot process event with an empty session ID from unified_msg_origin")
            return session_id
        except AttributeError:
            self.logger.error("äº‹ä»¶ä¸­ç¼ºå°‘ 'event.unified_msg_origin' å±æ€§ï¼Œæ— æ³•ç¡®å®šä¼šè¯IDï¼")
            raise

    def _memories_to_json(self, memories: List) -> List[Dict[str, Any]]:
        """
        å°†è®°å¿†å¯¹è±¡ç»Ÿä¸€è½¬æ¢ä¸ºJSONæ ¼å¼

        é€‚ç”¨äºBaseMemoryã€MemoryItemç­‰æ‰€æœ‰è®°å¿†å¯¹è±¡ç±»å‹

        Args:
            memories: è®°å¿†å¯¹è±¡åˆ—è¡¨

        Returns:
            JSONæ ¼å¼çš„è®°å¿†åˆ—è¡¨
        """
        memories_json = []
        for memory in memories:
            # å¤„ç†æšä¸¾ç±»å‹çš„memory_typeï¼ˆå…¼å®¹BaseMemoryå’ŒMemoryItemï¼‰
            memory_type = memory.memory_type.value if hasattr(memory.memory_type, 'value') else memory.memory_type

            memory_data = {
                'id': memory.id,
                'type': memory_type,
                'strength': memory.strength,
                'judgment': memory.judgment,
                'reasoning': memory.reasoning,
                'tags': memory.tags
            }
            memories_json.append(memory_data)

        return memories_json


    # _resolve_memory_ids æ–¹æ³•å·²ç§»è‡³ MemoryIDResolver ç±»ä¸­

    def _sleep(self):
        """AIç¡è§‰æ•´ç†è®°å¿†ï¼šé‡è¦å†…å®¹åŠ å¼ºï¼Œæ— ç”¨å†…å®¹æ¸…ç†"""
        if not self.is_enabled():
            return

        try:
            self.memory_system.consolidate_memories()
            self.logger.info("è®°å¿†å·©å›ºå®Œæˆ")
        except Exception as e:
            self.logger.error(f"è®°å¿†å·©å›ºå¤±è´¥: {e}")

    def _start_periodic_sleep(self):
        """å¯åŠ¨å®šæœŸç¡è§‰ï¼šåƒäººä¸€æ ·æŒ‰æ—¶æ•´ç†è®°å¿†"""
        if not self.is_enabled():
            return

        sleep_interval = self.sleep_interval
        if sleep_interval <= 0:
            return

        def sleep_worker():
            # ä½¿ç”¨Event.wait()æ›¿ä»£time.sleep()ï¼Œå¯ä»¥ç«‹å³å“åº”åœæ­¢ä¿¡å·
            while not self._stop_sleep_event.wait(timeout=sleep_interval):
                self._sleep()

        self._sleep_timer = threading.Thread(target=sleep_worker, daemon=True)
        self._sleep_timer.start()
        self.logger.info(f"å¯åŠ¨å®šæœŸç¡çœ ï¼Œé—´éš”: {sleep_interval}ç§’")

    def stop_sleep(self):
        """åœæ­¢å®šæœŸç¡çœ """
        self._stop_sleep_event.set()  # è®¾ç½®äº‹ä»¶ï¼Œé€šçŸ¥çº¿ç¨‹åœæ­¢
        if self._sleep_timer and self._sleep_timer.is_alive():
            self._sleep_timer.join(timeout=5)
        self.logger.info("å®šæœŸç¡çœ å·²åœæ­¢")

    def shutdown(self):
        """å…³é—­æ½œæ„è¯†ç³»ç»Ÿï¼Œè®©AIå¥½å¥½ä¼‘æ¯"""
        self.logger.info("æ­£åœ¨å…³é—­AIçš„æ½œæ„è¯†...")

        # åœæ­¢å®šæœŸç¡è§‰
        self.stop_sleep()

        # åœæ­¢è®°å¿†æ•´ç†ä»»åŠ¡
        from .utils.feedback_queue import stop_feedback_queue
        stop_feedback_queue(timeout=5)

        self.logger.info("AIæ½œæ„è¯†å·²ä¼‘æ¯ï¼Œä¸‹æ¬¡å†è§ï¼")
