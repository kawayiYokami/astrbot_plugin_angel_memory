"""
DeepMindæ½œæ„è¯†æ ¸å¿ƒæ¨¡å—

è¿™æ˜¯AIçš„æ½œæ„è¯†ç³»ç»Ÿï¼Œåœ¨åå°é»˜é»˜å¸®ä½ ç®¡ç†è®°å¿†ï¼š
- çœ‹åˆ°æ¶ˆæ¯æ—¶è‡ªåŠ¨å›å¿†ç›¸å…³å†…å®¹
- ç­›é€‰å‡ºæœ‰ç”¨çš„è®°å¿†å–‚ç»™ä¸»æ„è¯†
- å®šæœŸæ•´ç†è®°å¿†ï¼Œè®©é‡è¦å†…å®¹ä¸å®¹æ˜“å¿˜è®°
- å°±åƒäººç¡è§‰æ—¶æ•´ç†è®°å¿†ä¸€æ ·
"""

import asyncio
import time
import json
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from astrbot.api.event import AstrMessageEvent
from astrbot.api.provider import ProviderRequest
from .soul.soul_state import SoulState
from .utils.memory_id_resolver import MemoryIDResolver
from ..llm_memory.utils.json_parser import JsonParser
from .session_memory import SessionMemoryManager
from .memory_runtime import MemoryRuntime
from .utils import SmallModelPromptBuilder, MemoryInjector
from .utils.query_processor import get_query_processor
from .services.retrieval_service import DeepMindRetrievalService
from .services.injection_service import DeepMindInjectionService
from .services.feedback_service import DeepMindFeedbackService
from .services.sleep_service import DeepMindSleepService
from .utils.feedback_queue import get_feedback_queue

try:
    from astrbot.api import logger
except ImportError:
    import logging

    logger = logging.getLogger(__name__)


@dataclass
class ReflectionInput:
    """åæ€å…¥å£çš„çº¯æ•°æ®è½½ä½“ï¼ˆä¸ AstrMessageEvent è§£è€¦ï¼‰ã€‚"""

    session_id: str
    memory_scope: str
    latest_user_text: str
    latest_assistant_text: str
    secretary_decision: Dict[str, Any] = field(default_factory=dict)
    chat_records: List[Dict[str, Any]] = field(default_factory=list)
    memory_context: Dict[str, Any] = field(default_factory=dict)


class DeepMind:
    """AIçš„æ½œæ„è¯†ç³»ç»Ÿ

    è¿™æ˜¯AIçš„æ½œæ„è¯†ï¼Œé…åˆä¸»æ„è¯†ï¼ˆLLMï¼‰å·¥ä½œï¼š
    - è§‚å¯Ÿé˜¶æ®µï¼šæ³¨æ„ç”¨æˆ·è¯´äº†ä»€ä¹ˆï¼Œå¼€å§‹å›å¿†ç›¸å…³å†…å®¹
    - å›å¿†é˜¶æ®µï¼šä»è®°å¿†åº“é‡Œæ‰¾å‡ºæœ‰ç”¨çš„ä¿¡æ¯
    - åé¦ˆé˜¶æ®µï¼šå¥½è®°æ€§åŠ å¼ºï¼Œåè®°æ€§æ·˜æ±°
    - ç¡çœ é˜¶æ®µï¼šå®šæœŸæ•´ç†è®°å¿†ï¼Œå·©å›ºé‡è¦å†…å®¹

    æ½œæ„è¯†çš„å·¥ä½œæ–¹å¼ï¼š
    1. åªç®¡ä¼šè¯çŠ¶æ€ï¼Œå…·ä½“è®°å¿†å­˜å‚¨äº¤ç»™åº•å±‚ç³»ç»Ÿ
    2. å‡ºé”™äº†ä¹Ÿä¸å½±å“ä½ æ­£å¸¸èŠå¤©
    3. æ²¡æœ‰é…ç½®AIåŠ©æ‰‹æ—¶è‡ªåŠ¨å…³é—­ï¼Œä¸æ¶ˆè€—èµ„æº
    4. åƒäººçš„æ½œè¯†ä¸€æ ·ï¼Œé»˜é»˜å·¥ä½œï¼Œä¸æ‰“æ‰°ä¸»æ„è¯†æ€è€ƒ
    """

    # æ½œæ„è¯†å›å¿†çš„è§„åˆ™
    CHAINED_RECALL_PER_TYPE_LIMIT = 7  # æ¯ç§è®°å¿†æœ€å¤šæƒ³7æ¡ï¼Œé˜²æ­¢ä¿¡æ¯è¿‡è½½
    CHAINED_RECALL_FINAL_LIMIT = 7  # æœ€ç»ˆç»™ä¸»æ„è¯†æœ€å¤š7æ¡è®°å¿†

    def __init__(
        self,
        config,
        context,
        vector_store,
        note_service,
        plugin_context, # æ–°å¢
        memory_runtime: MemoryRuntime,
        provider_id: str = "",
    ):
        """
        åˆå§‹åŒ–AIçš„æ½œæ„è¯†ç³»ç»Ÿ

        Args:
            config: é…ç½®ä¿¡æ¯ï¼ˆæ¯”å¦‚å¤šä¹…ç¡ä¸€æ¬¡è§‰æ•´ç†è®°å¿†ï¼‰
            context: èŠå¤©æœºå™¨äººçš„å¤§è„‘ï¼ˆä¸»æ„è¯†ï¼‰
            vector_store: è®°å¿†æ•°æ®åº“ï¼ˆå­˜æ‰€æœ‰é•¿æœŸè®°å¿†çš„åœ°æ–¹ï¼‰
            note_service: ç¬”è®°ç®¡ç†å™¨ï¼ˆé‡è¦ä¿¡æ¯ä¸“é—¨å­˜æ”¾å¤„ï¼‰
            plugin_context: æ’ä»¶ä¸Šä¸‹æ–‡ï¼ˆæ–°å¢ï¼‰
            memory_runtime: ç»Ÿä¸€è®°å¿†è¿è¡Œæ—¶ï¼ˆå¿…å¡«ï¼‰
            provider_id: AIåŠ©æ‰‹çš„IDï¼Œæ²¡æœ‰çš„è¯æ½œæ„è¯†å°±ç¡è§‰ä¸å¹²æ´»
        """
        self.config = config
        self.memory_system = memory_runtime
        self.note_service = note_service
        self.context = context
        self.vector_store = vector_store
        self.provider_id = provider_id
        self.plugin_context = plugin_context # ä¿å­˜å¼•ç”¨

        # ä»å…¨å±€å®¹å™¨è·å–logger
        self.logger = logger
        self.json_parser = JsonParser()

        # è·å–é…ç½®å€¼ï¼ˆåµŒå¥—é…ç½®ï¼‰
        # å½“å‰æ ¼å¼ï¼šmemory_behavior.*, note_topk.*

        # è®°å¿†è¡Œä¸ºå‚æ•°
        memory_behavior = getattr(config, "memory_behavior", {})
        self.min_message_length = memory_behavior.get("min_message_length") if isinstance(memory_behavior, dict) else getattr(config, "min_message_length", 5)
        self.short_term_memory_capacity = memory_behavior.get("short_term_memory_capacity") if isinstance(memory_behavior, dict) else getattr(config, "short_term_memory_capacity", 1.0)
        self.sleep_interval = memory_behavior.get("sleep_interval") if isinstance(memory_behavior, dict) else getattr(config, "sleep_interval", 3600)

        # ç¬”è®° Top-K å‚æ•°ï¼ˆå€™é€‰å›ºå®šä¸ºæ³¨å…¥çš„ 7 å€ï¼‰
        note_topk = getattr(config, "note_topk", {})
        note_top_k = (
            int(note_topk.get("top_k", 8))
            if isinstance(note_topk, dict)
            else int(getattr(config, "note_top_k", 8))
        )
        if note_top_k < 0:
            note_top_k = 0
        self.note_inject_top_k = note_top_k
        self.note_candidate_top_k = note_top_k * 7

        # åˆå§‹åŒ–çŸ­æœŸè®°å¿†ç®¡ç†å™¨
        self.session_memory_manager = SessionMemoryManager(
            capacity_multiplier=self.short_term_memory_capacity
        )

        # ç¡çœ çŠ¶æ€ç®¡ç†
        self.last_sleep_time = None  # ä¸Šæ¬¡ç¡çœ æ—¶é—´æˆ³

        # åˆå§‹åŒ–å·¥å…·ç±»
        self.prompt_builder = SmallModelPromptBuilder()
        self.memory_injector = MemoryInjector()
        self.query_processor = get_query_processor()
        self.retrieval_service = DeepMindRetrievalService(self)
        self.injection_service = DeepMindInjectionService(self)
        self.feedback_service = DeepMindFeedbackService(self)
        self.sleep_service = DeepMindSleepService(self)
        self._reflection_state_lock = asyncio.Lock()
        self._reflection_states: Dict[str, Dict[str, Any]] = {}
        self._reflection_tick_task: Optional[asyncio.Task] = None
        self._reflection_stop_event = asyncio.Event()
        self._reflection_turn_threshold = max(
            1,
            int(
                (
                    memory_behavior.get("reflection_turn_threshold", 6)
                    if isinstance(memory_behavior, dict)
                    else getattr(config, "reflection_turn_threshold", 6)
                )
                or 6
            ),
        )
        self._reflection_idle_seconds = max(
            1,
            int(
                (
                    memory_behavior.get("reflection_idle_seconds", 600)
                    if isinstance(memory_behavior, dict)
                    else getattr(config, "reflection_idle_seconds", 600)
                )
                or 600
            ),
        )
        self._reflection_tick_seconds = max(
            10,
            int(
                (
                    memory_behavior.get("reflection_tick_seconds", 600)
                    if isinstance(memory_behavior, dict)
                    else getattr(config, "reflection_tick_seconds", 600)
                )
                or 600
            ),
        )

        # åˆå§‹åŒ–çµé­‚çŠ¶æ€ç®¡ç†å™¨
        try:
            # å°†é…ç½®å¯¹è±¡ä¼ é€’ç»™ SoulState
            self.soul = SoulState(config=self.config)
        except Exception as e:
            self.logger.error(f"çµé­‚çŠ¶æ€ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.soul = None


    def is_enabled(self) -> bool:
        """æ£€æŸ¥è®°å¿†ç³»ç»Ÿæ˜¯å¦å¯ç”¨"""
        return self.memory_system is not None

    def should_process_message(self, event: AstrMessageEvent) -> bool:
        """
        åˆ¤æ–­è¿™æ¡æ¶ˆæ¯æ˜¯å¦å€¼å¾—è®°ä½

        Args:
            event: ç”¨æˆ·å‘æ¥çš„æ¶ˆæ¯

        Returns:
            True=å€¼å¾—è®°ä½ï¼ŒFalse=ä¸ç”¨è®°
        """
        if not self.is_enabled():
            return False

        # ä»äº‹ä»¶ä¸­æå–æ¶ˆæ¯æ–‡æœ¬
        message_text = self._extract_message_text(event)
        if not message_text:
            return False

        message_text = message_text.strip()

        # æ£€æŸ¥æœ€å°æ¶ˆæ¯é•¿åº¦
        if len(message_text) < self.min_message_length:
            return False

        # å¿½ç•¥çº¯æŒ‡ä»¤æ¶ˆæ¯ï¼ˆä»¥/å¼€å¤´ï¼‰
        if message_text.startswith("/"):
            return False

        return True

    def _parse_memory_context(
        self, event: AstrMessageEvent
    ) -> Optional[Dict[str, Any]]:
        """
        è§£æäº‹ä»¶ä¸­çš„è®°å¿†ä¸Šä¸‹æ–‡æ•°æ®

        Args:
            event: æ¶ˆæ¯äº‹ä»¶

        Returns:
            åŒ…å« session_id, query, user_list çš„å­—å…¸ï¼Œè§£æå¤±è´¥è¿”å› None
        """
        return self.retrieval_service.parse_memory_context(event)

    async def _retrieve_memories_and_notes(
        self, event: AstrMessageEvent, query: str, precompute_vectors: bool = False
    ) -> Dict[str, Any]:
        """
        æ£€ç´¢é•¿æœŸè®°å¿†å’Œå€™é€‰ç¬”è®°

        Args:
            event: æ¶ˆæ¯äº‹ä»¶
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            precompute_vectors: æ˜¯å¦é¢„è®¡ç®—å‘é‡

        Returns:
            åŒ…å« long_term_memories, candidate_notes, note_id_mapping, secretary_decision çš„å­—å…¸
        """
        return await self.retrieval_service.retrieve_memories_and_notes(
            event, query, precompute_vectors
        )



    def _normalize_soul_value(self, dimension: str, value: float) -> float:
        """å°†çµé­‚çŠ¶æ€çš„ç‰©ç†å€¼å½’ä¸€åŒ–åˆ° [0, 1] åŒºé—´"""
        return self.injection_service.normalize_soul_value(dimension, value)

    def _create_tendency_bar(self, normalized_value: float) -> str:
        """åˆ›å»ºä¸€ä¸ª10æ ¼çš„æ–‡æœ¬è¿›åº¦æ¡"""
        return self.injection_service.create_tendency_bar(normalized_value)

    def _inject_memories_to_request(
        self, request: ProviderRequest, session_id: str, note_context: str, soul_state_values: Optional[Dict[str, Any]] = None
    ) -> None:
        """
        å°†è®°å¿†ã€ç¬”è®°å’Œçµé­‚çŠ¶æ€ç»Ÿä¸€æ³¨å…¥åˆ°LLMè¯·æ±‚ä¸­ï¼ˆä½¿ç”¨ extra_user_content_partsï¼‰
        """
        self.injection_service.inject_memories_to_request(
            request, session_id, note_context, soul_state_values
        )

    async def _update_memory_system(
        self, feedback_data: Dict[str, Any], long_term_memories: List, session_id: str
    ) -> None:
        """
        æ›´æ–°çŸ­æœŸè®°å¿†å¹¶å°†é•¿æœŸåé¦ˆä»»åŠ¡åŠ å…¥åå°é˜Ÿåˆ—

        Args:
            feedback_data: LLMåé¦ˆæ•°æ®
            long_term_memories: é•¿æœŸè®°å¿†åˆ—è¡¨
            session_id: ä¼šè¯ID
        """
        await self.feedback_service.update_memory_system(
            feedback_data, long_term_memories, session_id
        )

    async def _execute_feedback_task(
        self,
        useful_memory_ids: List[str],
        recalled_memory_ids: List[str],
        new_memories: List[Dict[str, Any]],
        merge_groups: List[List[str]],
        session_id: str,
    ) -> None:
        """å¼‚æ­¥æ‰§è¡Œçš„é•¿æœŸè®°å¿†åé¦ˆã€‚"""

        await self.feedback_service.execute_feedback_task(
            useful_memory_ids, recalled_memory_ids, new_memories, merge_groups, session_id
        )

    def _clean_note_content(self, content: str) -> str:
        """
        æ¸…ç†ç¬”è®°å†…å®¹ï¼Œä¿ç•™å•ä¸ªæ¢è¡Œç¬¦ï¼Œå»é™¤åŒæ¢è¡Œç¬¦

        Args:
            content: åŸå§‹ç¬”è®°å†…å®¹

        Returns:
            æ¸…ç†åçš„ç¬”è®°å†…å®¹ï¼ˆä¿ç•™\nï¼Œå»é™¤\n\nï¼‰
        """
        # å»é™¤é¦–å°¾ç©ºç™½
        content = content.strip()

        # å°†æ‰€æœ‰è¿ç»­çš„æ¢è¡Œç¬¦ï¼ˆåŒ…æ‹¬ç©ºè¡Œï¼‰æ›¿æ¢ä¸ºå•ä¸ªæ¢è¡Œç¬¦
        import re
        content = re.sub(r'\n+', '\n', content)

        return content

    async def organize_and_inject_memories(
        self, event: AstrMessageEvent, request: ProviderRequest
    ):
        """
        æ½œæ„è¯†çš„æ ¸å¿ƒå·¥ä½œï¼šæ•´ç†ç›¸å…³è®°å¿†å¹¶ç»“åˆçµé­‚çŠ¶æ€ï¼Œå–‚ç»™ä¸»æ„è¯†ã€‚
        """
        # å°†plugin_contextæ³¨å…¥åˆ°eventä¸­ï¼Œä¾›QueryProcessorä½¿ç”¨
        event.plugin_context = self.plugin_context

        session_id = self._get_session_id(event)

        # 1. ä» event.angelheart_context ä¸­è·å–å¯¹è¯å†å²ï¼ˆä»…ä¿ç•™æœªå¤„ç†æ¶ˆæ¯ï¼‰
        chat_records: List[Dict[str, Any]] = []
        unprocessed_chat_records: List[Dict[str, Any]] = []
        secretary_decision = {}
        if hasattr(event, "angelheart_context"):
            try:
                angelheart_data = json.loads(event.angelheart_context)
                chat_records = angelheart_data.get("chat_records", []) or []
                if not isinstance(chat_records, list):
                    chat_records = []
                unprocessed_chat_records = [
                    msg
                    for msg in chat_records
                    if isinstance(msg, dict) and msg.get("is_processed", True) is False
                ]
                secretary_decision = angelheart_data.get("secretary_decision", {}) or {}
            except (json.JSONDecodeError, KeyError, TypeError):
                self.logger.error(f"ä¸ºä¼šè¯ {session_id} è§£æ angelheart_context å¤±è´¥")

        # 2. ä» secretary_decision æ„å»ºæŸ¥è¯¢å­—ç¬¦ä¸²
        query = ""
        user_list = []

        if secretary_decision:
            # ä» secretary_decision æ„å»ºæŸ¥è¯¢è¯
            topic = secretary_decision.get("topic", "")
            entities = secretary_decision.get("entities", [])
            facts = secretary_decision.get("facts", [])
            keywords = secretary_decision.get("keywords", [])

            # æ„å»ºæŸ¥è¯¢è¯ï¼šä¸»é¢˜ + å®ä½“ + å…³é”®äº‹å® + å…³é”®è¯
            query_parts = []
            if topic:
                query_parts.append(topic)
            if entities:
                query_parts.extend(entities)
            if facts:
                query_parts.extend(facts[:3])  # é™åˆ¶äº‹å®æ•°é‡
            if keywords:
                query_parts.extend(keywords[:3])  # é™åˆ¶å…³é”®è¯æ•°é‡

            query = " ".join(query_parts)
        else:
            # é™çº§åˆ°åŸå§‹é€»è¾‘
            if not unprocessed_chat_records:
                message_text = self._extract_message_text(event)
                query = message_text if message_text else ""
            else:
                query, user_list = self.prompt_builder.format_chat_records(unprocessed_chat_records)

        # 3. å¦‚æœæœªé…ç½® provider_idï¼Œè·³è¿‡è®°å¿†æ•´ç†
        if not self.provider_id:
            return

        # 4. æ£€ç´¢é•¿æœŸè®°å¿†å’Œç¬”è®°
        retrieval_data = await self._retrieve_memories_and_notes(event, query, precompute_vectors=True)

        long_term_memories = retrieval_data["long_term_memories"]
        candidate_notes = retrieval_data["candidate_notes"]
        core_topic = retrieval_data["core_topic"]

        # 5. å°†æ£€ç´¢åˆ°çš„é•¿æœŸè®°å¿†å¡«å…¥çŸ­æœŸè®°å¿†
        if long_term_memories and self.memory_system:
            self.session_memory_manager.add_memories_to_session(session_id, long_term_memories)

        # 6. æ„å»ºç¬”è®°ä¸Šä¸‹æ–‡ï¼ˆå¤ç”¨NoteContextBuilderï¼‰
        note_context = ""
        if candidate_notes:
            from .utils.note_context_builder import NoteContextBuilder

            # Top-K æ³¨å…¥ç­–ç•¥ï¼šä¸å†æŒ‰ token é¢„ç®—è£å‰ª
            selected_notes = candidate_notes[: max(0, int(self.note_inject_top_k))]

            # ä½¿ç”¨ NoteContextBuilder æ¥æ„å»ºæœ€ç»ˆçš„ä¸Šä¸‹æ–‡
            if selected_notes:
                # builder ç°åœ¨è¿”å›åŒ…å«æ—¶æ•ˆæ€§è­¦å‘Šçš„ã€æ ¼å¼åŒ–çš„ç¬”è®°åˆ—è¡¨
                note_context = NoteContextBuilder.build_candidate_list_for_prompt(selected_notes)

                self.logger.debug(
                    f"ç¬”è®°ä¸Šä¸‹æ–‡æ„å»ºå®Œæˆï¼š{len(selected_notes)}æ¡ç¬”è®°ï¼Œ"
                    f"æ³¨å…¥ä¸Šé™K={self.note_inject_top_k}"
                )

        # 7. è·å–çµé­‚çŠ¶æ€å€¼
        soul_state_values = None
        if hasattr(self, "soul") and self.soul:
            try:
                soul_state_values = {
                    "RecallDepth": self.soul.get_value("RecallDepth"),
                    "ImpressionDepth": self.soul.get_value("ImpressionDepth"),
                    "ExpressionDesire": self.soul.get_value("ExpressionDesire"),
                    "Creativity": self.soul.get_value("Creativity")
                }
            except Exception as e:
                self.logger.warning(f"è·å–çµé­‚çŠ¶æ€å€¼å¤±è´¥: {e}")

        # 8. æ³¨å…¥è®°å¿†ã€ç¬”è®°å’Œçµé­‚çŠ¶æ€åˆ°è¯·æ±‚
        self._inject_memories_to_request(request, session_id, note_context, soul_state_values)

        # 9. (å¼‚æ­¥ä»»åŠ¡æ‰€éœ€) å°†åŸå§‹ä¸Šä¸‹æ–‡æ•°æ®å­˜å…¥event.angelmemory_context
        try:
            memory_id_mapping = MemoryIDResolver.generate_id_mapping([mem.to_dict() for mem in long_term_memories], "id")
            angelmemory_context = {
                "memories": self._memories_to_json(self.session_memory_manager.get_session_memories(session_id)),
                "recall_query": query,
                "recall_time": time.time(),
                "session_id": session_id,
                "user_list": user_list,
                "raw_chat_records": unprocessed_chat_records,
                "raw_memories": [memory.to_dict() for memory in long_term_memories],
                "raw_notes": candidate_notes,
                "core_topic": core_topic,
                "memory_id_mapping": memory_id_mapping,
                "note_id_mapping": {}
            }
            event.angelmemory_context = json.dumps(angelmemory_context)
        except Exception as e:
            self.logger.error(f"ä¿å­˜åŸå§‹ä¸Šä¸‹æ–‡æ•°æ®ä»¥ä¾›å¼‚æ­¥åˆ†æå¤±è´¥: {e}")

    def _extract_message_text(self, event: AstrMessageEvent) -> Optional[str]:
        """
        ä»äº‹ä»¶ä¸­æå–æ¶ˆæ¯æ–‡æœ¬ (ä½¿ç”¨æ ‡å‡†æ–¹æ³•)

        Args:
            event: æ¶ˆæ¯äº‹ä»¶

        Returns:
            æ¶ˆæ¯æ–‡æœ¬ï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å›None
        """
        try:
            # å‚ç…§ AngelHeart çš„æ­£ç¡®å®ç°
            return event.get_message_outline()
        except Exception as e:
            self.logger.error(f"æ½œæ„è¯†: è°ƒç”¨ event.get_message_outline() å¤±è´¥: {e}")
            return None

    def _get_session_id(self, event: AstrMessageEvent) -> str:
        """è·å–ä¼šè¯IDï¼Œç»Ÿä¸€ä½¿ç”¨ event.unified_msg_origin"""
        try:
            session_id = str(event.unified_msg_origin)
            if not session_id:
                self.logger.error("event.unified_msg_origin ä¸ºç©ºå€¼ï¼Œæ— æ³•å¤„ç†ä¼šè¯ï¼")
                raise ValueError(
                    "Cannot process event with an empty session ID from unified_msg_origin"
                )
            return session_id
        except AttributeError:
            self.logger.error(
                "äº‹ä»¶ä¸­ç¼ºå°‘ 'event.unified_msg_origin' å±æ€§ï¼Œæ— æ³•ç¡®å®šä¼šè¯IDï¼"
            )
            raise

    def _memories_to_json(self, memories: List) -> List[Dict[str, Any]]:
        """
        å°†è®°å¿†å¯¹è±¡ç»Ÿä¸€è½¬æ¢ä¸ºJSONæ ¼å¼

        é€‚ç”¨äºBaseMemoryã€MemoryItemç­‰æ‰€æœ‰è®°å¿†å¯¹è±¡ç±»å‹

        Args:
            memories: è®°å¿†å¯¹è±¡åˆ—è¡¨

        Returns:
            JSONæ ¼å¼çš„è®°å¿†åˆ—è¡¨
        """
        memories_json = []
        for memory in memories:
            # å¤„ç†æšä¸¾ç±»å‹çš„memory_typeï¼ˆå…¼å®¹BaseMemoryå’ŒMemoryItemï¼‰
            memory_type = (
                memory.memory_type.value
                if hasattr(memory.memory_type, "value")
                else memory.memory_type
            )

            memory_data = {
                "id": memory.id,
                "type": memory_type,
                "strength": memory.strength,
                "judgment": memory.judgment,
                "reasoning": memory.reasoning,
                "tags": memory.tags,
            }
            memories_json.append(memory_data)

        return memories_json

    # _resolve_memory_ids æ–¹æ³•å·²ç§»è‡³ MemoryIDResolver ç±»ä¸­

    async def check_and_sleep_if_needed(self, sleep_interval: int) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦ç¡çœ ï¼Œå¦‚æœéœ€è¦åˆ™è§¦å‘ç¡çœ 

        Args:
            sleep_interval: ç¡çœ é—´éš”ï¼ˆç§’ï¼‰ï¼Œ0è¡¨ç¤ºç¦ç”¨ç¡çœ 

        Returns:
            bool: æ˜¯å¦æ‰§è¡Œäº†ç¡çœ 
        """
        return await self.sleep_service.check_and_sleep_if_needed(sleep_interval)

    async def _sleep(self):
        """AIç¡è§‰æ•´ç†è®°å¿†ï¼šé‡è¦å†…å®¹åŠ å¼ºï¼Œæ— ç”¨å†…å®¹æ¸…ç†"""
        await self.sleep()

    async def sleep(self):
        """å…¬å…±ç¡çœ å…¥å£ï¼Œä¾›å¤–éƒ¨ç»„ä»¶è§¦å‘ç¡çœ æµç¨‹ã€‚"""
        await self.sleep_service.sleep()

    def shutdown(self):
        """å…³é—­æ½œæ„è¯†ç³»ç»Ÿï¼Œè®©AIå¥½å¥½ä¼‘æ¯"""
        try:
            self._reflection_stop_event.set()
            if self._reflection_tick_task and not self._reflection_tick_task.done():
                self._reflection_tick_task.cancel()
        except Exception:
            pass

        # åœæ­¢è®°å¿†æ•´ç†ä»»åŠ¡
        from .utils.feedback_queue import stop_feedback_queue

        stop_feedback_queue()

    async def async_analyze_and_update_memory(self, event: AstrMessageEvent, response):
        """
        å¼‚æ­¥åˆ†æå¹¶æ›´æ–°è®°å¿†ç³»ç»Ÿ

        Args:
            event: æ¶ˆæ¯äº‹ä»¶
            response: ä¸»LLMçš„å“åº”
        """
        # è·å–ä¼šè¯ID
        session_id = self._get_session_id(event)
        await self._ensure_reflection_tick_task()
        await self._buffer_reflection_turn(event, response, session_id)
        await self._trigger_reflection_if_needed(session_id, reason="count")

    async def _ensure_reflection_tick_task(self) -> None:
        if self._reflection_tick_task and not self._reflection_tick_task.done():
            return
        self._reflection_stop_event.clear()
        self._reflection_tick_task = asyncio.create_task(self._reflection_tick_loop())
        self.logger.info(
            f"[åæ€è°ƒåº¦] å¼€å§‹ tick={self._reflection_tick_seconds}s "
            f"idle={self._reflection_idle_seconds}s turns={self._reflection_turn_threshold}"
        )

    async def _reflection_tick_loop(self) -> None:
        while not self._reflection_stop_event.is_set():
            try:
                await asyncio.sleep(self._reflection_tick_seconds)
            except asyncio.CancelledError:
                break

            now = time.time()
            async with self._reflection_state_lock:
                session_ids = [
                    sid
                    for sid, state in self._reflection_states.items()
                    if int(state.get("pending_turns", 0)) > 0
                    and not bool(state.get("processing", False))
                    and (now - float(state.get("last_activity_at", 0.0)))
                    >= float(self._reflection_idle_seconds)
                ]
            if session_ids:
                self.logger.info(
                    f"[åæ€è°ƒåº¦] tickæ‰«æå‘½ä¸­ä¼šè¯æ•°={len(session_ids)} "
                    f"idleé˜ˆå€¼={self._reflection_idle_seconds}s"
                )

            for sid in session_ids:
                await self._trigger_reflection_if_needed(sid, reason="idle")

    def _build_reflection_records_for_turn(self, event: AstrMessageEvent, response) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆâ€œæœ¬è½®æ–°å¢â€çš„åæ€èŠå¤©è®°å½•ã€‚
        åˆ†æ”¯ï¼š
        - AngelHeartï¼šå–å·²å¤„ç†å†å² + æœ€æ–°ä¸€æ¡æœªå¤„ç†ç”¨æˆ·æ¶ˆæ¯ã€‚
        - åŸç”Ÿï¼šä»…å½“å‰è½® ç”¨æˆ· -> åŠ©ç†ã€‚
        """
        now_ts = time.time()
        response_text = (
            getattr(response, "completion_text", str(response))
            if response is not None
            else ""
        )

        # åˆ†æ”¯1ï¼šAngelHeart æä¾›å®Œæ•´ chat_records
        if hasattr(event, "angelheart_context") and getattr(event, "angelheart_context", None):
            try:
                angelheart_data = json.loads(event.angelheart_context)
                chat_records = angelheart_data.get("chat_records", []) or []
                if isinstance(chat_records, list) and chat_records:
                    processed = [
                        msg
                        for msg in chat_records
                        if isinstance(msg, dict) and bool(msg.get("is_processed", False))
                    ]
                    latest_user_unprocessed = None
                    for msg in reversed(chat_records):
                        if (
                            isinstance(msg, dict)
                            and str(msg.get("role", "")).strip() == "user"
                            and msg.get("is_processed", True) is False
                        ):
                            latest_user_unprocessed = msg
                            break
                    combined = list(processed)
                    if latest_user_unprocessed is not None:
                        combined.append(latest_user_unprocessed)
                    self.logger.debug(
                        f"[åæ€è°ƒåº¦] ä½¿ç”¨å¤©ä½¿ä¹‹å¿ƒèŠå¤©è®°å½•: processed={len(processed)} "
                        f"+ latest_unprocessed_user={1 if latest_user_unprocessed else 0}"
                    )
                    return self._dedupe_and_sort_chat_records(combined)
            except (json.JSONDecodeError, TypeError, KeyError) as e:
                self.logger.warning(f"åæ€èŠå¤©è®°å½•è§£æå¤±è´¥ï¼Œé™çº§åˆ°åŸç”Ÿåˆ†æ”¯: {e}")

        # åˆ†æ”¯2ï¼šåŸç”Ÿæ¶ˆæ¯ï¼ˆæ¯è½®ä»…ç”¨æˆ·è¾“å…¥ï¼‰
        user_text = self._extract_message_text(event) or ""
        records: List[Dict[str, Any]] = []
        if user_text.strip():
            records.append(
                {
                    "role": "user",
                    "content": user_text,
                    "sender_id": str(getattr(event, "sender_id", "") or "user"),
                    "sender_name": str(getattr(event, "sender_name", "") or "ç”¨æˆ·"),
                    "timestamp": float(now_ts),
                    "is_processed": False,
                    "is_structured_toolcall": False,
                }
            )
        if str(response_text).strip():
            records.append(
                {
                    "role": "assistant",
                    "content": str(response_text),
                    "sender_id": "assistant",
                    "sender_name": "åŠ©ç†",
                    "timestamp": float(now_ts + 0.001),
                    "is_processed": False,
                    "is_structured_toolcall": False,
                }
            )
        self.logger.debug(f"[åæ€è°ƒåº¦] ä½¿ç”¨åŸç”Ÿåˆ†æ”¯æ„å»ºæœ¬è½®è®°å½•: count={len(records)}")
        return records

    def _build_reflection_input(
        self,
        event: AstrMessageEvent,
        response,
        session_id: str,
    ) -> ReflectionInput:
        """
        ä»ä¸»çº¿ç¨‹äº‹ä»¶ä¸­æå–åæ€æ‰€éœ€æœ€å°æ•°æ®ç»“æ„ï¼Œé¿å…åæ€æ‰§è¡Œé˜¶æ®µä¾èµ– AstrMessageEventã€‚
        """
        records = self._build_reflection_records_for_turn(event, response)

        latest_user_text = ""
        latest_assistant_text = ""
        for msg in reversed(records):
            role = str(msg.get("role", "")).strip()
            content = self.prompt_builder.extract_text_from_content(msg.get("content", ""))
            if role == "assistant" and not latest_assistant_text and str(content).strip():
                latest_assistant_text = str(content).strip()
            if role == "user" and not latest_user_text and str(content).strip():
                latest_user_text = str(content).strip()
            if latest_user_text and latest_assistant_text:
                break

        secretary_decision: Dict[str, Any] = {}
        if hasattr(event, "angelheart_context") and getattr(event, "angelheart_context", None):
            try:
                angelheart_data = json.loads(event.angelheart_context)
                sd = angelheart_data.get("secretary_decision", {}) or {}
                if isinstance(sd, dict):
                    secretary_decision = sd
            except (json.JSONDecodeError, TypeError, KeyError):
                secretary_decision = {}

        memory_context: Dict[str, Any] = {}
        if hasattr(event, "angelmemory_context") and getattr(event, "angelmemory_context", None):
            try:
                context_data = json.loads(event.angelmemory_context)
                if isinstance(context_data, dict):
                    memory_context = {
                        "session_id": context_data.get("session_id", session_id),
                        "query": context_data.get("recall_query", ""),
                        "user_list": context_data.get("user_list", []),
                        "raw_chat_records": context_data.get("raw_chat_records", []),
                        "raw_memories": context_data.get("raw_memories", []),
                        "raw_notes": context_data.get("raw_notes", []),
                        "core_topic": context_data.get("core_topic", ""),
                        "memory_id_mapping": context_data.get("memory_id_mapping", {}),
                        "note_id_mapping": context_data.get("note_id_mapping", {}),
                    }
            except (json.JSONDecodeError, TypeError, KeyError):
                memory_context = {}

        try:
            memory_scope = self.plugin_context.resolve_memory_scope_from_event(event)
        except Exception:
            memory_scope = "public"

        return ReflectionInput(
            session_id=session_id,
            memory_scope=memory_scope,
            latest_user_text=latest_user_text,
            latest_assistant_text=latest_assistant_text,
            secretary_decision=secretary_decision,
            chat_records=records,
            memory_context=memory_context,
        )

    @staticmethod
    def _dedupe_and_sort_chat_records(records: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        normalized: List[Dict[str, Any]] = []
        seen = set()
        for msg in records or []:
            if not isinstance(msg, dict):
                continue
            role = str(msg.get("role", "") or "").strip()
            content = msg.get("content", "")
            sender_id = str(msg.get("sender_id", "") or "").strip()
            sender_name = str(msg.get("sender_name", "") or "").strip()
            timestamp = float(msg.get("timestamp", 0.0) or 0.0)
            if not role:
                continue
            # å»é‡é”®ï¼šè§’è‰²+å‘é€è€…+æ—¶é—´æˆ³+å†…å®¹
            dedupe_key = (role, sender_id, round(timestamp, 6), str(content))
            if dedupe_key in seen:
                continue
            seen.add(dedupe_key)
            normalized.append(
                {
                    "role": role,
                    "content": content,
                    "sender_id": sender_id,
                    "sender_name": sender_name,
                    "timestamp": timestamp,
                    "is_processed": bool(msg.get("is_processed", False)),
                    "is_structured_toolcall": bool(msg.get("is_structured_toolcall", False)),
                    "tool_call_id": msg.get("tool_call_id"),
                }
            )
        normalized.sort(key=lambda x: float(x.get("timestamp", 0.0) or 0.0))
        return normalized

    async def _buffer_reflection_turn(self, event: AstrMessageEvent, response, session_id: str) -> None:
        reflection_input = self._build_reflection_input(event, response, session_id)
        turn_records = list(reflection_input.chat_records)
        now = time.time()

        async with self._reflection_state_lock:
            state = self._reflection_states.setdefault(
                session_id,
                {
                    "pending_turns": 0,
                    "last_activity_at": 0.0,
                    "records": [],
                    "latest_input": None,
                    "processing": False,
                },
            )
            merged = list(state.get("records", [])) + list(turn_records)
            state["records"] = self._dedupe_and_sort_chat_records(merged)
            state["pending_turns"] = int(state.get("pending_turns", 0)) + 1
            state["last_activity_at"] = now
            state["latest_input"] = reflection_input
            self.logger.info(
                f"[åæ€è°ƒåº¦] å…¥ç¼“å†² session={session_id} "
                f"pending_turns={state['pending_turns']} records={len(state['records'])}"
            )

    async def _trigger_reflection_if_needed(self, session_id: str, reason: str) -> bool:
        now = time.time()
        payload: Dict[str, Any] = {}
        async with self._reflection_state_lock:
            state = self._reflection_states.get(session_id)
            if not state:
                return False
            if bool(state.get("processing", False)):
                return False

            pending_turns = int(state.get("pending_turns", 0))
            if pending_turns <= 0:
                return False
            idle_elapsed = now - float(state.get("last_activity_at", 0.0))
            meets_count = pending_turns >= int(self._reflection_turn_threshold)
            meets_idle = idle_elapsed >= float(self._reflection_idle_seconds)
            if not (meets_count or meets_idle):
                if reason == "count":
                    self.logger.debug(
                        f"[åæ€è°ƒåº¦] æœªè§¦å‘ session={session_id} "
                        f"pending={pending_turns}/{self._reflection_turn_threshold} "
                        f"idle={int(idle_elapsed)}s/{self._reflection_idle_seconds}s"
                    )
                return False

            state["processing"] = True
            latest_input = state.get("latest_input")
            if latest_input is None:
                state["processing"] = False
                return False
            payload = {
                "reflection_input": latest_input,
                "historical_chat_records": list(state.get("records", [])),
                "consumed_turns": pending_turns,
            }
            state["pending_turns"] = 0
            state["records"] = []

        historical_chat_text = ""
        try:
            historical_chat_text, _ = self.prompt_builder.format_chat_records(
                payload.get("historical_chat_records", [])
            )
        except Exception as e:
            self.logger.warning(f"æ ¼å¼åŒ–åæ€èŠå¤©è®°å½•å¤±è´¥ï¼Œé™çº§ä¸ºç©º: {e}")
            historical_chat_text = ""

        self.logger.info(
            f"[åæ€è°ƒåº¦] è§¦å‘ reason={reason} session={session_id} "
            f"turns={payload.get('consumed_turns', 0)} "
            f"records={len(payload.get('historical_chat_records', []))}"
        )
        success = await get_feedback_queue().submit(
            {
                "feedback_fn": self._execute_async_analysis_task,
                "session_id": session_id,
                "payload": {
                    "reflection_input": payload.get("reflection_input"),
                    "historical_chat_text_override": historical_chat_text,
                },
            }
        )

        async with self._reflection_state_lock:
            state = self._reflection_states.get(session_id)
            if not state:
                return bool(success)
            state["processing"] = False
            # è‹¥æ‰§è¡Œå¤±è´¥ï¼Œæ¢å¤å·²æ¶ˆè´¹çš„è½®æ¬¡ä¸è®°å½•ï¼Œé¿å…ä¸¢å¤±å¾…åæ€ä¸Šä¸‹æ–‡ã€‚
            if not bool(success):
                state["pending_turns"] = int(state.get("pending_turns", 0)) + int(
                    payload.get("consumed_turns", 0) or 0
                )
                restored = list(state.get("records", [])) + list(
                    payload.get("historical_chat_records", [])
                )
                state["records"] = self._dedupe_and_sort_chat_records(restored)
                self.logger.warning(
                    f"[åæ€è°ƒåº¦] æ‰§è¡Œå¤±è´¥åå›æ»š session={session_id} "
                    f"pending_turns={state['pending_turns']} records={len(state['records'])}"
                )
            else:
                self.logger.info(f"[åæ€è°ƒåº¦] å®Œæˆ session={session_id}")
        return bool(success)

    async def _execute_async_analysis_task(
        self,
        reflection_input: ReflectionInput,
        historical_chat_text_override: str = "",
    ):
        """
        å¼‚æ­¥æ‰§è¡Œçš„è®°å¿†åˆ†æä»»åŠ¡

        Args:
            reflection_input: åæ€è¾“å…¥çº¯æ•°æ®
        """
        try:
            session_id = str(getattr(reflection_input, "session_id", "") or "").strip()
            if not session_id:
                return False
            self.logger.info(
                f"[åæ€æ‰§è¡Œ] å¼€å§‹ session={session_id} "
                f"user_len={len(str(getattr(reflection_input, 'latest_user_text', '') or ''))} "
                f"assistant_len={len(str(getattr(reflection_input, 'latest_assistant_text', '') or ''))}"
            )

            context_data = getattr(reflection_input, "memory_context", {}) or {}
            if not isinstance(context_data, dict):
                context_data = {}

            query = str(context_data.get("query", "") or "")
            raw_chat_records = context_data.get("raw_chat_records", [])
            historical_chat_text = ""
            if str(historical_chat_text_override or "").strip():
                historical_chat_text = str(historical_chat_text_override).strip()
            elif isinstance(raw_chat_records, list) and raw_chat_records:
                historical_chat_text, _ = self.prompt_builder.format_chat_records(
                    raw_chat_records
                )
            if not historical_chat_text.strip():
                historical_chat_text = query
            if not historical_chat_text.strip():
                historical_chat_text = str(
                    getattr(reflection_input, "latest_user_text", "") or ""
                ).strip()

            # è·å–åŸå§‹è®°å¿†æ•°æ®
            raw_memories_data = context_data.get("raw_memories", [])
            core_topic = context_data.get("core_topic", "")

            # å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºè®°å¿†å¯¹è±¡
            from ..llm_memory.models.data_models import BaseMemory

            long_term_memories = []
            for memory_dict in raw_memories_data:
                try:
                    memory = BaseMemory.from_dict(memory_dict)
                    if memory:
                        long_term_memories.append(memory)
                except Exception as e:
                    self.logger.error(f"è½¬æ¢è®°å¿†å¯¹è±¡å¤±è´¥: {e}")

            # è·å–ä¸»LLMçš„æœ€ç»ˆå›ç­”
            response_text = str(
                getattr(reflection_input, "latest_assistant_text", "") or ""
            )


            # ä»ä¸Šä¸‹æ–‡æ•°æ®ä¸­è·å–IDæ˜ å°„è¡¨
            memory_id_mapping = context_data.get("memory_id_mapping", {})

            # æ„å»ºåæ€æç¤ºè¯ï¼ˆåªä¼ é€’è®°å¿†æ•°æ®ï¼Œä¸ä¼ é€’ç¬”è®°ï¼‰
            prompt = SmallModelPromptBuilder.build_post_hoc_analysis_prompt(
                historical_query=historical_chat_text,
                main_llm_response=response_text,
                raw_memories=long_term_memories,
                core_topic=core_topic,
                memory_id_mapping=memory_id_mapping,
                config=self.config,
            )


            # è°ƒç”¨å°æ¨¡å‹è¿›è¡Œåˆ†æï¼ˆåœ¨åå°çº¿ç¨‹ä¸­åŒæ­¥è°ƒç”¨ï¼‰
            provider = self.context.get_provider_by_id(self.provider_id)
            if not provider:
                self.logger.error(
                    f"æ‰¾ä¸åˆ°æä¾›è€…: {self.provider_id}ï¼Œä¼šè¯: {session_id}"
                )
                return

            try:
                # ç›´æ¥å¼‚æ­¥è°ƒç”¨ï¼Œæ— éœ€æ£€æŸ¥
                llm_response = await provider.text_chat(prompt=prompt)
            except Exception as e:
                self.logger.error(
                    f"ä¼šè¯ {session_id} çš„LLMè°ƒç”¨å¤±è´¥ï¼Œè·³è¿‡è®°å¿†æ•´ç†: {e}"
                )
                return

            if not llm_response or not getattr(llm_response, "completion_text", ""):
                self.logger.error(f"ä¼šè¯ {session_id} çš„LLM APIè°ƒç”¨å¤±è´¥")
                return

            # æå–å“åº”æ–‡æœ¬
            response_text = llm_response.completion_text

            # è§£æå®Œæ•´çš„ç»“æ„åŒ–è¾“å‡º
            full_json_data = self.json_parser.extract_json(response_text)

            if not isinstance(full_json_data, dict):
                self.logger.error(
                    f"ä¼šè¯ {session_id} çš„JSONè§£æå¤±è´¥æˆ–æœªè¿”å›å­—å…¸"
                )
                return

            # æå– feedback_data
            feedback_data = full_json_data.get("feedback_data", {})

            # --- çµé­‚çŠ¶æ€æ›´æ–° (Feedback Loop) ---
            if hasattr(self, "soul") and self.soul and "soul_state_code" in full_json_data:
                state_code = full_json_data.get("soul_state_code", "0000")
                if len(state_code) == 4:
                    try:
                        # ä½¿ç”¨æ–°çš„åŸå­åŒ–æ¥å£ï¼ˆ4ä½ä»£ç ä¸€æ¬¡æ€§è°ƒæ•´ï¼‰
                        # ä»£ç ä½å¯¹åº”: RecallDepth, ImpressionDepth, ExpressionDesire, Creativity
                        # 0000 é¢“åºŸ: è¯å°‘(Expression-), æ­»æ¿(Creativity-), ä¸æŸ¥å†å²(Recall-), æ‹’ç»æ–°çŸ¥(Impression-)
                        # 1111 è§‰é†’: è¯å¤š(Expression+), é£å‡(Creativity+), æŸ¥é˜…å†å²(Recall+), å¸æ”¶æ–°çŸ¥(Impression+)

                        self.soul.adjust(state_code, mode="reflect")
                        self.logger.info(f"ğŸ§˜ çµé­‚åæ€ ({state_code}): {self.soul.get_state_description()}")
                    except ValueError:
                        self.logger.warning(f"æ— æ•ˆçš„çµé­‚çŠ¶æ€ä»£ç : {state_code}")

            # IDè§£æï¼šä½¿ç”¨æ˜ å°„è¡¨å°†LLMè¿”å›çš„çŸ­IDç¿»è¯‘å›é•¿ID
            memory_id_mapping = context_data.get("memory_id_mapping", {})

            if "useful_memory_ids" in feedback_data:
                # ä½¿ç”¨æ˜ å°„è¡¨å°†çŸ­IDç¿»è¯‘å›é•¿ID
                short_ids = feedback_data.get("useful_memory_ids", [])
                long_ids = [
                    memory_id_mapping.get(short_id, short_id) for short_id in short_ids
                ]
                feedback_data["useful_memory_ids"] = long_ids
            else:
                self.logger.error(
                    "feedback_dataä¸­æ²¡æœ‰useful_memory_idså­—æ®µ"
                )

            if not isinstance(feedback_data, dict):
                self.logger.error(
                    f"feedback_dataä¸æ˜¯å­—å…¸ç±»å‹ï¼Œå®é™…ç±»å‹: {type(feedback_data)}ï¼Œå†…å®¹: {feedback_data}"
                )
                feedback_data = {}  # å®‰å…¨é™çº§

            # === æ–°çš„ç®€åŒ–æ¥å£å®ç° ===

            # --- å¼€å§‹æœ€ç»ˆä¿®æ­£ ---

            # 1. ä» feedback_data ä¸­è·å–åŸå§‹çš„ã€æŒ‰ç±»å‹åˆ†ç»„çš„æ–°è®°å¿†å­—å…¸
            new_memories_raw = feedback_data.get("new_memories", {})

            # 2. è°ƒç”¨å·²æœ‰çš„å·¥å…·å‡½æ•°ï¼Œå°†å…¶è½¬æ¢ä¸ºåº•å±‚æœåŠ¡æœŸæœ›çš„"æ‰å¹³åˆ—è¡¨"æ ¼å¼
            new_memories_normalized = MemoryIDResolver.normalize_new_memories_format(
                new_memories_raw, self.logger
            )

            # --- è®°å¿†ç”Ÿæˆé™åˆ¶ (åŸºäºçµé­‚ ImpressionDepth) ---
            if hasattr(self, "soul") and self.soul and new_memories_normalized:
                # è·å–å…è®¸ç”Ÿæˆçš„æœ€å¤§æ•°é‡
                impression_limit = int(self.soul.get_value("ImpressionDepth"))
                original_count = len(new_memories_normalized)

                # æˆªæ–­åˆ—è¡¨
                if original_count > impression_limit:
                    new_memories_normalized = new_memories_normalized[:impression_limit]
                    self.logger.info(f"âœ‚ï¸ è®°å¿†æˆªæ–­: çµé­‚ä»…å…è®¸è®°å½• {impression_limit} æ¡ (åŸ {original_count} æ¡)")

                # ä¸ºæ¯æ¡æ–°è®°å¿†æ³¨å…¥å½“å‰çš„çµé­‚å¿«ç…§
                snapshot = self.soul.get_snapshot()
                for mem in new_memories_normalized:
                    mem["state_snapshot"] = snapshot

            # --- ä¿®æ­£ç»“æŸ ---

            # 3. è°ƒç”¨å°è£…å¥½çš„ feedback æ¥å£ï¼Œå¹¶ä½¿ç”¨"è½¬æ¢å"çš„æ‰å¹³åˆ—è¡¨
            #    (ä»¥åŠæˆ‘ä»¬ä¹‹å‰è®¨è®ºè¿‡çš„ï¼Œè®© feedback è¿”å›æ–°åˆ›å»ºçš„å¯¹è±¡)
            newly_created_memories = []
            if self.memory_system:
                persona_name = ""
                if hasattr(reflection_input, "secretary_decision"):
                    sd = getattr(reflection_input, "secretary_decision", {}) or {}
                    if isinstance(sd, dict):
                        persona_name = str(sd.get("persona_name", "") or "").strip()
                memory_scope = self.plugin_context.resolve_memory_scope(
                    session_id, persona_name=persona_name
                )
                # ç›´æ¥å¼‚æ­¥è°ƒç”¨
                newly_created_memories = await self.memory_system.feedback(
                    useful_memory_ids=feedback_data.get("useful_memory_ids", []),
                    recalled_memory_ids=[mem.id for mem in (long_term_memories or []) if getattr(mem, "id", None)],
                    new_memories=new_memories_normalized,  # <--- ä½¿ç”¨è½¬æ¢åçš„æ•°æ®
                    merge_groups=feedback_data.get("merge_groups", []),
                    memory_scope=memory_scope,
                )

            # 2. æ›´æ–°çŸ­æœŸè®°å¿†
            # è·å–æœ‰ç”¨çš„æ—§è®°å¿†
            useful_ids = feedback_data.get("useful_memory_ids", [])
            useful_long_term_memories = [
                mem for mem in long_term_memories if mem.id in useful_ids
            ]

            # å°†æœ‰ç”¨çš„æ—§è®°å¿†å’Œå…¨æ–°çš„è®°å¿†åˆå¹¶ï¼Œä¸€èµ·æ”¾å…¥çŸ­æœŸè®°å¿†
            memories_for_session = useful_long_term_memories + newly_created_memories
            if memories_for_session:
                self.session_memory_manager.add_memories_to_session(
                    session_id, memories_for_session
                )
            self.logger.info(
                f"[åæ€æ‰§è¡Œ] å®Œæˆ session={session_id} "
                f"useful={len(useful_ids)} new={len(newly_created_memories)}"
            )

        except Exception as e:
            import traceback

            self.logger.error(f"å¼‚æ­¥è®°å¿†åˆ†æå¤±è´¥ - ä¼šè¯={session_id}: {e}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return False
        return True
