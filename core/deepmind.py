"""
DeepMindæ½œæ„è¯†æ ¸å¿ƒæ¨¡å—

è¿™æ˜¯AIçš„æ½œæ„è¯†ç³»ç»Ÿï¼Œåœ¨åå°é»˜é»˜å¸®ä½ ç®¡ç†è®°å¿†ï¼š
- çœ‹åˆ°æ¶ˆæ¯æ—¶è‡ªåŠ¨å›å¿†ç›¸å…³å†…å®¹
- ç­›é€‰å‡ºæœ‰ç”¨çš„è®°å¿†å–‚ç»™ä¸»æ„è¯†
- å®šæœŸæ•´ç†è®°å¿†ï¼Œè®©é‡è¦å†…å®¹ä¸å®¹æ˜“å¿˜è®°
- å°±åƒäººç¡è§‰æ—¶æ•´ç†è®°å¿†ä¸€æ ·
"""

import time
import json
import threading
from typing import List, Dict, Any, Optional
from astrbot.api.event import AstrMessageEvent
from astrbot.api.provider import ProviderRequest
from .utils.memory_id_resolver import MemoryIDResolver
from ..llm_memory import CognitiveService
from ..llm_memory.utils.json_parser import JsonParser
from .session_memory import SessionMemoryManager
from .utils import SmallModelPromptBuilder, MemoryInjector
from .utils.feedback_queue import get_feedback_queue
from .utils.query_processor import get_query_processor
from .config import MemoryConstants

try:
    from astrbot.api import logger
except ImportError:
    import logging

    logger = logging.getLogger(__name__)


class DeepMind:
    """AIçš„æ½œæ„è¯†ç³»ç»Ÿ

    è¿™æ˜¯AIçš„æ½œæ„è¯†ï¼Œé…åˆä¸»æ„è¯†ï¼ˆLLMï¼‰å·¥ä½œï¼š
    - è§‚å¯Ÿé˜¶æ®µï¼šæ³¨æ„ç”¨æˆ·è¯´äº†ä»€ä¹ˆï¼Œå¼€å§‹å›å¿†ç›¸å…³å†…å®¹
    - å›å¿†é˜¶æ®µï¼šä»è®°å¿†åº“é‡Œæ‰¾å‡ºæœ‰ç”¨çš„ä¿¡æ¯
    - åé¦ˆé˜¶æ®µï¼šå¥½è®°æ€§åŠ å¼ºï¼Œåè®°æ€§æ·˜æ±°
    - ç¡çœ é˜¶æ®µï¼šå®šæœŸæ•´ç†è®°å¿†ï¼Œå·©å›ºé‡è¦å†…å®¹

    æ½œæ„è¯†çš„å·¥ä½œæ–¹å¼ï¼š
    1. åªç®¡ä¼šè¯çŠ¶æ€ï¼Œå…·ä½“è®°å¿†å­˜å‚¨äº¤ç»™åº•å±‚ç³»ç»Ÿ
    2. å‡ºé”™äº†ä¹Ÿä¸å½±å“ä½ æ­£å¸¸èŠå¤©
    3. æ²¡æœ‰é…ç½®AIåŠ©æ‰‹æ—¶è‡ªåŠ¨å…³é—­ï¼Œä¸æ¶ˆè€—èµ„æº
    4. åƒäººçš„æ½œè¯†ä¸€æ ·ï¼Œé»˜é»˜å·¥ä½œï¼Œä¸æ‰“æ‰°ä¸»æ„è¯†æ€è€ƒ
    """

    # æ½œæ„è¯†å›å¿†çš„è§„åˆ™
    CHAINED_RECALL_PER_TYPE_LIMIT = 7  # æ¯ç§è®°å¿†æœ€å¤šæƒ³7æ¡ï¼Œé˜²æ­¢ä¿¡æ¯è¿‡è½½
    CHAINED_RECALL_FINAL_LIMIT = 7  # æœ€ç»ˆç»™ä¸»æ„è¯†æœ€å¤š7æ¡è®°å¿†
    NOTE_CANDIDATE_COUNT = 50  # å…ˆæ‰¾50æ¡ç¬”è®°ï¼Œè®©å°AIå¸®å¿™ç­›é€‰æœ‰ç”¨çš„

    def __init__(
        self,
        config,
        context,
        vector_store,
        note_service,
        provider_id: str = "",
        cognitive_service=None,
    ):
        """
        åˆå§‹åŒ–AIçš„æ½œæ„è¯†ç³»ç»Ÿ

        Args:
            config: é…ç½®ä¿¡æ¯ï¼ˆæ¯”å¦‚å¤šä¹…ç¡ä¸€æ¬¡è§‰æ•´ç†è®°å¿†ï¼‰
            context: èŠå¤©æœºå™¨äººçš„å¤§è„‘ï¼ˆä¸»æ„è¯†ï¼‰
            vector_store: è®°å¿†æ•°æ®åº“ï¼ˆå­˜æ‰€æœ‰é•¿æœŸè®°å¿†çš„åœ°æ–¹ï¼‰
            note_service: ç¬”è®°ç®¡ç†å™¨ï¼ˆé‡è¦ä¿¡æ¯ä¸“é—¨å­˜æ”¾å¤„ï¼‰
            provider_id: AIåŠ©æ‰‹çš„IDï¼Œæ²¡æœ‰çš„è¯æ½œæ„è¯†å°±ç¡è§‰ä¸å¹²æ´»
            cognitive_service: è®°å¿†ç®¡ç†æœåŠ¡ï¼ˆå¯é€‰ï¼Œå¦‚æœå¤–é¢å·²ç»æœ‰äº†å°±ç›´æ¥ç”¨ï¼‰
        """
        self.config = config
        self.memory_system: Optional[CognitiveService] = (
            cognitive_service  # ä½¿ç”¨æ³¨å…¥çš„å®ä¾‹
        )
        self.note_service = note_service
        self.context = context
        self.vector_store = vector_store
        self.provider_id = provider_id
        # ä»å…¨å±€å®¹å™¨è·å–logger
        self.logger = logger
        self.json_parser = JsonParser()

        # è·å–é…ç½®å€¼
        self.min_message_length = getattr(config, "min_message_length", 5)
        self.short_term_memory_capacity = getattr(
            config, "short_term_memory_capacity", 1.0
        )
        self.sleep_interval = getattr(config, "sleep_interval", 3600)  # é»˜è®¤1å°æ—¶
        self.small_model_note_budget = getattr(config, "small_model_note_budget", 8000)
        self.large_model_note_budget = getattr(config, "large_model_note_budget", 12000)

        # åˆå§‹åŒ–çŸ­æœŸè®°å¿†ç®¡ç†å™¨
        self.session_memory_manager = SessionMemoryManager(
            capacity_multiplier=self.short_term_memory_capacity
        )

        # åˆå§‹åŒ–å·¥å…·ç±»
        self.prompt_builder = SmallModelPromptBuilder()
        self.memory_injector = MemoryInjector()
        self.query_processor = get_query_processor()

        # ç¡çœ ç›¸å…³
        self._sleep_timer = None
        self._stop_sleep_event = (
            threading.Event()
        )  # ä½¿ç”¨Eventæ›¿ä»£å¸ƒå°”æ ‡å¿—ï¼Œé¿å…ç«æ€æ¡ä»¶

        # åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿï¼ˆå¦‚æœæ²¡æœ‰é€šè¿‡ä¾èµ–æ³¨å…¥æä¾›ï¼‰
        self._init_memory_system()

    def _init_memory_system(self) -> None:
        """åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ"""
        # å¦‚æœå·²ç»æœ‰äº†æ³¨å…¥çš„è®¤çŸ¥æœåŠ¡ï¼Œç›´æ¥ä½¿ç”¨
        if self.memory_system is not None:
            self.logger.info("Using injected CognitiveService instance")
            # åˆå§‹åŒ–æ—¶æ‰§è¡Œä¸€æ¬¡ç¡çœ 
            self._sleep()
            # å¯åŠ¨å®šæœŸç¡çœ 
            self._start_periodic_sleep()
            return

        # å¦åˆ™åˆ›å»ºæ–°çš„è®¤çŸ¥æœåŠ¡å®ä¾‹ï¼ˆå‘åå…¼å®¹ï¼‰
        try:
            self.memory_system = CognitiveService(vector_store=self.vector_store)
            self.logger.info("Memory system initialized successfully")

            # åˆå§‹åŒ–æ—¶æ‰§è¡Œä¸€æ¬¡ç¡çœ 
            self._sleep()

            # å¯åŠ¨å®šæœŸç¡çœ 
            self._start_periodic_sleep()

        except Exception as e:
            self.logger.error(f"Memory system initialization failed: {e}")
            self.memory_system = None

    def is_enabled(self) -> bool:
        """æ£€æŸ¥è®°å¿†ç³»ç»Ÿæ˜¯å¦å¯ç”¨"""
        return self.memory_system is not None

    def should_process_message(self, event: AstrMessageEvent) -> bool:
        """
        åˆ¤æ–­è¿™æ¡æ¶ˆæ¯æ˜¯å¦å€¼å¾—è®°ä½

        Args:
            event: ç”¨æˆ·å‘æ¥çš„æ¶ˆæ¯

        Returns:
            True=å€¼å¾—è®°ä½ï¼ŒFalse=ä¸ç”¨è®°
        """
        if not self.is_enabled():
            self.logger.debug("æ¶ˆæ¯è¢«è¿‡æ»¤: è®°å¿†ç³»ç»Ÿæœªå¯ç”¨")
            return False

        # ä»äº‹ä»¶ä¸­æå–æ¶ˆæ¯æ–‡æœ¬
        message_text = self._extract_message_text(event)
        if not message_text:
            self.logger.debug("æ¶ˆæ¯è¢«è¿‡æ»¤: æ–‡æœ¬ä¸ºç©º")
            return False

        message_text = message_text.strip()

        # æ£€æŸ¥æœ€å°æ¶ˆæ¯é•¿åº¦
        if len(message_text) < self.min_message_length:
            self.logger.debug(
                f"æ¶ˆæ¯è¢«è¿‡æ»¤: é•¿åº¦è¿‡çŸ­ ({len(message_text)} < {self.min_message_length})"
            )
            return False

        # å¿½ç•¥çº¯æŒ‡ä»¤æ¶ˆæ¯ï¼ˆä»¥/å¼€å¤´ï¼‰
        if message_text.startswith("/"):
            self.logger.debug("æ¶ˆæ¯è¢«è¿‡æ»¤: ä»¥'/'å¼€å¤´")
            return False

        return True

    def _parse_memory_context(
        self, event: AstrMessageEvent
    ) -> Optional[Dict[str, Any]]:
        """
        è§£æäº‹ä»¶ä¸­çš„è®°å¿†ä¸Šä¸‹æ–‡æ•°æ®

        Args:
            event: æ¶ˆæ¯äº‹ä»¶

        Returns:
            åŒ…å« session_id, query, user_list çš„å­—å…¸ï¼Œè§£æå¤±è´¥è¿”å› None
        """
        if not hasattr(event, "angelmemory_context"):
            return None

        try:
            context_data = json.loads(event.angelmemory_context)
            return {
                "session_id": context_data["session_id"],
                "query": context_data.get("recall_query", ""),
                "user_list": context_data.get("user_list", []),
                # æ·»åŠ åŸå§‹æ•°æ®å­—æ®µ
                "raw_memories": context_data.get("raw_memories", []),
                "raw_notes": context_data.get("raw_notes", []),
                "core_topic": context_data.get("core_topic", ""),
            }
        except (json.JSONDecodeError, KeyError) as e:
            self.logger.warning(f"Failed to parse memory context: {e}")
            return None

    def _retrieve_memories_and_notes(
        self, event: AstrMessageEvent, query: str
    ) -> Dict[str, Any]:
        """
        æ£€ç´¢é•¿æœŸè®°å¿†å’Œå€™é€‰ç¬”è®°

        Args:
            event: æ¶ˆæ¯äº‹ä»¶
            query: æŸ¥è¯¢å­—ç¬¦ä¸²

        Returns:
            åŒ…å« long_term_memories, candidate_notes, note_id_mapping, secretary_decision çš„å­—å…¸
        """
        # 1. é¢„å¤„ç†è®°å¿†æ£€ç´¢æŸ¥è¯¢è¯
        memory_query = self.query_processor.process_query_for_memory(query, event)

        # 1. ä½¿ç”¨é“¾å¼å¬å›ä»é•¿æœŸè®°å¿†æ£€ç´¢ç›¸å…³è®°å¿†
        long_term_memories = []
        if self.memory_system:
            long_term_memories = self.memory_system.chained_recall(
                query=memory_query,
                per_type_limit=self.CHAINED_RECALL_PER_TYPE_LIMIT,
                final_limit=self.CHAINED_RECALL_FINAL_LIMIT,
            )

        # 2. è·å– secretary_decision ä¿¡æ¯
        secretary_decision = {}
        try:
            if hasattr(event, "angelheart_context"):
                angelheart_data = json.loads(event.angelheart_context)
                secretary_decision = angelheart_data.get("secretary_decision", {})
        except (json.JSONDecodeError, KeyError):
            self.logger.debug("æ— æ³•è·å– secretary_decision ä¿¡æ¯")

        # 3. ä¼˜å…ˆä½¿ç”¨å¤©ä½¿ä¹‹å¿ƒæ ¸å¿ƒè¯é¢˜è¿›è¡Œç¬”è®°æ£€ç´¢
        core_topic = self._extract_core_topic(event)
        note_query = core_topic if core_topic and core_topic.strip() else query

        # åº”ç”¨ç»Ÿä¸€çš„æ£€ç´¢è¯é¢„å¤„ç†
        note_query = self.query_processor.process_query_for_notes(note_query, event)

        # 4. è·å–å€™é€‰ç¬”è®°ï¼ˆç”¨äºå°æ¨¡å‹çš„é€‰æ‹©ï¼‰
        candidate_notes = []
        if self.note_service:
            candidate_notes = self.note_service.search_notes_by_token_limit(
                query=note_query,
                max_tokens=self.small_model_note_budget,
                recall_count=self.NOTE_CANDIDATE_COUNT,
            )

        # 5. åˆ›å»ºçŸ­IDåˆ°å®Œæ•´IDçš„æ˜ å°„ï¼ˆç”¨äºåç»­ä¸Šä¸‹æ–‡æ‰©å±•ï¼‰
        note_id_mapping = {}
        for note in candidate_notes:
            note_id = note.get("id")
            if note_id:
                short_id = MemoryIDResolver.generate_short_id(note_id)
                note_id_mapping[short_id] = note_id

        # 6. åˆ›å»ºçŸ­æœŸè®°å¿†IDæ˜ å°„è¡¨ï¼ˆç”¨äºè§£æ useful_memory_idsï¼‰
        memory_id_mapping = {}
        if long_term_memories:
            memory_id_mapping = MemoryIDResolver.generate_id_mapping(
                [memory.to_dict() for memory in long_term_memories], "id"
            )

        return {
            "long_term_memories": long_term_memories,
            "candidate_notes": candidate_notes,
            "note_id_mapping": note_id_mapping,
            "memory_id_mapping": memory_id_mapping,
            "secretary_decision": secretary_decision,
            "core_topic": core_topic,
        }



    def _inject_memories_to_request(
        self, request: ProviderRequest, session_id: str, note_context: str
    ) -> None:
        """
        å°†è®°å¿†æ³¨å…¥åˆ°LLMè¯·æ±‚ä¸­

        Args:
            request: LLMè¯·æ±‚å¯¹è±¡
            session_id: ä¼šè¯ID
            note_context: ç¬”è®°ä¸Šä¸‹æ–‡
        """
        self.logger.debug(f"å¼€å§‹æ³¨å…¥è®°å¿†åˆ°è¯·æ±‚ä¸­ï¼Œä¼šè¯ID: {session_id}")

        # 1. ä»çŸ­æœŸè®°å¿†æ¨é€ç»™ä¸»æ„è¯†ï¼ˆæ½œæ„è¯†ç­›é€‰åçš„ç²¾é€‰è®°å¿†ï¼‰
        short_term_memories = self.session_memory_manager.get_session_memories(
            session_id
        )
        self.logger.debug(f"ä»çŸ­æœŸè®°å¿†ä¸­è·å–åˆ° {len(short_term_memories)} æ¡è®°å¿†")

        memory_context = self.memory_injector.format_fifo_memories_for_prompt(
            short_term_memories
        )
        self.logger.debug(f"æ ¼å¼åŒ–åçš„è®°å¿†ä¸Šä¸‹æ–‡é•¿åº¦: {len(memory_context)} å­—ç¬¦")

        # 2. åˆå¹¶è®°å¿†å’Œç¬”è®°ä¸Šä¸‹æ–‡
        if memory_context or note_context:
            # æ³¨å…¥è®°å¿†å†…å®¹ä½œä¸ºç”¨æˆ·æ¶ˆæ¯
            if memory_context:
                request.contexts.append({
                    "role": "user",
                    "content": f"[RAG-è®°å¿†] ç›¸å…³è®°å¿†å‚è€ƒ:\n{memory_context}"
                })

            # æ³¨å…¥ç¬”è®°å†…å®¹ä½œä¸ºç”¨æˆ·æ¶ˆæ¯
            if note_context:
                request.contexts.append({
                    "role": "user",
                    "content": f"[RAG-ç¬”è®°] ç›¸å…³ç¬”è®°å‚è€ƒ:\n{note_context}"
                })

            self.logger.debug("è®°å¿†å’Œç¬”è®°å·²æˆåŠŸæ³¨å…¥åˆ°è¯·æ±‚ä¸Šä¸‹æ–‡ä¸­")
        else:
            self.logger.debug("æ²¡æœ‰è®°å¿†æˆ–ç¬”è®°ä¸Šä¸‹æ–‡éœ€è¦æ³¨å…¥")

    def _update_memory_system(
        self, feedback_data: Dict[str, Any], long_term_memories: List, session_id: str
    ) -> None:
        """
        æ›´æ–°çŸ­æœŸè®°å¿†å¹¶å°†é•¿æœŸåé¦ˆä»»åŠ¡åŠ å…¥åå°é˜Ÿåˆ—

        Args:
            feedback_data: LLMåé¦ˆæ•°æ®
            long_term_memories: é•¿æœŸè®°å¿†åˆ—è¡¨
            session_id: ä¼šè¯ID
        """
        useful_memory_ids = feedback_data.get("useful_memory_ids", [])
        new_memories_raw = feedback_data.get("new_memories", {})
        merge_groups_raw = feedback_data.get("merge_groups", [])

        # 1. å¤„ç†æœ‰ç”¨çš„æ—§è®°å¿†
        useful_long_term_memories = []
        if useful_memory_ids:
            memory_map = {memory.id: memory for memory in long_term_memories}
            useful_long_term_memories = [
                memory_map[memory_id]
                for memory_id in useful_memory_ids
                if memory_id in memory_map
            ]

        # 2. å¤„ç†æ–°ç”Ÿæˆçš„è®°å¿†
        new_memories_normalized = MemoryIDResolver.normalize_new_memories_format(
            new_memories_raw, self.logger
        )
        new_memory_objects = []
        if new_memories_normalized:
            from ..llm_memory.models.data_models import BaseMemory, MemoryType

            for mem_dict in new_memories_normalized:
                try:
                    # åˆ›å»ºä¸€ä¸ªå­—å…¸å‰¯æœ¬ä»¥è¿›è¡Œä¿®æ”¹
                    init_data = mem_dict.copy()

                    # å°† 'type' é”®é‡å‘½åä¸º 'memory_type' å¹¶è½¬æ¢ä¸ºæšä¸¾ç±»å‹
                    if "type" in init_data:
                        init_data["memory_type"] = MemoryType(init_data.pop("type"))

                    # ç°åœ¨ï¼Œinit_data ä¸­çš„é”®ä¸æ„é€ å‡½æ•°å®Œå…¨åŒ¹é…
                    new_memory_objects.append(BaseMemory(**init_data))
                except Exception as e:
                    self.logger.warning(f"ä¸ºæ–°è®°å¿†åˆ›å»ºBaseMemoryå¯¹è±¡å¤±è´¥: {e}")

        # 3. æ›´æ–°çŸ­æœŸè®°å¿†ï¼šæ·»åŠ æ–°è®°å¿†ï¼Œè¯„ä¼°ç°æœ‰è®°å¿†ï¼Œæ¸…ç†æ­»äº¡è®°å¿†
        useful_memory_ids = [memory.id for memory in useful_long_term_memories]
        self.session_memory_manager.update_session_memories(
            session_id, new_memory_objects, useful_memory_ids
        )

        total_memories = len(useful_long_term_memories) + len(new_memory_objects)
        self.logger.info(
            "è®°å¿†æ›´æ–°ï¼š %d æ¡è®°å¿†è¿›å…¥çŸ­æœŸè®°å¿† (æœ‰ç”¨æ—§è®°å¿†: %d, æ–°ç”Ÿæˆè®°å¿†: %d)",
            total_memories,
            len(useful_long_term_memories),
            len(new_memory_objects),
        )

        # 4. æ–°å¢çš„INFOæ—¥å¿—é€»è¾‘
        if new_memory_objects:
            self.logger.info("åå°åˆ†æç”Ÿæˆäº† %d æ¡æ–°è®°å¿†ï¼š", len(new_memory_objects))
            for mem in new_memory_objects:
                # åªè®°å½•æ–°è®°å¿†çš„ç±»å‹å’Œè®ºæ–­ï¼Œä¿æŒINFOçº§åˆ«çš„æ—¥å¿—ç®€æ´
                self.logger.info(
                    f"  - [æ–°è®°å¿†: {mem.memory_type.value}] {mem.judgment}"
                )

        # 5. åå°å¼‚æ­¥å¤„ç†é•¿æœŸè®°å¿†åé¦ˆ
        merge_groups = MemoryIDResolver.normalize_merge_groups_format(merge_groups_raw)

        if useful_memory_ids or new_memories_normalized or merge_groups:
            task_payload = {
                "feedback_fn": self._execute_feedback_task,
                "session_id": session_id,
                # å°†æ‰€æœ‰æ•°æ®éƒ½æ”¾åœ¨é¡¶å±‚ï¼Œä¸ 'feedback_fn' åŒçº§
                "useful_memory_ids": list(useful_memory_ids),
                "new_memories": new_memories_normalized,
                "merge_groups": merge_groups,
                # 'payload' å­—æ®µå¯ä»¥ä¿ç•™å¹¶ä¼ å…¥ session_idï¼Œå› ä¸º _execute_feedback_task ä¼šç”¨åˆ°
                "payload": {"session_id": session_id},
            }
            get_feedback_queue().submit(task_payload)
        else:
            self.logger.debug("è®°å¿†åé¦ˆæ— å¾…å¤„ç†å†…å®¹ï¼Œè·³è¿‡")

    def _execute_feedback_task(
        self,
        useful_memory_ids: List[str],
        new_memories: List[Dict[str, Any]],
        merge_groups: List[List[str]],
        session_id: str,
    ) -> None:
        """åå°çº¿ç¨‹æ‰§è¡Œçš„é•¿æœŸè®°å¿†åé¦ˆã€‚"""
        self.logger.debug(
            "[feedback_queue] session=%s å¼€å§‹å¤„ç†åé¦ˆ: useful=%d new=%d merge=%d",
            session_id,
            len(useful_memory_ids),
            len(new_memories),
            len(merge_groups),
        )

        # æ£€æŸ¥ memory_system æ˜¯å¦å¯ç”¨
        if self.memory_system is not None:
            self.memory_system.feedback(
                useful_memory_ids=useful_memory_ids,
                new_memories=new_memories,
                merge_groups=merge_groups,
            )
        else:
            self.logger.warning("Memory system is not available, skipping feedback")

        self.logger.debug("[feedback_queue] session=%s åé¦ˆä»»åŠ¡å®Œæˆ", session_id)

    def _extract_core_topic(self, event: AstrMessageEvent) -> str:
        """
        ä»å¤©ä½¿ä¹‹å¿ƒä¸Šä¸‹æ–‡ä¸­æå–æ ¸å¿ƒè¯é¢˜

        Args:
            event: æ¶ˆæ¯äº‹ä»¶

        Returns:
            æ ¸å¿ƒè¯é¢˜å­—ç¬¦ä¸²ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        try:
            if hasattr(event, "angelheart_context"):
                angelheart_data = json.loads(event.angelheart_context)
                secretary_decision = angelheart_data.get("secretary_decision", {})
                core_topic = secretary_decision.get("topic", "")

                if core_topic and core_topic.strip():
                    return core_topic.strip()
        except (json.JSONDecodeError, KeyError) as e:
            self.logger.debug(f"æ— æ³•æå–æ ¸å¿ƒè¯é¢˜: {e}")

        return ""

    def _clean_note_content(self, content: str) -> str:
        """
        æ¸…ç†ç¬”è®°å†…å®¹ï¼Œä¿ç•™å•ä¸ªæ¢è¡Œç¬¦ï¼Œå»é™¤åŒæ¢è¡Œç¬¦

        Args:
            content: åŸå§‹ç¬”è®°å†…å®¹

        Returns:
            æ¸…ç†åçš„ç¬”è®°å†…å®¹ï¼ˆä¿ç•™\nï¼Œå»é™¤\n\nï¼‰
        """
        # å»é™¤é¦–å°¾ç©ºç™½
        content = content.strip()

        # å°†æ‰€æœ‰è¿ç»­çš„æ¢è¡Œç¬¦ï¼ˆåŒ…æ‹¬ç©ºè¡Œï¼‰æ›¿æ¢ä¸ºå•ä¸ªæ¢è¡Œç¬¦
        import re
        content = re.sub(r'\n+', '\n', content)

        return content

    async def organize_and_inject_memories(
        self, event: AstrMessageEvent, request: ProviderRequest
    ):
        """
        æ½œæ„è¯†çš„æ ¸å¿ƒå·¥ä½œï¼šæ•´ç†ç›¸å…³è®°å¿†å–‚ç»™ä¸»æ„è¯†

        å·¥ä½œæµç¨‹ï¼š
        1. ä»è®°å¿†åº“æ‰¾å‡ºç›¸å…³çš„å†…å®¹
        2. ç›´æ¥æ³¨å…¥åŸå§‹å†…å®¹ï¼ˆæé€Ÿå“åº”æ”¹é€ ï¼‰
        3. æŠŠæœ‰ç”¨çš„è®°å¿†åŒ…è£…æˆè®°å¿†åŒ…
        4. å–‚ç»™ä¸»æ„è¯†ï¼ˆLLMï¼‰å¸®åŠ©ä»–æ€è€ƒ

        Args:
            event: ç”¨æˆ·çš„æ¶ˆæ¯ï¼ˆè§¦å‘å›å¿†çš„çº¿ç´¢ï¼‰
            request: å³å°†å‘ç»™ä¸»æ„è¯†çš„è¯·æ±‚ï¼ˆæˆ‘ä»¬è¦å¾€é‡Œé¢å¡è®°å¿†ï¼‰
        """
        session_id = self._get_session_id(event)

        # 1. ä» event.angelheart_context ä¸­è·å–å¯¹è¯å†å²
        chat_records = []
        if hasattr(event, "angelheart_context"):
            try:
                angelheart_data = json.loads(event.angelheart_context)
                chat_records = angelheart_data.get("chat_records", [])
            except (json.JSONDecodeError, KeyError):
                self.logger.warning(
                    f"Failed to parse angelheart_context for session {session_id}"
                )

        # åˆå§‹åŒ– user_list ä¸ºç©ºåˆ—è¡¨
        user_list = []

        # å¦‚æœæ²¡æœ‰å¯¹è¯è®°å½•ï¼Œä½¿ç”¨å½“å‰æ¶ˆæ¯æ–‡æœ¬
        if not chat_records:
            message_text = self._extract_message_text(event)
            query = message_text if message_text else ""
        else:
            # 2. æ ¼å¼åŒ–å¯¹è¯å†å²ä¸ºæŸ¥è¯¢å­—ç¬¦ä¸²
            query, user_list = self.prompt_builder.format_chat_records(chat_records)

        # 3. è¯»å–ä¸»æ„è¯†çš„çŸ­æœŸè®°å¿†ï¼ˆä¾›å…¶ä»–æ¨¡å—å‚è€ƒï¼Œä¸è¿›è¡Œé•¿æœŸè®°å¿†å¬å›ï¼‰
        session_memories = self.session_memory_manager.get_session_memories(session_id)

        # 4. è½¬æ¢ä¸ºJSONæ ¼å¼
        memories_json = self._memories_to_json(session_memories)

        # æ³¨å…¥åˆ°äº‹ä»¶ä¸­ï¼ˆä½¿ç”¨angelmemory_contextï¼‰
        event.angelmemory_context = json.dumps(
            {
                "memories": memories_json,
                "recall_query": query,  # ä¿ç•™æŸ¥è¯¢å­—ç¬¦ä¸²ä¾›åç»­ä½¿ç”¨
                "recall_time": time.time(),
                "session_id": session_id,
                "user_list": user_list,  # å°†æ–°ç”Ÿæˆçš„"ç”¨æˆ·æ¸…å•"å­˜å…¥ä¸Šä¸‹æ–‡
            }
        )

        # å¦‚æœæœªé…ç½® provider_idï¼Œè·³è¿‡è®°å¿†æ•´ç†
        if not self.provider_id:
            self.logger.debug("æœªé…ç½® provider_idï¼Œè·³è¿‡è®°å¿†æ•´ç†")
            return

        # è§£æè®°å¿†ä¸Šä¸‹æ–‡æ•°æ®
        context_data = self._parse_memory_context(event)
        if not context_data:
            self.logger.debug("æ— æ³•è§£æè®°å¿†ä¸Šä¸‹æ–‡æ•°æ®ï¼Œè·³è¿‡è®°å¿†æ•´ç†")
            return

        session_id = context_data["session_id"]
        query = context_data["query"]
        self.logger.debug(f"å¤„ç†ä¼šè¯ {session_id}ï¼ŒæŸ¥è¯¢å†…å®¹: {query}")

        # æ£€ç´¢é•¿æœŸè®°å¿†å’Œå€™é€‰ç¬”è®°
        retrieval_data = self._retrieve_memories_and_notes(event, query)
        long_term_memories = retrieval_data["long_term_memories"]
        candidate_notes = retrieval_data["candidate_notes"]
        core_topic = retrieval_data["core_topic"]

        self.logger.debug(
            f"æ£€ç´¢åˆ° {len(long_term_memories)} æ¡é•¿æœŸè®°å¿†å’Œ {len(candidate_notes)} æ¡å€™é€‰ç¬”è®°"
        )

        try:
            # ç›´æ¥å°†æ£€ç´¢åˆ°çš„é•¿æœŸè®°å¿†å¡«å…¥çŸ­æœŸè®°å¿†çš„ç©ºæ§½ä½
            if long_term_memories and self.memory_system:
                # æ£€æŸ¥çŸ­æœŸè®°å¿†æ˜¯å¦è¿˜æœ‰ç©ºä½ï¼Œæœ‰ç©ºä½æ—¶æ‰å¡«å…¥æ–°è®°å¿†
                current_session_memories = (
                    self.session_memory_manager.get_session_memories(session_id)
                )
                # è·å–å„ç±»å‹è®°å¿†çš„å®¹é‡é…ç½®
                capacity_config = self.session_memory_manager.capacity_config
                capacity_multiplier = self.session_memory_manager.capacity_multiplier

                # æŒ‰ç±»å‹ç»Ÿè®¡å½“å‰è®°å¿†æ•°é‡
                memory_count_by_type = {}
                for memory in current_session_memories:
                    memory_type = memory.memory_type
                    memory_count_by_type[memory_type] = (
                        memory_count_by_type.get(memory_type, 0) + 1
                    )

                # ç­›é€‰å‡ºè¿˜æœ‰ç©ºä½çš„è®°å¿†ç±»å‹å¹¶å¡«å…¥
                memories_to_add = []
                for memory in long_term_memories:
                    memory_type_str = (
                        memory.memory_type.value
                        if hasattr(memory.memory_type, "value")
                        else str(memory.memory_type)
                    )
                    memory_type_key = MemoryConstants.MEMORY_TYPE_MAPPING.get(
                        memory_type_str, memory_type_str.lower()
                    )

                    # è·å–è¯¥ç±»å‹çš„è®°å¿†å®¹é‡
                    base_capacity = getattr(capacity_config, memory_type_key, 0)
                    capacity = int(base_capacity * capacity_multiplier)

                    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ç©ºä½
                    current_count = memory_count_by_type.get(memory_type_key, 0)
                    if current_count < capacity:
                        memories_to_add.append(memory)
                        memory_count_by_type[memory_type_key] = current_count + 1

                # å°†ç­›é€‰åçš„è®°å¿†æ·»åŠ åˆ°çŸ­æœŸè®°å¿†ä¸­
                if memories_to_add:
                    self.session_memory_manager.add_memories_to_session(
                        session_id, memories_to_add
                    )
                    self.logger.debug(
                        "æ½œæ„è¯†ç­›é€‰ï¼š%dæ¡æœ‰ç”¨è®°å¿†è¿›å…¥çŸ­æœŸè®°å¿†", len(memories_to_add)
                    )
                else:
                    self.logger.debug("æ²¡æœ‰ç©ºä½å¯å¡«å…¥æ–°çš„é•¿æœŸè®°å¿†")

            # ç›´æ¥æ³¨å…¥åŸå§‹ç¬”è®°å†…å®¹ï¼ˆä¸ç»è¿‡å°æ¨¡å‹ç­›é€‰ï¼‰
            note_context = ""
            if candidate_notes:
                # æ„å»ºç¬”è®°ä¸Šä¸‹æ–‡ï¼Œé™åˆ¶tokenæ•°é‡
                from ..llm_memory.utils.token_utils import count_tokens

                current_tokens = 0
                selected_notes = []

                for note in candidate_notes:
                    note_content = note.get("content", "")
                    note_tokens = count_tokens(note_content)

                    # æ£€æŸ¥æ˜¯å¦è¶…å‡ºå¤§æ¨¡å‹ç¬”è®°é¢„ç®—
                    if current_tokens + note_tokens <= self.large_model_note_budget:
                        selected_notes.append(note)
                        current_tokens += note_tokens
                    else:
                        break

                # æ„å»ºç¬”è®°ä¸Šä¸‹æ–‡
                if selected_notes:
                    # ä½¿ç”¨æ–°çš„æ–¹æ³•æ„å»ºç¬”è®°ä¸Šä¸‹æ–‡ï¼Œé¿å…æ¨¡å‹è¯¯è§£æ ‡ç­¾ä¸ºå¼•ç”¨
                    note_context_parts = []
                    for note in selected_notes:
                        content = note.get("content", "")
                        tags = note.get("tags", [])

                        # æ¸…ç†ç¬”è®°å†…å®¹ï¼ˆå»é™¤æ‰€æœ‰ç©ºè¡Œï¼‰
                        cleaned_content = self._clean_note_content(content)

                        if tags:
                            # å¦‚æœæœ‰æ ‡ç­¾ï¼Œæ„å»ºæ–°çš„å¼•è¨€æ ¼å¼
                            tags_str = ", ".join(tags)
                            intro_str = f"å…³äº({tags_str})çš„ç¬”è®°ï¼š"
                            note_context_parts.append(f"{intro_str} {cleaned_content}")
                        else:
                            # å¦‚æœæ²¡æœ‰æ ‡ç­¾ï¼Œç›´æ¥æ·»åŠ å†…å®¹
                            note_context_parts.append(cleaned_content)

                    # åˆå¹¶æ‰€æœ‰ç¬”è®°ï¼Œåªåœ¨å¼€å¤´æ·»åŠ ä¸€æ¬¡æ—¶æ•ˆæ€§æé†’
                    time_warning = "[æ³¨æ„ï¼šä»¥ä¸‹ç¬”è®°å†…å®¹å¯èƒ½ä¸å…·å¤‡æ—¶æ•ˆæ€§ï¼Œè¯·å‹¿ä½œä¸ºæœ€æ–°æ¶ˆæ¯çœ‹å¾…]\n"
                    note_context = time_warning + "\n\n".join(note_context_parts)
                    self.logger.debug(
                        f"æ„å»ºäº†åŒ…å« {len(selected_notes)} æ¡ç¬”è®°çš„ä¸Šä¸‹æ–‡ï¼Œå…± {current_tokens} tokens"
                    )

            # ç”Ÿæˆå¹¶ä¼ é€’IDæ˜ å°„è¡¨

            # ä¸ºè®°å¿†å’Œç¬”è®°åˆ†åˆ«ç”Ÿæˆ ID => çŸ­ID çš„æ˜ å°„
            memory_id_mapping = MemoryIDResolver.generate_id_mapping(
                [mem.to_dict() for mem in long_term_memories], "id"
            )
            note_id_mapping = MemoryIDResolver.generate_id_mapping(
                candidate_notes, "id"
            )

            # å°†åŸå§‹ä¸Šä¸‹æ–‡æ•°æ®å­˜å…¥event.angelmemory_contextï¼Œä¾›å¼‚æ­¥åˆ†æä½¿ç”¨
            try:
                angelmemory_context = (
                    json.loads(event.angelmemory_context)
                    if hasattr(event, "angelmemory_context")
                    and event.angelmemory_context
                    else {}
                )
                angelmemory_context["raw_memories"] = [
                    memory.to_dict() if hasattr(memory, "to_dict") else {}
                    for memory in long_term_memories
                ]
                angelmemory_context["raw_notes"] = candidate_notes
                angelmemory_context["core_topic"] = core_topic
                # æŠŠIDæ˜ å°„è¡¨ä¹Ÿä¸€èµ·å­˜è¿›å»
                angelmemory_context["memory_id_mapping"] = memory_id_mapping
                angelmemory_context["note_id_mapping"] = note_id_mapping
                event.angelmemory_context = json.dumps(angelmemory_context)
                self.logger.debug("åŸå§‹ä¸Šä¸‹æ–‡æ•°æ®å·²å­˜å…¥ event.angelmemory_context")

                # æ·»åŠ è°ƒè¯•æ—¥å¿—ï¼šè®°å½•å­˜å‚¨çš„åŸå§‹ä¸Šä¸‹æ–‡æ•°æ®
                self.logger.debug(
                    f"[æ³¨å…¥é˜¶æ®µ] å­˜å‚¨çš„åŸå§‹ä¸Šä¸‹æ–‡æ•°æ® - ä¼šè¯ID: {session_id}"
                )
                self.logger.debug(
                    f"  åŸå§‹è®°å¿†æ•°: {len(angelmemory_context.get('raw_memories', []))}"
                )
                self.logger.debug(
                    f"  åŸå§‹ç¬”è®°æ•°: {len(angelmemory_context.get('raw_notes', []))}"
                )
                self.logger.debug(
                    f"  æ ¸å¿ƒè¯é¢˜: {angelmemory_context.get('core_topic', '')}"
                )

                # æ·»åŠ æ›´è¯¦ç»†çš„ç¬”è®°ä¿¡æ¯æ—¥å¿—
                if angelmemory_context.get("raw_notes"):
                    notes_info = []
                    for i, note in enumerate(
                        angelmemory_context["raw_notes"][:3]
                    ):  # åªæ˜¾ç¤ºå‰3ä¸ªç¬”è®°
                        notes_info.append(
                            f"ç¬”è®°{i + 1}: ID={note.get('id', 'N/A')}, æ ‡ç­¾={note.get('tags', [])}, å†…å®¹é•¿åº¦={len(note.get('content', ''))}"
                        )
                    self.logger.debug(f"  å‰å‡ ä¸ªç¬”è®°ä¿¡æ¯: {notes_info}")
            except Exception as e:
                self.logger.warning(f"ä¿å­˜åŸå§‹ä¸Šä¸‹æ–‡æ•°æ®å¤±è´¥: {e}")

            # æ³¨å…¥è®°å¿†åˆ°è¯·æ±‚ï¼ˆä»çŸ­æœŸè®°å¿†ä¸­è¯»å–å¹¶æ³¨å…¥ï¼‰
            self._inject_memories_to_request(request, session_id, note_context)
            self.logger.debug("è®°å¿†å·²æ³¨å…¥åˆ°è¯·æ±‚ä¸­")

        except Exception as e:
            import traceback

            self.logger.error(
                f"Memory organization failed for session {session_id}: {e}"
            )
            self.logger.error(f"Traceback: {traceback.format_exc()}")

    def _extract_message_text(self, event: AstrMessageEvent) -> Optional[str]:
        """
        ä»äº‹ä»¶ä¸­æå–æ¶ˆæ¯æ–‡æœ¬ (ä½¿ç”¨æ ‡å‡†æ–¹æ³•)

        Args:
            event: æ¶ˆæ¯äº‹ä»¶

        Returns:
            æ¶ˆæ¯æ–‡æœ¬ï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å›None
        """
        try:
            # å‚ç…§ AngelHeart çš„æ­£ç¡®å®ç°
            return event.get_message_outline()
        except Exception as e:
            self.logger.warning(f"Deepæ€ç»´: è°ƒç”¨ event.get_message_outline() å¤±è´¥: {e}")
            return None

    def _get_session_id(self, event: AstrMessageEvent) -> str:
        """è·å–ä¼šè¯IDï¼Œç»Ÿä¸€ä½¿ç”¨ event.unified_msg_origin"""
        try:
            session_id = str(event.unified_msg_origin)
            if not session_id:
                self.logger.error("event.unified_msg_origin ä¸ºç©ºå€¼ï¼Œæ— æ³•å¤„ç†ä¼šè¯ï¼")
                raise ValueError(
                    "Cannot process event with an empty session ID from unified_msg_origin"
                )
            return session_id
        except AttributeError:
            self.logger.error(
                "äº‹ä»¶ä¸­ç¼ºå°‘ 'event.unified_msg_origin' å±æ€§ï¼Œæ— æ³•ç¡®å®šä¼šè¯IDï¼"
            )
            raise

    def _memories_to_json(self, memories: List) -> List[Dict[str, Any]]:
        """
        å°†è®°å¿†å¯¹è±¡ç»Ÿä¸€è½¬æ¢ä¸ºJSONæ ¼å¼

        é€‚ç”¨äºBaseMemoryã€MemoryItemç­‰æ‰€æœ‰è®°å¿†å¯¹è±¡ç±»å‹

        Args:
            memories: è®°å¿†å¯¹è±¡åˆ—è¡¨

        Returns:
            JSONæ ¼å¼çš„è®°å¿†åˆ—è¡¨
        """
        memories_json = []
        for memory in memories:
            # å¤„ç†æšä¸¾ç±»å‹çš„memory_typeï¼ˆå…¼å®¹BaseMemoryå’ŒMemoryItemï¼‰
            memory_type = (
                memory.memory_type.value
                if hasattr(memory.memory_type, "value")
                else memory.memory_type
            )

            memory_data = {
                "id": memory.id,
                "type": memory_type,
                "strength": memory.strength,
                "judgment": memory.judgment,
                "reasoning": memory.reasoning,
                "tags": memory.tags,
            }
            memories_json.append(memory_data)

        return memories_json

    # _resolve_memory_ids æ–¹æ³•å·²ç§»è‡³ MemoryIDResolver ç±»ä¸­

    def _sleep(self):
        """AIç¡è§‰æ•´ç†è®°å¿†ï¼šé‡è¦å†…å®¹åŠ å¼ºï¼Œæ— ç”¨å†…å®¹æ¸…ç†"""
        if not self.is_enabled():
            return

        try:
            # æ£€æŸ¥ memory_system æ˜¯å¦å¯ç”¨
            if self.memory_system is not None:
                self.memory_system.consolidate_memories()
                self.logger.info("è®°å¿†å·©å›ºå®Œæˆ")
            else:
                self.logger.warning(
                    "Memory system is not available, skipping consolidation"
                )
        except Exception as e:
            self.logger.error(f"è®°å¿†å·©å›ºå¤±è´¥: {e}")

    def _start_periodic_sleep(self):
        """å¯åŠ¨å®šæœŸç¡è§‰ï¼šåƒäººä¸€æ ·æŒ‰æ—¶æ•´ç†è®°å¿†"""
        if not self.is_enabled():
            return

        sleep_interval = self.sleep_interval
        if sleep_interval <= 0:
            return

        def sleep_worker():
            # ä½¿ç”¨Event.wait()æ›¿ä»£time.sleep()ï¼Œå¯ä»¥ç«‹å³å“åº”åœæ­¢ä¿¡å·
            while not self._stop_sleep_event.wait(timeout=sleep_interval):
                self._sleep()

        self._sleep_timer = threading.Thread(target=sleep_worker, daemon=True)
        self._sleep_timer.start()
        self.logger.info(f"å¯åŠ¨å®šæœŸç¡çœ ï¼Œé—´éš”: {sleep_interval}ç§’")

    def stop_sleep(self):
        """åœæ­¢å®šæœŸç¡çœ """
        self._stop_sleep_event.set()  # è®¾ç½®äº‹ä»¶ï¼Œé€šçŸ¥çº¿ç¨‹åœæ­¢
        if self._sleep_timer and self._sleep_timer.is_alive():
            self._sleep_timer.join(timeout=5)
        self.logger.info("å®šæœŸç¡çœ å·²åœæ­¢")

    def shutdown(self):
        """å…³é—­æ½œæ„è¯†ç³»ç»Ÿï¼Œè®©AIå¥½å¥½ä¼‘æ¯"""
        self.logger.info("æ­£åœ¨å…³é—­AIçš„æ½œæ„è¯†...")

        # åœæ­¢å®šæœŸç¡è§‰
        self.stop_sleep()

        # åœæ­¢è®°å¿†æ•´ç†ä»»åŠ¡
        from .utils.feedback_queue import stop_feedback_queue

        stop_feedback_queue(timeout=5)

        self.logger.info("AIæ½œæ„è¯†å·²ä¼‘æ¯ï¼Œä¸‹æ¬¡å†è§ï¼")

    async def async_analyze_and_update_memory(self, event: AstrMessageEvent, response):
        """
        å¼‚æ­¥åˆ†æå¹¶æ›´æ–°è®°å¿†ç³»ç»Ÿ

        Args:
            event: æ¶ˆæ¯äº‹ä»¶
            response: ä¸»LLMçš„å“åº”
        """
        # è·å–ä¼šè¯ID
        session_id = self._get_session_id(event)

        self.logger.info(f"[å¼‚æ­¥åˆ†æ] ä»»åŠ¡æäº¤ - ä¼šè¯ID: {session_id}")

        # ç›´æ¥å°†ä»»åŠ¡æäº¤åˆ°åå°é˜Ÿåˆ—ï¼Œä¸ç­‰å¾…LLMå“åº”
        task_payload = {
            "feedback_fn": self._execute_async_analysis_task,
            "session_id": session_id,
            "payload": {
                "event_data": self._serialize_event_data(event),
                "response_data": self._serialize_response_data(response),
                "session_id": session_id,
            },
            # æ·»åŠ è¿™äº›å­—æ®µä»¥ç¡®ä¿ä»»åŠ¡èƒ½è¢«æ­£ç¡®åˆ·æ–°åˆ°é˜Ÿåˆ—ä¸­
            # å³ä½¿æ˜¯ç©ºåˆ—è¡¨ï¼Œä¹Ÿèƒ½ç¡®ä¿ä»»åŠ¡è¢«å¤„ç†
            "useful_memory_ids": [],  # è¿™äº›å­—æ®µæ˜¯ä¸ºäº†ç¡®ä¿ä»»åŠ¡èƒ½è¢«åé¦ˆé˜Ÿåˆ—æ­£ç¡®å¤„ç†
            "new_memories": [],
            "merge_groups": [],
        }

        # æäº¤åˆ°åé¦ˆé˜Ÿåˆ—åå°æ‰§è¡Œ
        get_feedback_queue().submit(task_payload)

        self.logger.debug(f"å¼‚æ­¥è®°å¿†åˆ†æä»»åŠ¡å·²æäº¤åˆ°åå°é˜Ÿåˆ—ï¼Œä¼šè¯ID: {session_id}")

    def _serialize_event_data(self, event: AstrMessageEvent) -> Dict:
        """åºåˆ—åŒ–äº‹ä»¶æ•°æ®ä»¥ä¾¿åœ¨åå°çº¿ç¨‹ä¸­ä½¿ç”¨"""
        try:
            # æå–äº‹ä»¶ä¸­çš„å…³é”®æ•°æ®
            event_data = {
                "angelmemory_context": getattr(event, "angelmemory_context", None),
                "angelheart_context": getattr(event, "angelheart_context", None),
                "unified_msg_origin": getattr(event, "unified_msg_origin", None),
            }

            # å¦‚æœæœ‰ angelmemory_contextï¼Œå°è¯•è§£æå®ƒä»¥ç¡®ä¿æ•°æ®å®Œæ•´æ€§
            if event_data["angelmemory_context"]:
                try:
                    context_json = json.loads(event_data["angelmemory_context"])
                    event_data["angelmemory_context_parsed"] = context_json
                except (json.JSONDecodeError, TypeError):
                    pass

            return event_data
        except Exception as e:
            self.logger.warning(f"åºåˆ—åŒ–äº‹ä»¶æ•°æ®å¤±è´¥: {e}")
            return {}

    def _serialize_response_data(self, response) -> Dict:
        """åºåˆ—åŒ–å“åº”æ•°æ®ä»¥ä¾¿åœ¨åå°çº¿ç¨‹ä¸­ä½¿ç”¨"""
        try:
            # æå–å“åº”ä¸­çš„å…³é”®æ•°æ®
            response_data = {
                "completion_text": getattr(response, "completion_text", str(response))
                if response
                else ""
            }
            return response_data
        except Exception as e:
            self.logger.warning(f"åºåˆ—åŒ–å“åº”æ•°æ®å¤±è´¥: {e}")
            return {"completion_text": ""}

    def _execute_async_analysis_task(
        self, event_data: Dict, response_data: Dict, session_id: str
    ):
        """
        åœ¨åå°çº¿ç¨‹æ‰§è¡Œçš„å¼‚æ­¥åˆ†æä»»åŠ¡

        Args:
            event_data: åºåˆ—åŒ–çš„äº‹ä»¶æ•°æ®
            response_data: åºåˆ—åŒ–çš„å“åº”æ•°æ®
            session_id: ä¼šè¯ID
        """
        try:
            self.logger.info(f"[å¼‚æ­¥åˆ†æ] åå°ä»»åŠ¡æ‰§è¡Œå¼€å§‹ - ä¼šè¯ID: {session_id}")

            # é‡æ„äº‹ä»¶å¯¹è±¡çš„éƒ¨åˆ†æ•°æ®ç”¨äºå¤„ç†
            class SimpleEvent:
                def __init__(self, data):
                    self.angelmemory_context = data.get("angelmemory_context")
                    self.angelheart_context = data.get("angelheart_context")
                    self.unified_msg_origin = data.get("unified_msg_origin")

            event = SimpleEvent(event_data)

            # è·å–åŸå§‹ä¸Šä¸‹æ–‡æ•°æ®
            context_data = self._parse_memory_context(event)
            if not context_data:
                self.logger.debug(
                    f"[åå°ä»»åŠ¡] æ— æ³•è§£æè®°å¿†ä¸Šä¸‹æ–‡æ•°æ®ï¼Œä¼šè¯ID: {session_id}"
                )
                return

            query = context_data["query"]

            # è·å–åŸå§‹è®°å¿†å’Œç¬”è®°æ•°æ®
            raw_memories_data = context_data.get("raw_memories", [])
            raw_notes_data = context_data.get("raw_notes", [])
            core_topic = context_data.get("core_topic", "")

            self.logger.debug(
                f"[åå°ä»»åŠ¡] è§£æä¸Šä¸‹æ–‡æ•°æ®å®Œæˆï¼Œä¼šè¯ID: {session_id}, æŸ¥è¯¢: {query[:50]}..., è®°å¿†æ•°: {len(raw_memories_data)}, ç¬”è®°æ•°: {len(raw_notes_data)}"
            )

            # å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºè®°å¿†å¯¹è±¡
            from ..llm_memory.models.data_models import BaseMemory

            long_term_memories = []
            for memory_dict in raw_memories_data:
                try:
                    memory = BaseMemory.from_dict(memory_dict)
                    if memory:
                        long_term_memories.append(memory)
                except Exception as e:
                    self.logger.warning(f"è½¬æ¢è®°å¿†å¯¹è±¡å¤±è´¥: {e}")

            # è·å–ä¸»LLMçš„æœ€ç»ˆå›ç­”
            response_text = response_data.get("completion_text", "")

            self.logger.debug(f"[åå°ä»»åŠ¡] å‡†å¤‡æ„å»ºæç¤ºè¯ï¼Œä¼šè¯ID: {session_id}")

            # ä»ä¸Šä¸‹æ–‡æ•°æ®ä¸­è·å–IDæ˜ å°„è¡¨
            memory_id_mapping = context_data.get("memory_id_mapping", {})
            note_id_mapping = context_data.get("note_id_mapping", {})

            # æ„å»ºåæ€æç¤ºè¯ï¼ˆä½¿ç”¨æ¨¡å—åŒ–çš„æç¤ºè¯æ„å»ºå™¨ï¼Œç°åœ¨å±•ç¤ºçŸ­IDï¼‰
            prompt = SmallModelPromptBuilder.build_post_hoc_analysis_prompt(
                historical_query=query,
                main_llm_response=response_text,
                raw_memories=long_term_memories,
                raw_notes=raw_notes_data,
                core_topic=core_topic,
                memory_id_mapping=memory_id_mapping,  # ä¼ é€’è®°å¿†IDæ˜ å°„è¡¨
                note_id_mapping=note_id_mapping,  # ä¼ é€’ç¬”è®°IDæ˜ å°„è¡¨
                config=self.config,
            )

            self.logger.debug(
                f"[åå°ä»»åŠ¡] æç¤ºè¯æ„å»ºå®Œæˆï¼Œä¼šè¯ID: {session_id}ï¼Œæç¤ºè¯é•¿åº¦: {len(prompt)}"
            )

            # æ·»åŠ æ›´è¯¦ç»†çš„ç¬”è®°ä¿¡æ¯æ—¥å¿—
            if raw_notes_data:
                notes_info = []
                for i, note in enumerate(raw_notes_data[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ªç¬”è®°
                    notes_info.append(
                        f"ç¬”è®°{i + 1}: ID={note.get('id', 'N/A')}, æ ‡ç­¾={note.get('tags', [])}, å†…å®¹é•¿åº¦={len(note.get('content', ''))}"
                    )
                self.logger.debug(f"  å‰å‡ ä¸ªç¬”è®°ä¿¡æ¯: {notes_info}")

            # è°ƒç”¨å°æ¨¡å‹è¿›è¡Œåˆ†æï¼ˆåœ¨åå°çº¿ç¨‹ä¸­åŒæ­¥è°ƒç”¨ï¼‰
            provider = self.context.get_provider_by_id(self.provider_id)
            if not provider:
                self.logger.error(
                    f"Provider not found: {self.provider_id} for session {session_id}"
                )
                return

            try:
                self.logger.info(f"[å¼‚æ­¥åˆ†æ] å¼€å§‹è°ƒç”¨åˆ†æLLM - ä¼šè¯ID: {session_id}")
                # åœ¨åå°çº¿ç¨‹ä¸­åŒæ­¥è°ƒç”¨ï¼Œä¸ä½¿ç”¨async/await
                llm_response = provider.text_chat(prompt=prompt)

                # ç­‰å¾…å“åº”å®Œæˆ
                if hasattr(llm_response, "__await__"):
                    # å¦‚æœè¿”å›çš„æ˜¯åç¨‹å¯¹è±¡ï¼Œéœ€è¦åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œ
                    import asyncio

                    llm_response = asyncio.run(llm_response)

                self.logger.debug(f"[åå°ä»»åŠ¡] LLMè°ƒç”¨å®Œæˆï¼Œä¼šè¯ID: {session_id}")
            except Exception as e:
                self.logger.warning(
                    f"â±ï¸ LLMè°ƒç”¨å¤±è´¥ for session {session_id}ï¼Œè·³è¿‡è®°å¿†æ•´ç†: {e}"
                )
                return

            if not llm_response or not getattr(llm_response, "completion_text", ""):
                self.logger.error(f"LLM API call failed for session {session_id}")
                return

            # æå–å“åº”æ–‡æœ¬
            response_text = llm_response.completion_text

            # è§£æå®Œæ•´çš„ç»“æ„åŒ–è¾“å‡º
            full_json_data = self.json_parser.extract_json(response_text)
            self.logger.debug(f"Parsed full_json_data: {full_json_data}")

            if not isinstance(full_json_data, dict):
                self.logger.error(
                    f"JSON parsing failed or did not return a dict for session {session_id}"
                )
                return

            # æå– feedback_data
            feedback_data = full_json_data.get("feedback_data", {})

            # IDè§£æï¼šä½¿ç”¨æ˜ å°„è¡¨å°†LLMè¿”å›çš„çŸ­IDç¿»è¯‘å›é•¿ID
            memory_id_mapping = context_data.get("memory_id_mapping", {})
            note_id_mapping = context_data.get("note_id_mapping", {})

            if "useful_memory_ids" in feedback_data:
                # ä½¿ç”¨æ˜ å°„è¡¨å°†çŸ­IDç¿»è¯‘å›é•¿ID
                short_ids = feedback_data.get("useful_memory_ids", [])
                long_ids = [
                    memory_id_mapping.get(short_id, short_id) for short_id in short_ids
                ]
                feedback_data["useful_memory_ids"] = long_ids
            else:
                self.logger.warning(
                    "ğŸ” [DEBUG] feedback_dataä¸­æ²¡æœ‰useful_memory_idså­—æ®µ"
                )

            if not isinstance(feedback_data, dict):
                self.logger.error(
                    f"feedback_data is not a dict, it's {type(feedback_data)}: {feedback_data}"
                )
                feedback_data = {}  # å®‰å…¨é™çº§

            # === æ–°çš„ç®€åŒ–æ¥å£å®ç° ===

            # --- å¼€å§‹æœ€ç»ˆä¿®æ­£ ---

            # 1. ä» feedback_data ä¸­è·å–åŸå§‹çš„ã€æŒ‰ç±»å‹åˆ†ç»„çš„æ–°è®°å¿†å­—å…¸
            new_memories_raw = feedback_data.get("new_memories", {})

            # 2. è°ƒç”¨å·²æœ‰çš„å·¥å…·å‡½æ•°ï¼Œå°†å…¶è½¬æ¢ä¸ºåº•å±‚æœåŠ¡æœŸæœ›çš„"æ‰å¹³åˆ—è¡¨"æ ¼å¼
            new_memories_normalized = MemoryIDResolver.normalize_new_memories_format(
                new_memories_raw, self.logger
            )

            # --- ä¿®æ­£ç»“æŸ ---

            # 3. è°ƒç”¨å°è£…å¥½çš„ feedback æ¥å£ï¼Œå¹¶ä½¿ç”¨"è½¬æ¢å"çš„æ‰å¹³åˆ—è¡¨
            #    (ä»¥åŠæˆ‘ä»¬ä¹‹å‰è®¨è®ºè¿‡çš„ï¼Œè®© feedback è¿”å›æ–°åˆ›å»ºçš„å¯¹è±¡)
            newly_created_memories = []
            if self.memory_system:
                newly_created_memories = self.memory_system.feedback(
                    useful_memory_ids=feedback_data.get("useful_memory_ids", []),
                    new_memories=new_memories_normalized,  # <--- ä½¿ç”¨è½¬æ¢åçš„æ•°æ®
                    merge_groups=feedback_data.get("merge_groups", []),
                )

            # 2. æ›´æ–°çŸ­æœŸè®°å¿†
            # è·å–æœ‰ç”¨çš„æ—§è®°å¿†
            useful_ids = feedback_data.get("useful_memory_ids", [])
            useful_long_term_memories = [
                mem for mem in long_term_memories if mem.id in useful_ids
            ]

            # å°†æœ‰ç”¨çš„æ—§è®°å¿†å’Œå…¨æ–°çš„è®°å¿†åˆå¹¶ï¼Œä¸€èµ·æ”¾å…¥çŸ­æœŸè®°å¿†
            memories_for_session = useful_long_term_memories + newly_created_memories
            if memories_for_session:
                self.session_memory_manager.add_memories_to_session(
                    session_id, memories_for_session
                )
                self.logger.info(
                    "è®°å¿†æ›´æ–°ï¼š %d æ¡è®°å¿†è¿›å…¥çŸ­æœŸè®°å¿† (æœ‰ç”¨æ—§è®°å¿†: %d, æ–°ç”Ÿæˆè®°å¿†: %d)",
                    len(memories_for_session),
                    len(useful_long_term_memories),
                    len(newly_created_memories),
                )

            self.logger.info(
                f"[å¼‚æ­¥åˆ†æ] é•¿æœŸè®°å¿†æ›´æ–°æŒ‡ä»¤å·²å‘é€ - ä¼šè¯ID: {session_id}"
            )

        except Exception as e:
            import traceback

            self.logger.error(f"å¼‚æ­¥è®°å¿†åˆ†æå¤±è´¥ - session={session_id}: {e}")
            self.logger.error(f"Traceback: {traceback.format_exc()}")
