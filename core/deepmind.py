from .soul.soul_state import SoulState
"""
DeepMindæ½œæ„è¯†æ ¸å¿ƒæ¨¡å—

è¿™æ˜¯AIçš„æ½œæ„è¯†ç³»ç»Ÿï¼Œåœ¨åå°é»˜é»˜å¸®ä½ ç®¡ç†è®°å¿†ï¼š
- çœ‹åˆ°æ¶ˆæ¯æ—¶è‡ªåŠ¨å›å¿†ç›¸å…³å†…å®¹
- ç­›é€‰å‡ºæœ‰ç”¨çš„è®°å¿†å–‚ç»™ä¸»æ„è¯†
- å®šæœŸæ•´ç†è®°å¿†ï¼Œè®©é‡è¦å†…å®¹ä¸å®¹æ˜“å¿˜è®°
- å°±åƒäººç¡è§‰æ—¶æ•´ç†è®°å¿†ä¸€æ ·
"""

import time
import json
from typing import List, Dict, Any, Optional
from astrbot.api.event import AstrMessageEvent
from astrbot.api.provider import ProviderRequest
from .utils.memory_id_resolver import MemoryIDResolver
from ..llm_memory import CognitiveService
from ..llm_memory.utils.json_parser import JsonParser
from .session_memory import SessionMemoryManager
from .utils import SmallModelPromptBuilder, MemoryInjector
from .utils.feedback_queue import get_feedback_queue
from .utils.query_processor import get_query_processor
from .config import MemoryConstants

try:
    from astrbot.api import logger
except ImportError:
    import logging

    logger = logging.getLogger(__name__)


class DeepMind:
    """AIçš„æ½œæ„è¯†ç³»ç»Ÿ

    è¿™æ˜¯AIçš„æ½œæ„è¯†ï¼Œé…åˆä¸»æ„è¯†ï¼ˆLLMï¼‰å·¥ä½œï¼š
    - è§‚å¯Ÿé˜¶æ®µï¼šæ³¨æ„ç”¨æˆ·è¯´äº†ä»€ä¹ˆï¼Œå¼€å§‹å›å¿†ç›¸å…³å†…å®¹
    - å›å¿†é˜¶æ®µï¼šä»è®°å¿†åº“é‡Œæ‰¾å‡ºæœ‰ç”¨çš„ä¿¡æ¯
    - åé¦ˆé˜¶æ®µï¼šå¥½è®°æ€§åŠ å¼ºï¼Œåè®°æ€§æ·˜æ±°
    - ç¡çœ é˜¶æ®µï¼šå®šæœŸæ•´ç†è®°å¿†ï¼Œå·©å›ºé‡è¦å†…å®¹

    æ½œæ„è¯†çš„å·¥ä½œæ–¹å¼ï¼š
    1. åªç®¡ä¼šè¯çŠ¶æ€ï¼Œå…·ä½“è®°å¿†å­˜å‚¨äº¤ç»™åº•å±‚ç³»ç»Ÿ
    2. å‡ºé”™äº†ä¹Ÿä¸å½±å“ä½ æ­£å¸¸èŠå¤©
    3. æ²¡æœ‰é…ç½®AIåŠ©æ‰‹æ—¶è‡ªåŠ¨å…³é—­ï¼Œä¸æ¶ˆè€—èµ„æº
    4. åƒäººçš„æ½œè¯†ä¸€æ ·ï¼Œé»˜é»˜å·¥ä½œï¼Œä¸æ‰“æ‰°ä¸»æ„è¯†æ€è€ƒ
    """

    # æ½œæ„è¯†å›å¿†çš„è§„åˆ™
    CHAINED_RECALL_PER_TYPE_LIMIT = 7  # æ¯ç§è®°å¿†æœ€å¤šæƒ³7æ¡ï¼Œé˜²æ­¢ä¿¡æ¯è¿‡è½½
    CHAINED_RECALL_FINAL_LIMIT = 7  # æœ€ç»ˆç»™ä¸»æ„è¯†æœ€å¤š7æ¡è®°å¿†
    NOTE_CANDIDATE_COUNT = 50  # å…ˆæ‰¾50æ¡ç¬”è®°ï¼Œè®©å°AIå¸®å¿™ç­›é€‰æœ‰ç”¨çš„

    def __init__(
        self,
        config,
        context,
        vector_store,
        note_service,
        plugin_context, # æ–°å¢
        provider_id: str = "",
        cognitive_service=None,
    ):
        """
        åˆå§‹åŒ–AIçš„æ½œæ„è¯†ç³»ç»Ÿ

        Args:
            config: é…ç½®ä¿¡æ¯ï¼ˆæ¯”å¦‚å¤šä¹…ç¡ä¸€æ¬¡è§‰æ•´ç†è®°å¿†ï¼‰
            context: èŠå¤©æœºå™¨äººçš„å¤§è„‘ï¼ˆä¸»æ„è¯†ï¼‰
            vector_store: è®°å¿†æ•°æ®åº“ï¼ˆå­˜æ‰€æœ‰é•¿æœŸè®°å¿†çš„åœ°æ–¹ï¼‰
            note_service: ç¬”è®°ç®¡ç†å™¨ï¼ˆé‡è¦ä¿¡æ¯ä¸“é—¨å­˜æ”¾å¤„ï¼‰
            plugin_context: æ’ä»¶ä¸Šä¸‹æ–‡ï¼ˆæ–°å¢ï¼‰
            provider_id: AIåŠ©æ‰‹çš„IDï¼Œæ²¡æœ‰çš„è¯æ½œæ„è¯†å°±ç¡è§‰ä¸å¹²æ´»
            cognitive_service: è®°å¿†ç®¡ç†æœåŠ¡ï¼ˆå¯é€‰ï¼Œå¦‚æœå¤–é¢å·²ç»æœ‰äº†å°±ç›´æ¥ç”¨ï¼‰
        """
        self.config = config
        self.memory_system: Optional[CognitiveService] = (
            cognitive_service  # ä½¿ç”¨æ³¨å…¥çš„å®ä¾‹
        )
        self.note_service = note_service
        self.context = context
        self.vector_store = vector_store
        self.provider_id = provider_id
        self.plugin_context = plugin_context # ä¿å­˜å¼•ç”¨

        # ä»å…¨å±€å®¹å™¨è·å–logger
        self.logger = logger
        self.json_parser = JsonParser()

        # è·å–é…ç½®å€¼
        self.min_message_length = getattr(config, "min_message_length", 5)
        self.short_term_memory_capacity = getattr(
            config, "short_term_memory_capacity", 1.0
        )
        self.sleep_interval = getattr(config, "sleep_interval", 3600)  # é»˜è®¤1å°æ—¶
        self.small_model_note_budget = getattr(config, "small_model_note_budget", 8000)
        self.large_model_note_budget = getattr(config, "large_model_note_budget", 12000)

        # åˆå§‹åŒ–çŸ­æœŸè®°å¿†ç®¡ç†å™¨
        self.session_memory_manager = SessionMemoryManager(
            capacity_multiplier=self.short_term_memory_capacity
        )

        # ç¡çœ çŠ¶æ€ç®¡ç†
        self.last_sleep_time = None  # ä¸Šæ¬¡ç¡çœ æ—¶é—´æˆ³

        # åˆå§‹åŒ–å·¥å…·ç±»
        self.prompt_builder = SmallModelPromptBuilder()
        self.memory_injector = MemoryInjector()
        self.query_processor = get_query_processor()

        # åˆå§‹åŒ–çµé­‚çŠ¶æ€ç®¡ç†å™¨
        try:
            self.soul = SoulState(storage_path=self.plugin_context.get_data_dir() + "/soul_state.json")
        except Exception as e:
            self.logger.error(f"çµé­‚çŠ¶æ€ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.soul = None

        # åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿï¼ˆå¦‚æœæ²¡æœ‰é€šè¿‡ä¾èµ–æ³¨å…¥æä¾›ï¼‰
        self._init_memory_system()

    def _init_memory_system(self) -> None:
        """åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ"""
        # å¦‚æœå·²ç»æœ‰äº†æ³¨å…¥çš„è®¤çŸ¥æœåŠ¡ï¼Œç›´æ¥ä½¿ç”¨
        if self.memory_system is not None:
            return

        # å¦åˆ™åˆ›å»ºæ–°çš„è®¤çŸ¥æœåŠ¡å®ä¾‹ï¼ˆå‘åå…¼å®¹ï¼‰
        try:
            self.memory_system = CognitiveService(vector_store=self.vector_store)

        except Exception as e:
            self.logger.error(f"è®°å¿†ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            self.memory_system = None

    def is_enabled(self) -> bool:
        """æ£€æŸ¥è®°å¿†ç³»ç»Ÿæ˜¯å¦å¯ç”¨"""
        return self.memory_system is not None

    def should_process_message(self, event: AstrMessageEvent) -> bool:
        """
        åˆ¤æ–­è¿™æ¡æ¶ˆæ¯æ˜¯å¦å€¼å¾—è®°ä½

        Args:
            event: ç”¨æˆ·å‘æ¥çš„æ¶ˆæ¯

        Returns:
            True=å€¼å¾—è®°ä½ï¼ŒFalse=ä¸ç”¨è®°
        """
        if not self.is_enabled():
            return False

        # ä»äº‹ä»¶ä¸­æå–æ¶ˆæ¯æ–‡æœ¬
        message_text = self._extract_message_text(event)
        if not message_text:
            return False

        message_text = message_text.strip()

        # æ£€æŸ¥æœ€å°æ¶ˆæ¯é•¿åº¦
        if len(message_text) < self.min_message_length:
            return False

        # å¿½ç•¥çº¯æŒ‡ä»¤æ¶ˆæ¯ï¼ˆä»¥/å¼€å¤´ï¼‰
        if message_text.startswith("/"):
            return False

        return True

    def _parse_memory_context(
        self, event: AstrMessageEvent
    ) -> Optional[Dict[str, Any]]:
        """
        è§£æäº‹ä»¶ä¸­çš„è®°å¿†ä¸Šä¸‹æ–‡æ•°æ®

        Args:
            event: æ¶ˆæ¯äº‹ä»¶

        Returns:
            åŒ…å« session_id, query, user_list çš„å­—å…¸ï¼Œè§£æå¤±è´¥è¿”å› None
        """
        if not hasattr(event, "angelmemory_context"):
            return None

        try:
            context_data = json.loads(event.angelmemory_context)
            return {
                "session_id": context_data["session_id"],
                "query": context_data.get("recall_query", ""),
                "user_list": context_data.get("user_list", []),
                # æ·»åŠ åŸå§‹æ•°æ®å­—æ®µ
                "raw_memories": context_data.get("raw_memories", []),
                "raw_notes": context_data.get("raw_notes", []),
                "core_topic": context_data.get("core_topic", ""),
            }
        except (json.JSONDecodeError, KeyError) as e:
            self.logger.warning(f"è§£æè®°å¿†ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return None

    async def _retrieve_memories_and_notes(
        self, event: AstrMessageEvent, query: str, precompute_vectors: bool = False
    ) -> Dict[str, Any]:
        """
        æ£€ç´¢é•¿æœŸè®°å¿†å’Œå€™é€‰ç¬”è®°

        Args:
            event: æ¶ˆæ¯äº‹ä»¶
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            precompute_vectors: æ˜¯å¦é¢„è®¡ç®—å‘é‡

        Returns:
            åŒ…å« long_term_memories, candidate_notes, note_id_mapping, secretary_decision çš„å­—å…¸
        """
        # 1. é¢„å¤„ç†è®°å¿†æ£€ç´¢æŸ¥è¯¢è¯
        if precompute_vectors:
            memory_query, memory_vector = await self.query_processor.process_query_for_memory_with_vector(query, event)
        else:
            memory_query = self.query_processor.process_query_for_memory(query, event)
            memory_vector = None

        # 1. ä½¿ç”¨é“¾å¼å¬å›ä»é•¿æœŸè®°å¿†æ£€ç´¢ç›¸å…³è®°å¿†
        long_term_memories = []
        if self.memory_system:
            try:
                # ä» angelheart_context è·å–å®ä½“åˆ—è¡¨ (é€šè¿‡ QueryProcessor)
                rag_fields = self.query_processor.extract_rag_fields(event)
                entities = rag_fields.get("entities", [])

                # å®‰å…¨è·å– handlers
                handlers = None
                if hasattr(self.memory_system, 'memory_handler_factory') and self.memory_system.memory_handler_factory:
                    handlers = getattr(self.memory_system.memory_handler_factory, 'handlers', None)

                # åŠ¨æ€è·å–æ£€ç´¢ä¸Šé™
                dynamic_limit = self.CHAINED_RECALL_PER_TYPE_LIMIT
                if self.soul:
                    try:
                        dynamic_limit = self.soul.get_value("RecallDepth")
                        self.logger.info(f"ğŸ§  çµé­‚å›å¿†æ·±åº¦: {dynamic_limit} (E={self.soul.energy['RecallDepth']:.1f})")
                    except Exception as e:
                        self.logger.warning(f"è·å–çµé­‚å‚æ•°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")

                # è°ƒç”¨æ–°çš„ chained_recall
                long_term_memories = await self.memory_system.chained_recall(
                    query=memory_query,
                    entities=entities,
                    per_type_limit=int(dynamic_limit), # åŠ¨æ€æ§åˆ¶
                    final_limit=int(dynamic_limit * 1.5),
                    memory_handlers=handlers,
                    event=event,
                    vector=memory_vector,
                )

                # æƒ…ç»ªå…±é¸£ï¼šæ—§è®°å¿†å†²å‡»å½“å‰çŠ¶æ€
                if self.soul:
                    for mem in long_term_memories:
                        if hasattr(mem, "state_snapshot"):
                            self.soul.resonate(mem.state_snapshot)

            except Exception as e:
                self.logger.error(f"é“¾å¼å¬å›å¤±è´¥ï¼Œè·³è¿‡è®°å¿†æ£€ç´¢: {e}")
                long_term_memories = []

        # 2. è·å– secretary_decision ä¿¡æ¯
        secretary_decision = {}
        try:
            if hasattr(event, "angelheart_context"):
                angelheart_data = json.loads(event.angelheart_context)
                secretary_decision = angelheart_data.get("secretary_decision", {})
        except (json.JSONDecodeError, KeyError):
            self.logger.error("æ— æ³•è·å– secretary_decision ä¿¡æ¯")

        # 3. ä½¿ç”¨ç»Ÿä¸€çš„RAGå­—æ®µè¿›è¡Œç¬”è®°æ£€ç´¢
        # ç›´æ¥ä½¿ç”¨åŸå§‹queryï¼Œè®©QueryProcessorç»Ÿä¸€å¤„ç†RAGå­—æ®µ
        if precompute_vectors:
            note_query, note_vector = await self.query_processor.process_query_for_notes_with_vector(query, event)
        else:
            note_query = self.query_processor.process_query_for_notes(query, event)
            note_vector = None

        # 4. è·å–å€™é€‰ç¬”è®°ï¼ˆç”¨äºå°æ¨¡å‹çš„é€‰æ‹©ï¼‰
        candidate_notes = []
        if self.note_service:
            candidate_notes = await self.note_service.search_notes_by_token_limit(
                query=note_query,
                max_tokens=self.small_model_note_budget,
                recall_count=self.NOTE_CANDIDATE_COUNT,
                vector=note_vector  # ä¼ é€’é¢„è®¡ç®—å‘é‡
            )

        # 5. åˆ›å»ºçŸ­IDåˆ°å®Œæ•´IDçš„æ˜ å°„ï¼ˆç”¨äºåç»­ä¸Šä¸‹æ–‡æ‰©å±•ï¼‰
        note_id_mapping = {}
        for note in candidate_notes:
            note_id = note.get("id")
            if note_id:
                short_id = MemoryIDResolver.generate_short_id(note_id)
                note_id_mapping[short_id] = note_id

        # 6. åˆ›å»ºçŸ­æœŸè®°å¿†IDæ˜ å°„è¡¨ï¼ˆç”¨äºè§£æ useful_memory_idsï¼‰
        memory_id_mapping = {}
        if long_term_memories:
            memory_id_mapping = MemoryIDResolver.generate_id_mapping(
                [memory.to_dict() for memory in long_term_memories], "id"
            )

        return {
            "long_term_memories": long_term_memories,
            "candidate_notes": candidate_notes,
            "note_id_mapping": note_id_mapping,
            "memory_id_mapping": memory_id_mapping,
            "secretary_decision": secretary_decision,
            "core_topic": secretary_decision.get("topic", ""),
        }



    def _inject_memories_to_request(
        self, request: ProviderRequest, session_id: str, note_context: str
    ) -> None:
        """
        å°†è®°å¿†æ³¨å…¥åˆ°LLMè¯·æ±‚ä¸­

        Args:
            request: LLMè¯·æ±‚å¯¹è±¡
            session_id: ä¼šè¯ID
            note_context: ç¬”è®°ä¸Šä¸‹æ–‡
        """

        # 1. ä»çŸ­æœŸè®°å¿†æ¨é€ç»™ä¸»æ„è¯†ï¼ˆæ½œæ„è¯†ç­›é€‰åçš„ç²¾é€‰è®°å¿†ï¼‰
        short_term_memories = self.session_memory_manager.get_session_memories(
            session_id
        )

        memory_context = self.memory_injector.format_session_memories_for_prompt(
            short_term_memories
        )

        # 2. åˆå¹¶è®°å¿†å’Œç¬”è®°ä¸Šä¸‹æ–‡
        if memory_context or note_context:
            # æ³¨å…¥è®°å¿†å†…å®¹ä½œä¸ºç”¨æˆ·æ¶ˆæ¯
            if memory_context:
                request.contexts.append({
                    "role": "user",
                    "content": f"[RAG-è®°å¿†] ç›¸å…³è®°å¿†å‚è€ƒ:\n{memory_context}"
                })

            # æ³¨å…¥ç¬”è®°å†…å®¹ä½œä¸ºç”¨æˆ·æ¶ˆæ¯
            if note_context:
                request.contexts.append({
                    "role": "user",
                    "content": f"[RAG-ç¬”è®°] ç›¸å…³ç¬”è®°å‚è€ƒ:\n{note_context}"
                })

        else:
            pass

    async def _update_memory_system(
        self, feedback_data: Dict[str, Any], long_term_memories: List, session_id: str
    ) -> None:
        """
        æ›´æ–°çŸ­æœŸè®°å¿†å¹¶å°†é•¿æœŸåé¦ˆä»»åŠ¡åŠ å…¥åå°é˜Ÿåˆ—

        Args:
            feedback_data: LLMåé¦ˆæ•°æ®
            long_term_memories: é•¿æœŸè®°å¿†åˆ—è¡¨
            session_id: ä¼šè¯ID
        """
        useful_memory_ids = feedback_data.get("useful_memory_ids", [])
        new_memories_raw = feedback_data.get("new_memories", {})
        merge_groups_raw = feedback_data.get("merge_groups", [])

        # 1. å¤„ç†æœ‰ç”¨çš„æ—§è®°å¿†
        useful_long_term_memories = []
        if useful_memory_ids:
            memory_map = {memory.id: memory for memory in long_term_memories}
            useful_long_term_memories = [
                memory_map[memory_id]
                for memory_id in useful_memory_ids
                if memory_id in memory_map
            ]

        # 2. å¤„ç†æ–°ç”Ÿæˆçš„è®°å¿†
        new_memories_normalized = MemoryIDResolver.normalize_new_memories_format(
            new_memories_raw, self.logger
        )
        new_memory_objects = []
        if new_memories_normalized:
            from ..llm_memory.models.data_models import BaseMemory, MemoryType

            for mem_dict in new_memories_normalized:
                try:
                    # åˆ›å»ºä¸€ä¸ªå­—å…¸å‰¯æœ¬ä»¥è¿›è¡Œä¿®æ”¹
                    init_data = mem_dict.copy()

                    # å°† 'type' é”®é‡å‘½åä¸º 'memory_type' å¹¶è½¬æ¢ä¸ºæšä¸¾ç±»å‹
                    if "type" in init_data:
                        init_data["memory_type"] = MemoryType(init_data.pop("type"))

                    # ç°åœ¨ï¼Œinit_data ä¸­çš„é”®ä¸æ„é€ å‡½æ•°å®Œå…¨åŒ¹é…
                    new_memory_objects.append(BaseMemory(**init_data))
                except Exception as e:
                    self.logger.warning(f"ä¸ºæ–°è®°å¿†åˆ›å»ºBaseMemoryå¯¹è±¡å¤±è´¥: {e}")

        # 3. æ›´æ–°çŸ­æœŸè®°å¿†ï¼šæ·»åŠ æ–°è®°å¿†ï¼Œè¯„ä¼°ç°æœ‰è®°å¿†ï¼Œæ¸…ç†æ­»äº¡è®°å¿†
        useful_memory_ids = [memory.id for memory in useful_long_term_memories]
        self.session_memory_manager.update_session_memories(
            session_id, new_memory_objects, useful_memory_ids
        )

        # 5. åå°å¼‚æ­¥å¤„ç†é•¿æœŸè®°å¿†åé¦ˆ
        merge_groups = MemoryIDResolver.normalize_merge_groups_format(merge_groups_raw)

        if useful_memory_ids or new_memories_normalized or merge_groups:
            task_payload = {
                "feedback_fn": self._execute_feedback_task,
                "session_id": session_id,
                # å°†æ‰€æœ‰æ•°æ®éƒ½æ”¾åœ¨é¡¶å±‚ï¼Œä¸ 'feedback_fn' åŒçº§
                "useful_memory_ids": list(useful_memory_ids),
                "new_memories": new_memories_normalized,
                "merge_groups": merge_groups,
                # 'payload' å­—æ®µå¯ä»¥ä¿ç•™å¹¶ä¼ å…¥ session_idï¼Œå› ä¸º _execute_feedback_task ä¼šç”¨åˆ°
                "payload": {"session_id": session_id},
            }
            await get_feedback_queue().submit(task_payload)
        else:
            pass

    async def _execute_feedback_task(
        self,
        useful_memory_ids: List[str],
        new_memories: List[Dict[str, Any]],
        merge_groups: List[List[str]],
        session_id: str,
    ) -> None:
        """å¼‚æ­¥æ‰§è¡Œçš„é•¿æœŸè®°å¿†åé¦ˆã€‚"""

        # æ£€æŸ¥ memory_system æ˜¯å¦å¯ç”¨
        if self.memory_system is not None:
            # ç›´æ¥å¼‚æ­¥è°ƒç”¨
            await self.memory_system.feedback(
                useful_memory_ids=useful_memory_ids,
                new_memories=new_memories,
                merge_groups=merge_groups,
            )
        else:
            self.logger.error("è®°å¿†ç³»ç»Ÿä¸å¯ç”¨ï¼Œè·³è¿‡åé¦ˆ")

    def _clean_note_content(self, content: str) -> str:
        """
        æ¸…ç†ç¬”è®°å†…å®¹ï¼Œä¿ç•™å•ä¸ªæ¢è¡Œç¬¦ï¼Œå»é™¤åŒæ¢è¡Œç¬¦

        Args:
            content: åŸå§‹ç¬”è®°å†…å®¹

        Returns:
            æ¸…ç†åçš„ç¬”è®°å†…å®¹ï¼ˆä¿ç•™\nï¼Œå»é™¤\n\nï¼‰
        """
        # å»é™¤é¦–å°¾ç©ºç™½
        content = content.strip()

        # å°†æ‰€æœ‰è¿ç»­çš„æ¢è¡Œç¬¦ï¼ˆåŒ…æ‹¬ç©ºè¡Œï¼‰æ›¿æ¢ä¸ºå•ä¸ªæ¢è¡Œç¬¦
        import re
        content = re.sub(r'\n+', '\n', content)

        return content

    async def organize_and_inject_memories(
        self, event: AstrMessageEvent, request: ProviderRequest
    ):
        """
        æ½œæ„è¯†çš„æ ¸å¿ƒå·¥ä½œï¼šæ•´ç†ç›¸å…³è®°å¿†å–‚ç»™ä¸»æ„è¯†

        å·¥ä½œæµç¨‹ï¼š
        1. ä»è®°å¿†åº“æ‰¾å‡ºç›¸å…³çš„å†…å®¹
        2. ç›´æ¥æ³¨å…¥åŸå§‹å†…å®¹ï¼ˆæé€Ÿå“åº”æ”¹é€ ï¼‰
        3. æŠŠæœ‰ç”¨çš„è®°å¿†åŒ…è£…æˆè®°å¿†åŒ…
        4. å–‚ç»™ä¸»æ„è¯†ï¼ˆLLMï¼‰å¸®åŠ©ä»–æ€è€ƒ

        Args:
            event: ç”¨æˆ·çš„æ¶ˆæ¯ï¼ˆè§¦å‘å›å¿†çš„çº¿ç´¢ï¼‰
            request: å³å°†å‘ç»™ä¸»æ„è¯†çš„è¯·æ±‚ï¼ˆæˆ‘ä»¬è¦å¾€é‡Œé¢å¡è®°å¿†ï¼‰
        """
        session_id = self._get_session_id(event)

        # 0. åŠ¨æ€æ³¨å…¥ LLM å‚æ•° (åŸºäºçµé­‚çŠ¶æ€)
        if hasattr(self, "soul") and self.soul:
            try:
                # è·å–åŠ¨æ€å‚æ•°
                dynamic_temp = self.soul.get_value("Creativity")
                dynamic_tokens = int(self.soul.get_value("ExpressionDesire"))

                # æ³¨å…¥åˆ°è¯·æ±‚ä¸­ (å°è¯•ä½¿ç”¨ extension å­—æ®µï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º)
                if not hasattr(request, "extension"):
                    request.extension = {}

                # ç¡®ä¿ extension æ˜¯å­—å…¸
                if request.extension is None:
                    request.extension = {}

                request.extension.update({
                    "temperature": dynamic_temp,
                    "max_tokens": dynamic_tokens
                })

                self.logger.info(f"ğŸ‘» çµé­‚å‚æ•°æ³¨å…¥: Temp={dynamic_temp}, MaxTokens={dynamic_tokens}")
            except Exception as e:
                self.logger.warning(f"çµé­‚å‚æ•°æ³¨å…¥å¤±è´¥: {e}")

        # 1. ä» event.angelheart_context ä¸­è·å–å¯¹è¯å†å²
        chat_records = []
        if hasattr(event, "angelheart_context"):
            try:
                angelheart_data = json.loads(event.angelheart_context)
                chat_records = angelheart_data.get("chat_records", [])
            except (json.JSONDecodeError, KeyError):
                self.logger.error(
                    f"ä¸ºä¼šè¯ {session_id} è§£æ angelheart_context å¤±è´¥"
                )

        # åˆå§‹åŒ– user_list ä¸ºç©ºåˆ—è¡¨
        user_list = []

        # å¦‚æœæ²¡æœ‰å¯¹è¯è®°å½•ï¼Œä½¿ç”¨å½“å‰æ¶ˆæ¯æ–‡æœ¬
        if not chat_records:
            message_text = self._extract_message_text(event)
            query = message_text if message_text else ""
        else:
            # 2. æ ¼å¼åŒ–å¯¹è¯å†å²ä¸ºæŸ¥è¯¢å­—ç¬¦ä¸²
            query, user_list = self.prompt_builder.format_chat_records(chat_records)

        # 3. è¯»å–ä¸»æ„è¯†çš„çŸ­æœŸè®°å¿†ï¼ˆä¾›å…¶ä»–æ¨¡å—å‚è€ƒï¼Œä¸è¿›è¡Œé•¿æœŸè®°å¿†å¬å›ï¼‰
        session_memories = self.session_memory_manager.get_session_memories(session_id)

        # 4. è½¬æ¢ä¸ºJSONæ ¼å¼
        memories_json = self._memories_to_json(session_memories)

        # æ³¨å…¥åˆ°äº‹ä»¶ä¸­ï¼ˆä½¿ç”¨angelmemory_contextï¼‰
        event.angelmemory_context = json.dumps(
            {
                "memories": memories_json,
                "recall_query": query,  # ä¿ç•™æŸ¥è¯¢å­—ç¬¦ä¸²ä¾›åç»­ä½¿ç”¨
                "recall_time": time.time(),
                "session_id": session_id,
                "user_list": user_list,  # å°†æ–°ç”Ÿæˆçš„"ç”¨æˆ·æ¸…å•"å­˜å…¥ä¸Šä¸‹æ–‡
            }
        )

        # å¦‚æœæœªé…ç½® provider_idï¼Œè·³è¿‡è®°å¿†æ•´ç†
        if not self.provider_id:
            return

        # è§£æè®°å¿†ä¸Šä¸‹æ–‡æ•°æ®
        context_data = self._parse_memory_context(event)
        if not context_data:
            return

        session_id = context_data["session_id"]
        query = context_data["query"]

        # æ ¸å¿ƒä¿®å¤ï¼šå°† plugin_context é™„åŠ åˆ° event å¯¹è±¡
        event.plugin_context = self.plugin_context

        # æ£€ç´¢é•¿æœŸè®°å¿†å’Œå€™é€‰ç¬”è®°
        retrieval_data = await self._retrieve_memories_and_notes(event, query, precompute_vectors=True)
        long_term_memories = retrieval_data["long_term_memories"]
        candidate_notes = retrieval_data["candidate_notes"]
        core_topic = retrieval_data["core_topic"]


        try:
            # ç›´æ¥å°†æ£€ç´¢åˆ°çš„é•¿æœŸè®°å¿†å¡«å…¥çŸ­æœŸè®°å¿†ï¼Œç”±session_memoryæŒ‰ç”Ÿå‘½å€¼æ·˜æ±°
            if long_term_memories and self.memory_system:
                self.session_memory_manager.add_memories_to_session(
                    session_id, long_term_memories
                )

            # ç›´æ¥æ³¨å…¥åŸå§‹ç¬”è®°å†…å®¹ï¼ˆä¸ç»è¿‡å°æ¨¡å‹ç­›é€‰ï¼‰
            note_context = ""
            if candidate_notes:
                # æ„å»ºç¬”è®°ä¸Šä¸‹æ–‡ï¼Œé™åˆ¶tokenæ•°é‡
                from ..llm_memory.utils.token_utils import count_tokens

                current_tokens = 0
                selected_notes = []

                for note in candidate_notes:
                    note_content = note.get("content", "")
                    note_tokens = count_tokens(note_content)

                    # æ£€æŸ¥æ˜¯å¦è¶…å‡ºå¤§æ¨¡å‹ç¬”è®°é¢„ç®—
                    if current_tokens + note_tokens <= self.large_model_note_budget:
                        selected_notes.append(note)
                        current_tokens += note_tokens
                    else:
                        break

                # æ„å»ºç¬”è®°ä¸Šä¸‹æ–‡
                if selected_notes:
                    # ä½¿ç”¨æ–°çš„æ–¹æ³•æ„å»ºç¬”è®°ä¸Šä¸‹æ–‡ï¼Œé¿å…æ¨¡å‹è¯¯è§£æ ‡ç­¾ä¸ºå¼•ç”¨
                    note_context_parts = []
                    for note in selected_notes:
                        content = note.get("content", "")
                        tags = note.get("tags", [])

                        # æ¸…ç†ç¬”è®°å†…å®¹ï¼ˆå»é™¤æ‰€æœ‰ç©ºè¡Œï¼‰
                        cleaned_content = self._clean_note_content(content)

                        if tags:
                            # å¦‚æœæœ‰æ ‡ç­¾ï¼Œæ„å»ºæ–°çš„å¼•è¨€æ ¼å¼
                            tags_str = ", ".join(tags)
                            intro_str = f"å…³äº({tags_str})çš„ç¬”è®°ï¼š"
                            note_context_parts.append(f"{intro_str} {cleaned_content}")
                        else:
                            # å¦‚æœæ²¡æœ‰æ ‡ç­¾ï¼Œç›´æ¥æ·»åŠ å†…å®¹
                            note_context_parts.append(cleaned_content)

                    # åˆå¹¶æ‰€æœ‰ç¬”è®°ï¼Œåªåœ¨å¼€å¤´æ·»åŠ ä¸€æ¬¡æ—¶æ•ˆæ€§æé†’
                    time_warning = "[æ³¨æ„ï¼šä»¥ä¸‹ç¬”è®°å†…å®¹å¯èƒ½ä¸å…·å¤‡æ—¶æ•ˆæ€§ï¼Œè¯·å‹¿ä½œä¸ºæœ€æ–°æ¶ˆæ¯çœ‹å¾…]\n"
                    note_context = time_warning + "\n\n".join(note_context_parts)

            # ç”Ÿæˆå¹¶ä¼ é€’IDæ˜ å°„è¡¨

            # ä¸ºè®°å¿†å’Œç¬”è®°åˆ†åˆ«ç”Ÿæˆ ID => çŸ­ID çš„æ˜ å°„
            memory_id_mapping = MemoryIDResolver.generate_id_mapping(
                [mem.to_dict() for mem in long_term_memories], "id"
            )
            note_id_mapping = MemoryIDResolver.generate_id_mapping(
                candidate_notes, "id"
            )

            # å°†åŸå§‹ä¸Šä¸‹æ–‡æ•°æ®å­˜å…¥event.angelmemory_contextï¼Œä¾›å¼‚æ­¥åˆ†æä½¿ç”¨
            try:
                angelmemory_context = (
                    json.loads(event.angelmemory_context)
                    if hasattr(event, "angelmemory_context")
                    and event.angelmemory_context
                    else {}
                )
                angelmemory_context["raw_memories"] = [
                    memory.to_dict() if hasattr(memory, "to_dict") else {}
                    for memory in long_term_memories
                ]
                angelmemory_context["raw_notes"] = candidate_notes
                angelmemory_context["core_topic"] = core_topic
                # æŠŠIDæ˜ å°„è¡¨ä¹Ÿä¸€èµ·å­˜è¿›å»
                angelmemory_context["memory_id_mapping"] = memory_id_mapping
                angelmemory_context["note_id_mapping"] = note_id_mapping
                event.angelmemory_context = json.dumps(angelmemory_context)
            except Exception as e:
                self.logger.error(f"ä¿å­˜åŸå§‹ä¸Šä¸‹æ–‡æ•°æ®å¤±è´¥: {e}")

            # æ³¨å…¥è®°å¿†åˆ°è¯·æ±‚ï¼ˆä»çŸ­æœŸè®°å¿†ä¸­è¯»å–å¹¶æ³¨å…¥ï¼‰
            self._inject_memories_to_request(request, session_id, note_context)

        except Exception as e:
            import traceback

            self.logger.error(
                f"ä¼šè¯ {session_id} çš„è®°å¿†ç»„ç»‡å¤±è´¥: {e}"
            )
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _extract_message_text(self, event: AstrMessageEvent) -> Optional[str]:
        """
        ä»äº‹ä»¶ä¸­æå–æ¶ˆæ¯æ–‡æœ¬ (ä½¿ç”¨æ ‡å‡†æ–¹æ³•)

        Args:
            event: æ¶ˆæ¯äº‹ä»¶

        Returns:
            æ¶ˆæ¯æ–‡æœ¬ï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å›None
        """
        try:
            # å‚ç…§ AngelHeart çš„æ­£ç¡®å®ç°
            return event.get_message_outline()
        except Exception as e:
            self.logger.error(f"æ½œæ„è¯†: è°ƒç”¨ event.get_message_outline() å¤±è´¥: {e}")
            return None

    def _get_session_id(self, event: AstrMessageEvent) -> str:
        """è·å–ä¼šè¯IDï¼Œç»Ÿä¸€ä½¿ç”¨ event.unified_msg_origin"""
        try:
            session_id = str(event.unified_msg_origin)
            if not session_id:
                self.logger.error("event.unified_msg_origin ä¸ºç©ºå€¼ï¼Œæ— æ³•å¤„ç†ä¼šè¯ï¼")
                raise ValueError(
                    "Cannot process event with an empty session ID from unified_msg_origin"
                )
            return session_id
        except AttributeError:
            self.logger.error(
                "äº‹ä»¶ä¸­ç¼ºå°‘ 'event.unified_msg_origin' å±æ€§ï¼Œæ— æ³•ç¡®å®šä¼šè¯IDï¼"
            )
            raise

    def _memories_to_json(self, memories: List) -> List[Dict[str, Any]]:
        """
        å°†è®°å¿†å¯¹è±¡ç»Ÿä¸€è½¬æ¢ä¸ºJSONæ ¼å¼

        é€‚ç”¨äºBaseMemoryã€MemoryItemç­‰æ‰€æœ‰è®°å¿†å¯¹è±¡ç±»å‹

        Args:
            memories: è®°å¿†å¯¹è±¡åˆ—è¡¨

        Returns:
            JSONæ ¼å¼çš„è®°å¿†åˆ—è¡¨
        """
        memories_json = []
        for memory in memories:
            # å¤„ç†æšä¸¾ç±»å‹çš„memory_typeï¼ˆå…¼å®¹BaseMemoryå’ŒMemoryItemï¼‰
            memory_type = (
                memory.memory_type.value
                if hasattr(memory.memory_type, "value")
                else memory.memory_type
            )

            memory_data = {
                "id": memory.id,
                "type": memory_type,
                "strength": memory.strength,
                "judgment": memory.judgment,
                "reasoning": memory.reasoning,
                "tags": memory.tags,
            }
            memories_json.append(memory_data)

        return memories_json

    # _resolve_memory_ids æ–¹æ³•å·²ç§»è‡³ MemoryIDResolver ç±»ä¸­

    async def check_and_sleep_if_needed(self, sleep_interval: int) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦ç¡çœ ï¼Œå¦‚æœéœ€è¦åˆ™è§¦å‘ç¡çœ 

        Args:
            sleep_interval: ç¡çœ é—´éš”ï¼ˆç§’ï¼‰ï¼Œ0è¡¨ç¤ºç¦ç”¨ç¡çœ 

        Returns:
            bool: æ˜¯å¦æ‰§è¡Œäº†ç¡çœ 
        """
        # å¦‚æœç¡çœ é—´éš”ä¸º0ï¼Œè¡¨ç¤ºç¦ç”¨ç¡çœ 
        if sleep_interval <= 0:
            return False

        import time

        current_time = time.time()

        # é¦–æ¬¡è¿è¡Œï¼Œç«‹å³ç¡çœ 
        if self.last_sleep_time is None:
            await self._sleep()
            self.last_sleep_time = current_time
            return True

        # è®¡ç®—è·ç¦»ä¸Šæ¬¡ç¡çœ çš„æ—¶é—´
        time_since_last_sleep = current_time - self.last_sleep_time

        # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ç¡çœ é—´éš”
        if time_since_last_sleep >= sleep_interval:
            await self._sleep()
            self.last_sleep_time = current_time
            return True
        else:
            # æœªåˆ°ç¡çœ æ—¶é—´
            return False

    async def _sleep(self):
        """AIç¡è§‰æ•´ç†è®°å¿†ï¼šé‡è¦å†…å®¹åŠ å¼ºï¼Œæ— ç”¨å†…å®¹æ¸…ç†"""
        if not self.is_enabled():
            return

        import time

        start_time = time.time()

        try:
            # æ£€æŸ¥ memory_system æ˜¯å¦å¯ç”¨
            if self.memory_system is not None:
                await self.memory_system.consolidate_memories()
                elapsed_time = time.time() - start_time
            else:
                self.logger.error(
                    "è®°å¿†ç³»ç»Ÿä¸å¯ç”¨ï¼Œè·³è¿‡å·©å›º"
                )
        except Exception as e:
            elapsed_time = time.time() - start_time
            self.logger.error(f"è®°å¿†å·©å›ºå¤±è´¥ï¼ˆè€—æ—¶ {elapsed_time:.2f} ç§’ï¼‰: {e}")

    def shutdown(self):
        """å…³é—­æ½œæ„è¯†ç³»ç»Ÿï¼Œè®©AIå¥½å¥½ä¼‘æ¯"""

        # åœæ­¢è®°å¿†æ•´ç†ä»»åŠ¡
        from .utils.feedback_queue import stop_feedback_queue

        stop_feedback_queue()

    async def async_analyze_and_update_memory(self, event: AstrMessageEvent, response):
        """
        å¼‚æ­¥åˆ†æå¹¶æ›´æ–°è®°å¿†ç³»ç»Ÿ

        Args:
            event: æ¶ˆæ¯äº‹ä»¶
            response: ä¸»LLMçš„å“åº”
        """
        # è·å–ä¼šè¯ID
        session_id = self._get_session_id(event)

        # ç›´æ¥å°†ä»»åŠ¡æäº¤åˆ°åå°é˜Ÿåˆ—ï¼Œä¸ç­‰å¾…LLMå“åº”
        task_payload = {
            "feedback_fn": self._execute_async_analysis_task,
            "session_id": session_id,
            "payload": {
                "event_data": self._serialize_event_data(event),
                "response_data": self._serialize_response_data(response),
                "session_id": session_id,
            },
            # æ·»åŠ è¿™äº›å­—æ®µä»¥ç¡®ä¿ä»»åŠ¡èƒ½è¢«æ­£ç¡®åˆ·æ–°åˆ°é˜Ÿåˆ—ä¸­
            # å³ä½¿æ˜¯ç©ºåˆ—è¡¨ï¼Œä¹Ÿèƒ½ç¡®ä¿ä»»åŠ¡è¢«å¤„ç†
            "useful_memory_ids": [],  # è¿™äº›å­—æ®µæ˜¯ä¸ºäº†ç¡®ä¿ä»»åŠ¡èƒ½è¢«åé¦ˆé˜Ÿåˆ—æ­£ç¡®å¤„ç†
            "new_memories": [],
            "merge_groups": [],
        }

        # æäº¤åˆ°åé¦ˆé˜Ÿåˆ—åå°æ‰§è¡Œ
        await get_feedback_queue().submit(task_payload)

    def _serialize_event_data(self, event: AstrMessageEvent) -> Dict:
        """åºåˆ—åŒ–äº‹ä»¶æ•°æ®ä»¥ä¾¿åœ¨åå°çº¿ç¨‹ä¸­ä½¿ç”¨"""
        try:
            # æå–äº‹ä»¶ä¸­çš„å…³é”®æ•°æ®
            event_data = {
                "angelmemory_context": getattr(event, "angelmemory_context", None),
                "angelheart_context": getattr(event, "angelheart_context", None),
                "unified_msg_origin": getattr(event, "unified_msg_origin", None),
            }

            # å¦‚æœæœ‰ angelmemory_contextï¼Œå°è¯•è§£æå®ƒä»¥ç¡®ä¿æ•°æ®å®Œæ•´æ€§
            if event_data["angelmemory_context"]:
                try:
                    context_json = json.loads(event_data["angelmemory_context"])
                    event_data["angelmemory_context_parsed"] = context_json
                except (json.JSONDecodeError, TypeError):
                    pass

            return event_data
        except Exception as e:
            self.logger.error(f"åºåˆ—åŒ–äº‹ä»¶æ•°æ®å¤±è´¥: {e}")
            return {}

    def _serialize_response_data(self, response) -> Dict:
        """åºåˆ—åŒ–å“åº”æ•°æ®ä»¥ä¾¿åœ¨åå°çº¿ç¨‹ä¸­ä½¿ç”¨"""
        try:
            # æå–å“åº”ä¸­çš„å…³é”®æ•°æ®
            response_data = {
                "completion_text": getattr(response, "completion_text", str(response))
                if response
                else ""
            }
            return response_data
        except Exception as e:
            self.logger.error(f"åºåˆ—åŒ–å“åº”æ•°æ®å¤±è´¥: {e}")
            return {"completion_text": ""}

    async def _execute_async_analysis_task(
        self, event_data: Dict, response_data: Dict, session_id: str
    ):
        """
        å¼‚æ­¥æ‰§è¡Œçš„è®°å¿†åˆ†æä»»åŠ¡

        Args:
            event_data: åºåˆ—åŒ–çš„äº‹ä»¶æ•°æ®
            response_data: åºåˆ—åŒ–çš„å“åº”æ•°æ®
            session_id: ä¼šè¯ID
        """
        try:
            # é‡æ„äº‹ä»¶å¯¹è±¡çš„éƒ¨åˆ†æ•°æ®ç”¨äºå¤„ç†
            class SimpleEvent:
                def __init__(self, data):
                    self.angelmemory_context = data.get("angelmemory_context")
                    self.angelheart_context = data.get("angelheart_context")
                    self.unified_msg_origin = data.get("unified_msg_origin")

            event = SimpleEvent(event_data)

            # è·å–åŸå§‹ä¸Šä¸‹æ–‡æ•°æ®
            context_data = self._parse_memory_context(event)
            if not context_data:
                return

            query = context_data["query"]

            # è·å–åŸå§‹è®°å¿†å’Œç¬”è®°æ•°æ®
            raw_memories_data = context_data.get("raw_memories", [])
            raw_notes_data = context_data.get("raw_notes", [])
            core_topic = context_data.get("core_topic", "")


            # å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºè®°å¿†å¯¹è±¡
            from ..llm_memory.models.data_models import BaseMemory

            long_term_memories = []
            for memory_dict in raw_memories_data:
                try:
                    memory = BaseMemory.from_dict(memory_dict)
                    if memory:
                        long_term_memories.append(memory)
                except Exception as e:
                    self.logger.error(f"è½¬æ¢è®°å¿†å¯¹è±¡å¤±è´¥: {e}")

            # è·å–ä¸»LLMçš„æœ€ç»ˆå›ç­”
            response_text = response_data.get("completion_text", "")


            # ä»ä¸Šä¸‹æ–‡æ•°æ®ä¸­è·å–IDæ˜ å°„è¡¨
            memory_id_mapping = context_data.get("memory_id_mapping", {})
            note_id_mapping = context_data.get("note_id_mapping", {})

            # æ„å»ºåæ€æç¤ºè¯ï¼ˆä½¿ç”¨æ¨¡å—åŒ–çš„æç¤ºè¯æ„å»ºå™¨ï¼Œç°åœ¨å±•ç¤ºçŸ­IDï¼‰
            prompt = SmallModelPromptBuilder.build_post_hoc_analysis_prompt(
                historical_query=query,
                main_llm_response=response_text,
                raw_memories=long_term_memories,
                raw_notes=raw_notes_data,
                core_topic=core_topic,
                memory_id_mapping=memory_id_mapping,  # ä¼ é€’è®°å¿†IDæ˜ å°„è¡¨
                note_id_mapping=note_id_mapping,  # ä¼ é€’ç¬”è®°IDæ˜ å°„è¡¨
                config=self.config,
            )


            # è°ƒç”¨å°æ¨¡å‹è¿›è¡Œåˆ†æï¼ˆåœ¨åå°çº¿ç¨‹ä¸­åŒæ­¥è°ƒç”¨ï¼‰
            provider = self.context.get_provider_by_id(self.provider_id)
            if not provider:
                self.logger.error(
                    f"æ‰¾ä¸åˆ°æä¾›è€…: {self.provider_id}ï¼Œä¼šè¯: {session_id}"
                )
                return

            try:
                # ç›´æ¥å¼‚æ­¥è°ƒç”¨ï¼Œæ— éœ€æ£€æŸ¥
                llm_response = await provider.text_chat(prompt=prompt)
            except Exception as e:
                self.logger.error(
                    f"ä¼šè¯ {session_id} çš„LLMè°ƒç”¨å¤±è´¥ï¼Œè·³è¿‡è®°å¿†æ•´ç†: {e}"
                )
                return

            if not llm_response or not getattr(llm_response, "completion_text", ""):
                self.logger.error(f"ä¼šè¯ {session_id} çš„LLM APIè°ƒç”¨å¤±è´¥")
                return

            # æå–å“åº”æ–‡æœ¬
            response_text = llm_response.completion_text

            # è§£æå®Œæ•´çš„ç»“æ„åŒ–è¾“å‡º
            full_json_data = self.json_parser.extract_json(response_text)

            if not isinstance(full_json_data, dict):
                self.logger.error(
                    f"ä¼šè¯ {session_id} çš„JSONè§£æå¤±è´¥æˆ–æœªè¿”å›å­—å…¸"
                )
                return

            # æå– feedback_data
            feedback_data = full_json_data.get("feedback_data", {})

            # --- çµé­‚çŠ¶æ€æ›´æ–° (Feedback Loop) ---
            if hasattr(self, "soul") and self.soul and "soul_state_code" in full_json_data:
                state_code = full_json_data.get("soul_state_code", "0000")
                if len(state_code) == 4:
                    try:
                        # è§£æ4ä½ä»£ç 
                        is_recall, is_learn, is_talkative, is_creative = [int(c) for c in state_code]

                        # å®šä¹‰æ›´æ–°è§„åˆ™ (å‘½ä¸­+1.0, æœªå‘½ä¸­-0.5, è‡ªç„¶è¡°å‡0.1)
                        # ä»£ç ä½å¯¹åº”: RecallDepth, ImpressionDepth, ExpressionDesire, Creativity
                        # æ³¨æ„ï¼šä¸Šé¢çš„è§£æé¡ºåºå¯èƒ½éœ€è¦æ ¹æ®Promptä¸­çš„å®šä¹‰å¾®è°ƒ
                        # 0000 é¢“åºŸ: è¯å°‘(Expression-), æ­»æ¿(Creativity-), ä¸æŸ¥å†å²(Recall-), æ‹’ç»æ–°çŸ¥(Impression-)
                        # 1111 è§‰é†’: è¯å¤š(Expression+), é£å‡(Creativity+), æŸ¥é˜…å†å²(Recall+), å¸æ”¶æ–°çŸ¥(Impression+)

                        # æ›´æ–° RecallDepth (å¯¹åº”ç¬¬1ä½: æŸ¥é˜…å†å²)
                        self.soul.update_energy("RecallDepth", 1.0 if is_recall else -0.5, decay=0.1)

                        # æ›´æ–° ImpressionDepth (å¯¹åº”ç¬¬2ä½: å¸æ”¶æ–°çŸ¥)
                        self.soul.update_energy("ImpressionDepth", 1.0 if is_learn else -0.5, decay=0.1)

                        # æ›´æ–° ExpressionDesire (å¯¹åº”ç¬¬3ä½: è¯å¤š)
                        self.soul.update_energy("ExpressionDesire", 1.0 if is_talkative else -0.5, decay=0.1)

                        # æ›´æ–° Creativity (å¯¹åº”ç¬¬4ä½: å‘æ•£/é€»è¾‘é£å‡/ä¸è¢«æŸç¼š)
                        self.soul.update_energy("Creativity", 1.0 if is_creative else -0.5, decay=0.1)

                        self.logger.info(f"ğŸ§˜ çµé­‚åæ€ ({state_code}): {self.soul.get_state_description()}")
                    except ValueError:
                        self.logger.warning(f"æ— æ•ˆçš„çµé­‚çŠ¶æ€ä»£ç : {state_code}")

            # IDè§£æï¼šä½¿ç”¨æ˜ å°„è¡¨å°†LLMè¿”å›çš„çŸ­IDç¿»è¯‘å›é•¿ID
            memory_id_mapping = context_data.get("memory_id_mapping", {})
            note_id_mapping = context_data.get("note_id_mapping", {})

            if "useful_memory_ids" in feedback_data:
                # ä½¿ç”¨æ˜ å°„è¡¨å°†çŸ­IDç¿»è¯‘å›é•¿ID
                short_ids = feedback_data.get("useful_memory_ids", [])
                long_ids = [
                    memory_id_mapping.get(short_id, short_id) for short_id in short_ids
                ]
                feedback_data["useful_memory_ids"] = long_ids
            else:
                self.logger.error(
                    "feedback_dataä¸­æ²¡æœ‰useful_memory_idså­—æ®µ"
                )

            if not isinstance(feedback_data, dict):
                self.logger.error(
                    f"feedback_dataä¸æ˜¯å­—å…¸ç±»å‹ï¼Œå®é™…ç±»å‹: {type(feedback_data)}ï¼Œå†…å®¹: {feedback_data}"
                )
                feedback_data = {}  # å®‰å…¨é™çº§

            # === æ–°çš„ç®€åŒ–æ¥å£å®ç° ===

            # --- å¼€å§‹æœ€ç»ˆä¿®æ­£ ---

            # 1. ä» feedback_data ä¸­è·å–åŸå§‹çš„ã€æŒ‰ç±»å‹åˆ†ç»„çš„æ–°è®°å¿†å­—å…¸
            new_memories_raw = feedback_data.get("new_memories", {})

            # 2. è°ƒç”¨å·²æœ‰çš„å·¥å…·å‡½æ•°ï¼Œå°†å…¶è½¬æ¢ä¸ºåº•å±‚æœåŠ¡æœŸæœ›çš„"æ‰å¹³åˆ—è¡¨"æ ¼å¼
            new_memories_normalized = MemoryIDResolver.normalize_new_memories_format(
                new_memories_raw, self.logger
            )

            # --- è®°å¿†ç”Ÿæˆé™åˆ¶ (åŸºäºçµé­‚ ImpressionDepth) ---
            if hasattr(self, "soul") and self.soul and new_memories_normalized:
                # è·å–å…è®¸ç”Ÿæˆçš„æœ€å¤§æ•°é‡
                impression_limit = int(self.soul.get_value("ImpressionDepth"))
                original_count = len(new_memories_normalized)

                # æˆªæ–­åˆ—è¡¨
                if original_count > impression_limit:
                    new_memories_normalized = new_memories_normalized[:impression_limit]
                    self.logger.info(f"âœ‚ï¸ è®°å¿†æˆªæ–­: çµé­‚ä»…å…è®¸è®°å½• {impression_limit} æ¡ (åŸ {original_count} æ¡)")

                # ä¸ºæ¯æ¡æ–°è®°å¿†æ³¨å…¥å½“å‰çš„çµé­‚å¿«ç…§
                snapshot = self.soul.get_snapshot()
                for mem in new_memories_normalized:
                    mem["state_snapshot"] = snapshot

            # --- ä¿®æ­£ç»“æŸ ---

            # 3. è°ƒç”¨å°è£…å¥½çš„ feedback æ¥å£ï¼Œå¹¶ä½¿ç”¨"è½¬æ¢å"çš„æ‰å¹³åˆ—è¡¨
            #    (ä»¥åŠæˆ‘ä»¬ä¹‹å‰è®¨è®ºè¿‡çš„ï¼Œè®© feedback è¿”å›æ–°åˆ›å»ºçš„å¯¹è±¡)
            newly_created_memories = []
            if self.memory_system:
                # ç›´æ¥å¼‚æ­¥è°ƒç”¨
                newly_created_memories = await self.memory_system.feedback(
                    useful_memory_ids=feedback_data.get("useful_memory_ids", []),
                    new_memories=new_memories_normalized,  # <--- ä½¿ç”¨è½¬æ¢åçš„æ•°æ®
                    merge_groups=feedback_data.get("merge_groups", []),
                )

            # 2. æ›´æ–°çŸ­æœŸè®°å¿†
            # è·å–æœ‰ç”¨çš„æ—§è®°å¿†
            useful_ids = feedback_data.get("useful_memory_ids", [])
            useful_long_term_memories = [
                mem for mem in long_term_memories if mem.id in useful_ids
            ]

            # å°†æœ‰ç”¨çš„æ—§è®°å¿†å’Œå…¨æ–°çš„è®°å¿†åˆå¹¶ï¼Œä¸€èµ·æ”¾å…¥çŸ­æœŸè®°å¿†
            memories_for_session = useful_long_term_memories + newly_created_memories
            if memories_for_session:
                self.session_memory_manager.add_memories_to_session(
                    session_id, memories_for_session
                )

        except Exception as e:
            import traceback

            self.logger.error(f"å¼‚æ­¥è®°å¿†åˆ†æå¤±è´¥ - ä¼šè¯={session_id}: {e}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
