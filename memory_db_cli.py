#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®°å¿†æ•°æ®åº“CLIå·¥å…· - æ ¸å¿ƒäº¤äº’å¼è°ƒè¯•å™¨
"""

import json
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional
import chromadb
import requests

# æ·»åŠ ä¸»é¡¹ç›®è·¯å¾„åˆ° sys.path
SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR.parent.parent.parent / "astrbot"
if PROJECT_ROOT.exists() and str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

PLUGIN_ROOT = SCRIPT_DIR
if str(PLUGIN_ROOT) not in sys.path:
    sys.path.insert(0, str(PLUGIN_ROOT))

try:
    from rich.console import Console
    from rich.table import Table
    from rich.panel import Panel
    from rich.prompt import Prompt
except ImportError:
    print("âŒ äº¤äº’å¼æ¨¡å¼éœ€è¦å®‰è£… 'rich' åº“: pip install rich")
    sys.exit(1)


class DatabasePathResolver:
    """æ•°æ®åº“è·¯å¾„è‡ªåŠ¨æ¨æ–­å™¨"""
    def __init__(self, script_path: Path):
        self.script_path = script_path
        self.plugin_root = script_path.parent

    def resolve_database_path(self) -> Optional[Path]:
        """è‡ªåŠ¨æ¨æ–­ ChromaDB æ•°æ®åº“è·¯å¾„"""
        try:
            data_dir = self.plugin_root.parent.parent
            index_dir = data_dir / "plugin_data" / "astrbot_plugin_angel_memory"
            if not index_dir.exists():
                print(f"âŒ æ’ä»¶æ•°æ®ç›®å½•ä¸å­˜åœ¨: {index_dir}")
                return None

            config_path = data_dir / "config" / "astrbot_plugin_angel_memory_config.json"
            provider_id = ""
            if config_path.exists():
                try:
                    with open(config_path, 'r', encoding='utf-8-sig') as f:
                        config = json.load(f)
                        provider_id = config.get("astrbot_embedding_provider_id", "")
                except Exception as e:
                    print(f"âš ï¸  è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            else:
                print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")

            import re
            safe_provider_id = re.sub(r'[<>:"/\\|?*]', '_', provider_id.strip()) if provider_id and provider_id.strip() else "local"
            db_dir = index_dir / f"memory_{safe_provider_id}" / "chromadb"

            if not db_dir.exists():
                print(f"âš ï¸  æ•°æ®åº“ç›®å½•ä¸å­˜åœ¨: {db_dir}")
                return None

            print(f"âœ… æˆåŠŸå®šä½æ•°æ®åº“: {db_dir}")
            if provider_id:
                print(f"   å½“å‰æä¾›å•†: {provider_id}")
            return db_dir
        except Exception as e:
            print(f"âŒ è·¯å¾„æ¨æ–­å¤±è´¥: {e}")
            return None


class SimpleEmbeddingProvider:
    """ç®€åŒ–çš„åµŒå…¥æä¾›å•† - ç”¨äºCLIå·¥å…·çš„å‘é‡åŒ–"""
    def __init__(self, provider_id: str, api_key: str = None):
        self.provider_id = provider_id
        self.api_key = ""
        self.api_url = "https://api.siliconflow.cn/v1/embeddings"
        self.model = "BAAI/bge-m3"

    def embed_documents_sync(self, texts: List[str]) -> List[List[float]]:
        """åŒæ­¥æ–¹æ³•ï¼šä¸ºæ–‡æ¡£åˆ—è¡¨ç”Ÿæˆå‘é‡åµŒå…¥"""
        if not texts:
            return []

        headers = {"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"}
        data = {"model": self.model, "input": texts, "encoding_format": "float"}

        try:
            response = requests.post(self.api_url, headers=headers, json=data, timeout=30)
            response.raise_for_status()
            result = response.json()
            return [item["embedding"] for item in result["data"]]
        except Exception as e:
            console = Console()
            console.print(f"[red]âŒ å‘é‡åŒ–å¤±è´¥: {e}[/red]")
            raise

    def get_model_info(self) -> Dict[str, Any]:
        return {"model": self.model}


class MemoryDBDebugger:
    """æ ¸å¿ƒè°ƒè¯•å™¨"""
    def __init__(self, db_path: Path, provider_id: str, api_key: str = None):
        self.db_path = db_path
        self.client = chromadb.PersistentClient(path=str(db_path))
        self.provider_id = provider_id
        self.api_key = api_key
        self.embedding_provider = None
        self.bm25_retriever = None
        self.integrated_mode = False
        self._try_load_components()

    def _try_load_components(self):
        """å°è¯•ä»é¡¹ç›®ä¸­åŠ è½½ç»„ä»¶"""
        try:
            if self.provider_id:
                self.embedding_provider = SimpleEmbeddingProvider(self.provider_id, self.api_key)
            else:
                raise RuntimeError("éœ€è¦æŒ‡å®šæä¾›å•†ID")

            import importlib.util
            bm25_path = PLUGIN_ROOT / "llm_memory" / "components" / "bm25_retriever.py"
            spec = importlib.util.spec_from_file_location("bm25_module", bm25_path)
            bm25_module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(bm25_module)
            # ä½¿ç”¨æ–°çš„æ— çŠ¶æ€ç²¾æ’å‡½æ•°
            self.rerank_with_bm25 = bm25_module.rerank_with_bm25

            self.integrated_mode = True
            print("âœ… æ··åˆæ£€ç´¢æ¨¡å¼å·²å¯ç”¨ (ä½¿ç”¨æ— çŠ¶æ€ BM25 ç²¾æ’)")
            model_info = self.embedding_provider.get_model_info()
            print(f"   å‘é‡åŒ–æ¨¡å‹: {model_info.get('model')}")
        except Exception as e:
            print(f"âš ï¸  åˆå§‹åŒ–å¤±è´¥: {e}")
            self.integrated_mode = False

    def _vector_search(self, collection_name: str, query: str, limit: int) -> List[Dict[str, Any]]:
        """æ‰§è¡Œçº¯å‘é‡æœç´¢çš„æ ¸å¿ƒå®ç°"""
        console = Console()
        try:
            query_embedding_list = self.embedding_provider.embed_documents_sync([query])
            if not query_embedding_list:
                return []
            query_embedding = query_embedding_list[0]

            collection = self.client.get_or_create_collection(name=collection_name)
            results = collection.query(query_embeddings=[query_embedding], n_results=limit)

            ids = results.get('ids', [[]])[0]
            distances = results.get('distances', [[]])[0]

            output = []
            for i, doc_id in enumerate(ids):
                distance = distances[i]
                similarity = max(0.0, 1.0 - (distance / 2.0))
                output.append({'id': doc_id, 'similarity': similarity})
            return output
        except Exception as e:
            console.print(f"[red]âŒ _vector_search å‘ç”Ÿé”™è¯¯: {e}[/red]")
            return []

    def hybrid_search(self, collection_name: str, query: str, limit: int = 10, vector_weight: float = 0.7, bm25_weight: float = 0.3) -> List[Dict[str, Any]]:
        """æ‰§è¡Œæ··åˆæ£€ç´¢å¹¶è¿”å›è¯¦ç»†ç»“æœ"""
        console = Console()
        if not self.integrated_mode:
            return []

        with console.status("[bold green]æ‰§è¡Œæ··åˆæ£€ç´¢ä¸­...") as status:
            status.update("ğŸ” (1/3) å‘é‡æœç´¢...")
            vector_results = self._vector_search(collection_name, query, limit=limit * 2)
            vector_scores = {res['id']: res['similarity'] for res in vector_results}

            # --- è°ƒè¯•åŠŸèƒ½ï¼šä¿å­˜å‘é‡æœç´¢ç»“æœåˆ° JSON ---
            collection = self.client.get_or_create_collection(collection_name)
            try:
                top_30_ids = [res['id'] for res in vector_results[:30]]
                if top_30_ids:
                    retrieved_items = collection.get(ids=top_30_ids, include=['metadatas', 'documents'])
                    export_data = []
                    for i, doc_id in enumerate(retrieved_items['ids']):
                        export_data.append({
                            "id": doc_id,
                            "metadata": retrieved_items['metadatas'][i],
                            "document": retrieved_items['documents'][i]
                        })

                    export_path = Path(__file__).parent / "debug_vector_results.json"
                    with open(export_path, 'w', encoding='utf-8') as f:
                        json.dump(export_data, f, ensure_ascii=False, indent=2)
                    console.print(f"âœ… [green]å·²å°†å‰ 30 ä¸ªå‘é‡æœç´¢ç»“æœä¿å­˜åˆ° {export_path}[/green]")
            except Exception as e:
                console.print(f"[yellow]âš ï¸  ä¿å­˜è°ƒè¯• JSON å¤±è´¥: {e}[/yellow]")
            # --- è°ƒè¯•åŠŸèƒ½ç»“æŸ ---

            status.update("ğŸ“š (2/3) BM25 ç²¾æ’...")
            collection = self.client.get_or_create_collection(collection_name)

            # --- æ–°çš„â€œå¬å›-è¿‡æ»¤-ç²¾æ’â€æ··åˆæ£€ç´¢ç­–ç•¥ ---
            # 1. å‘é‡å¬å›
            RECALL_COUNT = 100 # å¬å›æ•°é‡
            vector_results = self._vector_search(collection_name, query, limit=RECALL_COUNT)
            vector_scores = {res['id']: res['similarity'] for res in vector_results}

            # 2. å‘é‡åˆ†æ•°è¿‡æ»¤
            VECTOR_THRESHOLD = 0.5
            filtered_by_score = [res for res in vector_results if res['similarity'] >= VECTOR_THRESHOLD]

            if not filtered_by_score:
                console.print(f"[yellow]âš ï¸  æ²¡æœ‰å‘é‡åˆ†æ•°é«˜äº {VECTOR_THRESHOLD} çš„æ–‡æ¡£ï¼Œè·³è¿‡ BM25 ç²¾æ’ã€‚[/yellow]")
                bm25_results = []
            else:
                # 3. æ•°é‡é™åˆ¶
                MAX_CANDIDATES = 100 # æœ€å¤šå¯¹100ä¸ªæ–‡æ¡£è¿›è¡Œç²¾æ’
                candidates_for_rerank = filtered_by_score[:MAX_CANDIDATES]
                console.print(f"[green]âœ… å‘é‡å¬å› {len(vector_results)} æ¡ï¼Œè¿‡æ»¤åå‰©ä½™ {len(filtered_by_score)} æ¡ï¼Œå–å‰ {len(candidates_for_rerank)} æ¡è¿›è¡Œ BM25 ç²¾æ’ã€‚[/green]")

                # 4. å‡†å¤‡ç²¾æ’æ•°æ®
                candidate_ids = [c['id'] for c in candidates_for_rerank]
                retrieved_items = collection.get(ids=candidate_ids, include=['metadatas'])
                id_to_content = {
                    item['id']: item['metadata'].get('content', '')
                    for item in zip(retrieved_items['ids'], retrieved_items['metadatas'])
                }

                rerank_input = [
                    {"id": c_id, "content": id_to_content.get(c_id, "")}
                    for c_id in candidate_ids
                ]

                # 5. è°ƒç”¨æ— çŠ¶æ€ BM25 ç²¾æ’
                bm25_results = self.rerank_with_bm25(query, rerank_input, limit=limit)
            # --- æ–°ç­–ç•¥ç»“æŸ ---

            max_bm25_score = max(score for _, score in bm25_results) if bm25_results else 1.0
            bm25_scores = {doc_id: score / max_bm25_score for doc_id, score in bm25_results}

            status.update("ğŸ”„ (3/3) ç»“æœèåˆ...")
            all_ids = set(vector_scores.keys()) | set(bm25_scores.keys())

            combined_results = []
            items_data = {}
            if all_ids:
                retrieved_items = collection.get(ids=list(all_ids))
                for i, doc_id in enumerate(retrieved_items['ids']):
                    items_data[doc_id] = {'metadata': retrieved_items['metadatas'][i], 'document': retrieved_items['documents'][i]}

            for doc_id in all_ids:
                vec_score = vector_scores.get(doc_id, 0.0)
                bm25_s = bm25_scores.get(doc_id, 0.0)
                content = (items_data.get(doc_id, {}).get('metadata', {}).get('content') or items_data.get(doc_id, {}).get('document') or "N/A")
                combined_results.append({
                    "id": doc_id,
                    "content_summary": content[:100].strip().replace('\n', ' ') + "...",
                    "vector_score": vec_score,
                    "bm25_score": bm25_s,
                    "combined_score": (vec_score * vector_weight) + (bm25_s * bm25_weight)
                })

            return sorted(combined_results, key=lambda x: x['combined_score'], reverse=True)[:limit]


def main():
    """ä¸»å…¥å£å‡½æ•° - äº¤äº’å¼è°ƒè¯•æ¨¡å¼"""
    console = Console()
    console.print(Panel("[bold cyan]æ¬¢è¿ä½¿ç”¨ Angel Memory äº¤äº’å¼è°ƒè¯•å·¥å…·[/bold cyan]", expand=False))

    resolver = DatabasePathResolver(Path(__file__))
    db_path = resolver.resolve_database_path()
    if not db_path:
        sys.exit(1)

    provider_id = "local"
    data_dir = Path(__file__).parent.parent.parent
    config_path = data_dir / "config" / "astrbot_plugin_angel_memory_config.json"
    if config_path.exists():
        try:
            with open(config_path, 'r', encoding='utf-8-sig') as f:
                provider_id = json.load(f).get("astrbot_embedding_provider_id", "local")
        except Exception as e:
            console.print(f"[yellow]âš ï¸  è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}[/yellow]")

    debugger = MemoryDBDebugger(db_path, provider_id=provider_id)
    if not debugger.integrated_mode:
        sys.exit(1)

    mode = Prompt.ask("è¯·é€‰æ‹©é›†åˆ (memory, note)", choices=["memory", "note"], default="note")
    collection_name = "personal_memory_v1" if mode == "memory" else "notes_main"

    try:
        count = debugger.client.get_or_create_collection(name=collection_name).count()
        console.print(f"âœ… [bold]å·²é”å®šé›†åˆ:[/bold] {collection_name} ({count}æ¡æ–‡æ¡£)")
    except Exception as e:
        console.print(f"[red]âŒ è·å–é›†åˆçŠ¶æ€å¤±è´¥: {e}[/red]")

    while True:
        try:
            query = Prompt.ask("\n[bold]è¯·è¾“å…¥æŸ¥è¯¢å†…å®¹[/bold] (æˆ–è¾“å…¥ 'exit' é€€å‡º)")
            if query.lower() == 'exit':
                break

            results = debugger.hybrid_search(collection_name, query, limit=10)
            if not results:
                console.print("[yellow]âš ï¸  æ²¡æœ‰æ‰¾åˆ°åŒ¹é…ç»“æœ[/yellow]")
                continue

            table = Table(title="æ··åˆæ£€ç´¢è°ƒè¯•ç»“æœ")
            table.add_column("Rank", style="magenta")
            table.add_column("ID", style="cyan")
            table.add_column("Content", style="white")
            table.add_column("Vec Score", style="green")
            table.add_column("BM25 Score", style="yellow")
            table.add_column("Combined", style="blue")

            for i, res in enumerate(results):
                table.add_row(
                    str(i + 1), res['id'], res['content_summary'],
                    f"{res['vector_score']:.4f}", f"{res['bm25_score']:.4f}", f"{res['combined_score']:.4f}"
                )
            console.print(table)
        except KeyboardInterrupt:
            break
        except Exception as e:
            console.print(f"[red]å‘ç”Ÿé”™è¯¯: {e}[/red]")

    console.print("[bold yellow]å†è§ï¼[/bold yellow]")


if __name__ == "__main__":
    main()
