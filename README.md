# Angel Memory - 认知双系统

> 让 AI 拥有自行运转的潜意识记忆 + 开箱即用的知识检索

## 🧠 革新认知设计

「对话记忆」加「笔记检索」，双系统协同。

### 核心架构

- **记忆系统**：处理对话经验和认知元

- **笔记系统**：检索文档内容和知识片段

- **协同增强**：两套系统并行作用于主模型

## 🔬 双层认知：分工合作

### 认知角色分工

「主意识」专注推理，「潜意识」管理记忆，「笔记库」提供知识。

### 流程协同

```

用户输入 →

├─ 笔记检索（即时知识支持）

├─ 记忆召回（对话历史经验）

└─ 主模型推理（综合决策）

```

## 🧩 记忆系统：经验认知

「记忆元」= 论断 + 理由 + 标签

### 记忆类型架构

- **知识元**：事实认知，「Python 是语言」

- **技能元**：流程掌握，「回答问题前先理解」

- **情感元**：感受记录

- **任务元**：行为追踪

- **事件元**：历史存档

### 认知循环

「观察 → 回忆 → 反馈 → 睡眠」四步循环，持续优化记忆网络。

## 📚 笔记系统：知识检索

多格式文档解析，智能检索机制。

### 文件支持

- **文档类**：PDF、Word、PPT、Excel

- **文本类**：Markdown、纯文本

- **数据类**：CSV、JSON、XML

- **媒体类**：图片、音频

- **容器类**：ZIP 压缩包

- **网络类**：YouTube 链接

### 检索架构

- **动态解析**：插件化解析器框架

- **智能分块**：基于语义完整性

- **标签系统**：多级权重索引

- **双向量化**：内容+标签独立向量

## 🧪 技术融合实现

### 记忆工作流

事件触发「链式回忆」，多轨并行提取。确定有用记忆注入系统提示。

### 笔记工作流

文件监控自动解析，向量化存储。实时检索对话相关知识点。

### 协同增效

记忆提供「经验智能」，笔记提供「知识支持」。双系统互补增强模型理解。

## 🚀 系统特性

### 记忆系统

- **关联网络**：链式回忆穿透深度记忆

- **权重优化**：使用频率决定记忆重要性

- **动态整理**：睡眠阶段自发优化网络

### 笔记系统

- **多格式解析**：20+文档格式无缝支持
- **智能标签**：路径+标题+内容多维索引
- **容量适配**：Token 限制动态控制检索量
- **自动扫描**：启动时自动索引 raw/目录文件

## 📚 快速使用

### ⚠️ 重要前置依赖

**必须安装 [astrbot_plugin_angel_heart](https://github.com/kawayiYokami/astrbot_plugin_angel_heart) 插件**

> AstrBot 原生的聊天记录管理功能完全不可用，必须使用天使之心插件提供的聊天记录管理能力。没有此插件，记忆系统将无法正常获取对话历史。

### 基础配置

```json
{
  "min_message_length": 5,
  "short_term_memory_capacity": 1.0,
  "sleep_interval": 3600,
  "provider_id": "",
  "note_search_token_limit": 10000,
  "small_model_note_budget": 8000,
  "large_model_note_budget": 12000
}
```

**配置项说明**：

- **`min_message_length`**：触发记忆处理的最小消息字符数（1-500）

  - 过滤过短消息，避免噪音干扰

- **`short_term_memory_capacity`**：短期记忆容量倍数（0.1-10.0）

  - 设置为 2.0 则容量翻倍
  - 影响单会话中保持的记忆数量

- **`sleep_interval`**：记忆巩固间隔，单位为秒（0-86400）

  - 默认 1 小时(3600)，设置为 0 禁用自动睡眠
  - 记忆系统优化的执行频率

- **`provider_id`**：记忆整理 LLM 提供商 ID

  - 留空则只召回记忆不进行整理
  - 填写后将调用 LLM 进行记忆筛选和整理
  - 建议使用快速的小模型

- **`note_search_token_limit`**：笔记检索 token 限制（0-32000）
  - 控制检索笔记内容量，避免上下文过长
  - 根据模型上下文限制设置

- **`small_model_note_budget`**：小模型笔记 Token 预算（0-64000）
  - 小模型用于智能选择相关笔记的 Token 数量限制
  - 建议 8000-12000 之间

- **`large_model_note_budget`**：大模型笔记 Token 预算（0-64000）
  - 大模型用于生成最终回答的笔记上下文 Token 数量限制
  - 建议 12000-16000 之间

### 项目结构

```
astrbot_plugin_angel_memory/
├── core/                    # 记忆系统核心
│   ├── deepmind.py         # 主记忆处理逻辑
│   ├── config.py           # 插件配置管理
│   └── note_enhancer.py    # 笔记增强器
├── llm_memory/             # 记忆系统子模块
│   ├── parser/            # 多格式文件解析器
│   ├── service/           # 笔记和记忆服务
│   └── components/        # 向量存储等组件
├── docs/                  # 设计文档和说明
├── tests/                 # 测试代码
└── metadata.yaml          # 插件配置元数据
```

### 数据存储目录

插件数据存储在：

```
astrbot/data/plugin_data/astrbot_plugin_angel_memory/
├── raw/                   # 放置知识库文件
└── storage/              # 自动生成的向量数据库
```

### 知识库使用指南

#### 文件组织规范

**路径结构决定知识结构** - 文件夹层级和文件名都会成为检索关键词

推荐结构：

```
raw/
├── 编程/
│   ├── Python基础.md
│   ├── 算法与数据结构/
│   │   └── 排序算法详解.md
│   └── 设计模式/
├── 产品知识/
│   ├── 需求分析.md
│   └── 用户体验设计.md
└── 个人文档/
    └── 项目笔记.md
```

#### 文件格式建议

- **首选 Markdown**：结构清晰，检索效果最佳
- **命名具有描述性**：文件名本身会成为重要标签
- **内容结构化**：使用标题层级组织内容
- **避免大型文件**：建议按主题拆分为小文件
- **索引同步**：每次插件重启都会重新扫描，确保知识库与文件同步

#### 自动索引流程

1. 将文档放入 `raw/` 目录
2. 重启插件触发扫描（每次重启都会重新构建索引）
3. 系统解析、向量化、建立索引
4. 删除文件后重启插件，相应内容将从知识库中清除
5. 对话时自动检索索引中的最新内容

### 快速开始

1. **安装前置依赖**：先安装 [astrbot_plugin_angel_heart](https://github.com/kawayiYokami/astrbot_plugin_angel_heart) 插件
2. **安装本插件**：将本插件放入 AstrBot 的 `plugins` 目录
3. **首次使用**：插件自动创建数据目录结构
4. **添加知识**：将文档放入 `astrbot/data/plugin_data/astrbot_plugin_angel_memory/raw/`
5. **重启插件**：触发索引扫描（每次重启都会完全重建索引）
6. **更新管理**：删除或修改文件后，重启插件使知识库同步
7. **立即生效**：重启后的对话基于最新索引内容

## 🤔 解决核心问题

### 经验积累

记忆系统积累对话经验，从问答中学习用户模式和偏好。

### 知识扩展

笔记系统提供外部知识库，突破模型固有知识边界。

### 效率平衡

记忆系统轻量化处理对话流，笔记系统按需加载相关知识。

## 🎯 设计哲学

「经验认知+知识支持」双轨并行。

记忆系统处理「经历」，笔记系统提供「知识」。经验与知识互补，对话与检索共存，构建完整 AI 认知体系。

---

**构建既有思想，又有知识的 AI 大脑。**
