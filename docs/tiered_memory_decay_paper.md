# 面向对话式 AI 长期记忆的三档自适应衰减算法：设计、实现与仿真验证

> **摘要**：对话式 AI 在长期运行中会持续积累记忆条目，如何在保留重要记忆的同时高效清退低价值记忆，是制约系统可扩展性的核心问题。本文提出一种基于"使用价值累积"的三档分级记忆衰减算法（Tiered Memory Decay，TMD），将记忆按 `useful_score` 动态划分为易逝档（T0）、待证档（T1）和核心档（T2）三个等级，分别施加时间驱动遗忘、召回判定遗忘和永久保留三种策略。通过离散事件仿真器对 1 年周期、500~10,000 次/天调用量级的场景进行了系统性验证，结果表明该算法在维持 94%~95% 噪声驱散率的同时，核心记忆可持续累积，且在 10 倍负载变化下保持线性可预测的存活比例。本文详细阐述了算法的数学模型、实现架构、仿真方法论和参数敏感性分析。

---

## 1 引言

### 1.1 问题背景

在对话式 AI 系统中，长期记忆（Long-Term Memory）是支撑个性化、上下文理解和持续学习的基础。系统每次与用户交互后，都可能产生新的记忆条目——包括事实知识、事件记录、情感状态、技能模式等。随着时间推移，记忆池不可避免地膨胀，带来以下挑战：

1. **存储压力**：记忆条目数量线性增长，SQL 存储和向量索引的检索效率随之下降。
2. **检索噪声**：大量低质量、过时或一次性的记忆条目参与检索，稀释了有价值记忆的召回概率。
3. **不可逆删除风险**：简单的"先进先出"或统一衰减策略可能误删重要的低频记忆（如每年一次的关键事件）。

人类的遗忘曲线（Ebbinghaus Forgetting Curve）为这一问题提供了启发：人类大脑通过"间隔重复"（Spaced Repetition）和"使用频率"两个维度对记忆进行自然筛选——频繁回忆且被证明有用的知识会被巩固到长期记忆中，而不再被使用的信息则逐渐遗忘。

### 1.2 现有方法的局限

传统的记忆管理方案主要有：

- **统一时间衰减**：所有记忆以固定速率衰减。缺陷：无法区分高价值和低价值记忆，重要记忆可能在低频使用期被误删。
- **基于访问频率的 LRU/LFU**：借鉴缓存策略。缺陷：将"被召回"等同于"有价值"，忽略了"被召回但无用"这一关键信号。
- **固定容量窗口**：保留最近 N 条记忆。缺陷：完全丢弃时间远端的长期知识。

以上方案的共同问题是**缺乏对记忆"被证明有用"这一正向反馈信号的建模**。

### 1.3 本文贡献

本文提出三档自适应衰减算法（TMD），核心贡献包括：

1. 引入 `useful_score` 作为记忆价值的累积度量指标，基于"召回后是否被判定有用"这一显式反馈信号进行升档。
2. 设计三档差异化遗忘策略，使不同价值阶段的记忆面临不同的遗忘压力。
3. 构建离散事件仿真器，通过 6 种用户画像和多压力等级进行系统性验证。
4. 给出可直接应用于生产系统的参数推荐和实现方案。

---

## 2 算法设计

### 2.1 核心概念

#### 2.1.1 记忆数据模型

每条记忆 $m$ 包含以下与衰减相关的属性：

| 属性 | 类型 | 含义 |
|------|------|------|
| $s(m)$ | `int` | 强度（strength），记忆的生命力指标 |
| $u_c(m)$ | `int` | 有用计数（useful_count），累计被判定有用的次数 |
| $u_s(m)$ | `float` | 有用分数（useful_score），价值累积指标 |
| $a(m)$ | `bool` | 是否为主动记忆（is_active），主动记忆不参与衰减 |
| $t_{create}(m)$ | `float` | 创建时间 |
| $t_{recall}(m)$ | `float` | 最后被召回时间 |
| $t_{decay}(m)$ | `float` | 最后衰减参考时间（内部字段） |

#### 2.1.2 档位定义

设升档阈值 $\theta_0$（T0→T1 阈值）和 $\theta_1$（T1→T2 阈值），定义档位函数：

$$
\text{tier}(m) = \begin{cases}
2 & \text{if } u_s(m) \geq \theta_1 \\
1 & \text{if } \theta_0 \leq u_s(m) < \theta_1 \\
0 & \text{if } u_s(m) < \theta_0
\end{cases}
$$

默认参数：$\theta_0 = 3.0$，$\theta_1 = 10.0$。

三个档位对应的语义为：

| 档位 | 名称 | 语义 |
|------|------|------|
| T0 | 易逝档 | 尚未被证明有用的新记忆，随时间自然衰减 |
| T1 | 待证档 | 有一定使用价值但尚未充分验证，仅在被证伪时衰减 |
| T2 | 核心档 | 经过多次验证的高价值记忆，永久保留 |

### 2.2 状态转移规则

#### 2.2.1 召回反馈事件

当记忆 $m$ 被召回后，系统根据 LLM 的判断产生"有用"或"无用"反馈：

**判定有用时**：

$$
s(m) \leftarrow s(m) + \delta_{\text{boost}}
$$
$$
u_c(m) \leftarrow u_c(m) + 1
$$
$$
u_s(m) \leftarrow u_s(m) + v_{\text{consolidate}}
$$
$$
t_{recall}(m) \leftarrow t_{\text{now}}
$$

其中 $\delta_{\text{boost}} = 1$（强度增量），$v_{\text{consolidate}} = 2.5$（巩固速度）。

**判定无用时**（仅对 T1 生效）：

$$
s(m) \leftarrow \max(0, \; s(m) - 1) \quad \text{iff } \text{tier}(m) = 1
$$

T0 在此事件中不受影响（其衰减由时间驱动），T2 在此事件中不受影响（永不遗忘）。

#### 2.2.2 时间驱动自然衰减

仅对 T0 生效。设基础衰减周期为 $C_0$ 天，全局遗忘速度 $v_f$，T0 档位遗忘速度 $v_{f0}$，则实际衰减周期为：

$$
C_{\text{effective}} = \max\left(1, \; \left\lfloor \frac{C_0}{v_f \cdot v_{f0}} \right\rceil\right)
$$

其中 $\lfloor \cdot \rceil$ 表示四舍五入取整。

设参考时间 $t_{\text{ref}}$ 为 $\max(t_{decay}(m), t_{recall}(m), t_{create}(m))$，经过的衰减步数为：

$$
n_{\text{steps}} = \left\lfloor \frac{t_{\text{now}} - t_{\text{ref}}}{C_{\text{effective}} \times 86400} \right\rfloor
$$

若 $n_{\text{steps}} > 0$：

$$
s(m) \leftarrow \max(0, \; s(m) - n_{\text{steps}})
$$
$$
t_{decay}(m) \leftarrow t_{\text{ref}} + n_{\text{steps}} \times C_{\text{effective}} \times 86400
$$

#### 2.2.3 删除条件

$$
\text{DELETE}(m) \quad \text{iff} \quad s(m) \leq 0 \;\land\; \neg a(m)
$$

#### 2.2.4 升档路径

记忆的升档完全由 $u_s(m)$ 的累积驱动。以默认参数为例：

- 新记忆初始 $u_s = 0$，位于 T0
- 每次被判定有用，$u_s$ 增加 2.5
- 被判定有用 2 次后，$u_s = 5.0 \geq 3.0$，升入 T1
- 被判定有用 4 次后，$u_s = 10.0 \geq 10.0$，升入 T2

### 2.3 算法直觉

TMD 算法的设计直觉可以用一个类比来说明：

- **T0（试用期员工）**：新入职，如果在考察期内（衰减周期）没有做出贡献，自然淘汰。
- **T1（正式员工）**：已经证明过价值，享有基本保障——只有在被叫去做事但没做好时（召回无用）才扣分。
- **T2（核心骨干）**：多次证明价值后获得终身保障，不再面临淘汰压力。

这种设计确保了：
1. 噪声记忆快速清退（T0 自动衰减）
2. 有潜力的记忆获得充分验证机会（T1 只在证伪时衰减）
3. 经过验证的记忆获得长期保障（T2 永不遗忘）

---

## 3 系统实现

### 3.1 存储层

系统支持两种存储后端，共享同一套衰减策略：

**SQL 后端（SQLite）**：在 `memory_records` 表中新增以下列：

```sql
useful_count   INTEGER NOT NULL DEFAULT 0,
useful_score   REAL    NOT NULL DEFAULT 0,
last_recalled_at REAL  NOT NULL DEFAULT 0,
last_decay_at  REAL    NOT NULL DEFAULT 0
```

其中 `last_decay_at` 为纯内部字段，不暴露到业务模型中，专门用于追踪自然衰减的参考时间点，避免与 `last_recalled_at` 的业务语义产生冲突。

**向量后端（ChromaDB）**：在向量元数据（metadata）中存储等价字段，通过逐条查询-更新的方式维护。

### 3.2 衰减策略层

```
MemoryDecayConfig (frozen dataclass)
  ├── tier0_threshold: float = 3.0
  ├── tier1_threshold: float = 10.0
  ├── consolidate_speed: float = 2.5
  ├── cycle_tier0_days: int = 3
  ├── forget_speed: float = 1.0
  └── tier0_forget_speed: float = 1.0

MemoryDecayPolicy
  ├── tier_of(useful_score) → int
  ├── tier0_decay_cycle_days() → int
  ├── should_natural_decay(useful_score) → bool
  ├── should_decay_on_useless_recall(useful_score) → bool
  └── is_immortal(useful_score) → bool
```

策略层与存储层解耦，通过依赖注入传递配置。参数支持通过插件配置文件覆盖默认值，并提供合法性校验（如 `tier1_threshold >= tier0_threshold`）。

### 3.3 批量自然衰减的 SQL 实现

T0 自然衰减在 `consolidate_memories()`（记忆巩固/睡眠周期）中触发。为避免将大量行加载到 Python 逐条处理，采用单条 CTE + UPDATE 语句在 SQLite 内部完成批量计算：

```sql
WITH decay_calc AS (
    SELECT id, strength,
           <ref_time 计算>,
           CAST((now - ref_time) / cycle_seconds AS INTEGER) AS decay_steps
    FROM memory_records
    WHERE is_active = 0 AND useful_score < θ₀ AND strength > 0
)
UPDATE memory_records
SET strength   = MAX(0, strength - decay_calc.decay_steps),
    last_decay_at = ref_time + decay_steps * cycle_seconds,
    updated_at = now
WHERE id IN (SELECT id FROM decay_calc WHERE decay_steps > 0)
```

该方案将 IO 从 O(N) 次缩减为 O(1) 次数据库往返。

### 3.4 反馈处理流程

完整的反馈流程如下：

```
输入：useful_memory_ids (有用的记忆ID集合)
      recalled_memory_ids (所有被召回的记忆ID集合)

步骤 1：强化有用记忆
  对 useful_memory_ids 中每条记忆：
    strength += 1, useful_score += 2.5, useful_count += 1

步骤 1.5：衰减被召回但无用的记忆
  useless_ids = recalled_memory_ids - useful_memory_ids
  对 useless_ids 中每条记忆：
    若 tier(m) == 1：strength -= 1

步骤 2：创建新记忆（省略）
步骤 3：合并重复记忆（省略）
```

关键设计决策：`recalled_memory_ids` 从召回结果中提取全部记忆 ID（而非仅无用的），与 `useful_memory_ids` 做集合差运算以得出"被召回但无用"的集合。这保证了两个信号源的独立性和可审计性。

### 3.5 记忆合并的档位保留

当多条记忆被合并为一条时，新记忆的档位相关属性取各源记忆的最大值：

$$
u_s(m_{\text{new}}) = \max_{i} \, u_s(m_i)
$$

$$
t_{recall}(m_{\text{new}}) = \max_{i} \, t_{recall}(m_i)
$$

这确保了合并操作不会导致记忆降档。

---

## 4 仿真方法论

### 4.1 仿真器架构

构建了一个离散时间步仿真器（`memory_decay_simulator.py`），以"天"为基本时间单位，支持两种运行模式：

- **网格模式**（Grid Mode）：遍历初始强度和有用增量的参数组合，输出汇总统计。
- **画像模式**（Profile Mode）：使用预定义的用户行为画像，模拟真实使用场景。

### 4.2 用户行为画像

为贴近真实场景，定义了 6 种典型记忆使用画像：

| 画像名称 | 初始强度 | 使用频率模式 | 现实对应 |
|----------|---------|-------------|---------|
| 短期背书后弃用 | 8 | 前 60 天高频（0.80），之后骤降至 0 | 考试备忘、临时项目知识 |
| 日常天天可见 | 6 | 全程稳定（0.35） | 用户姓名、常用偏好 |
| 近期高频后消失 | 7 | 前 180 天中高频（0.45），之后衰减至 0 | 短期兴趣、项目周期内的技术栈 |
| 每年温习一次 | 6 | 每 365 天触发一次 | 生日、纪念日 |
| 偶发低频记忆 | 5 | 全程低频（0.03→0.01） | 偶然提及的冷知识 |
| 一次性噪声 | 4 | 几乎不用（0.005→0） | 无意义闲聊、错误信息 |

每种画像还配置了独立的每日新增记忆参数（`new_prob`, `new_min`, `new_max`），用于模拟持续产生的新记忆。其中"一次性噪声"画像的新增概率最高（0.95）、新增数量最多（3-10 条/天），反映现实中噪声记忆占多数的特征。

### 4.3 每日仿真流程

```
对每一天 d = 1, 2, ..., 365:
  1. 确定当日调用次数 calls ~ Uniform(calls_min, calls_max)
  2. 每次调用产生 1 条新记忆（按画像权重分配类型）
  3. 分配召回槽位：total_slots = calls × recall_topk
     按画像当日权重比例分配到各画像桶
  4. 对每个槽位：
     从对应桶中随机选择 1 条存活记忆
     以 useful_prob 概率判定有用，执行对应规则
  5. 对所有存活记忆执行自然衰减（仅 T0）
  6. 删除 strength ≤ 0 的记忆
  7. 记录当日存活统计
```

### 4.4 压力等级

| 等级 | 每日调用次数 | 年累计创建 | 年累计召回事件 |
|------|------------|-----------|--------------|
| 中压 | 500 | ~182,500 | ~1,825,000 |
| 高压 | 5,000 | ~1,825,000 | ~18,250,000 |
| 极限高压 | 10,000 | ~3,650,000 | ~36,500,000 |

### 4.5 评估指标

- **驱散率**（Deletion Ratio）：年内被删除的被动记忆占总被动记忆的比例
- **存活率**（Survival Ratio）：年末仍存活的被动记忆占比
- **平均寿命**（Avg Lifetime）：所有被动记忆的平均存活天数
- **P90 寿命**：90% 分位的存活天数
- **分档存活分布**：年末各档位的存活记忆数量

---

## 5 仿真结果

### 5.1 实验一：巩固速度对比

**固定参数**：`cycle_tier0 = 3`, `forget_speed = 1.0`, `useful_prob = 0.05`, `daily_calls = 500`, `recall_topk = 10`

**变量**：`consolidate_speed` ∈ {1.0, 2.5}

| 指标 | $v_c = 1.0$ (基线) | $v_c = 2.5$ (推荐) |
|------|-------------------|-------------------|
| 累计创建 | 182,500 | 182,500 |
| 被遗忘数 | 173,544 | 172,705 |
| 驱散率 | 95.1% | 94.6% |
| 年末存活 | 8,956 | 9,795 |
| T0 存活 | 8,784 | 8,128 |
| T1 存活 | 170 | 351 |
| T2 存活 | **2** | **1,316** |

**分析**：

$v_c = 1.0$ 时升入 T2 需要 10 次有用判定（每次 +1.0），在 5% 有用概率下极难达成，导致 T2 几乎为空。$v_c = 2.5$ 时仅需 4 次有用判定即可升入 T2，T2 存活数从 2 增长到 1,316（**658 倍**），而驱散率仅下降 0.5 个百分点。

这证实了巩固速度是影响核心记忆累积效率的关键旋钮，且其对驱散率的边际影响极小——因为绝大多数记忆从未获得任何"有用"反馈，始终停留在 T0 被时间衰减清除。

### 5.2 实验二：压力等级扩展性

**固定参数**：推荐配置（$v_c = 2.5$）

| 指标 | 中压 (500/天) | 高压 (5,000/天) | 极限 (10,000/天) |
|------|--------------|----------------|-----------------|
| 累计创建 | 182,500 | 1,825,000 | 3,650,000 |
| 驱散率 | 94.6% | 94.6% | 94.6% |
| 年末存活 | 9,795 | 98,466 | 197,110 |
| T0 存活 | 8,128 | 81,612 | 163,308 |
| T1 存活 | 351 | 3,401 | 6,866 |
| T2 存活 | 1,316 | 13,453 | 26,936 |

**分析**：

关键发现——**驱散率在 10 倍负载变化下保持恒定（94.6%）**。这是因为：

1. T0 的时间衰减是负载无关的——无论每天产生多少记忆，每 3 天固定衰减 1 点强度。
2. 每条记忆被判定有用的概率（5%）和巩固速度是固定的，因此升档比例也是恒定的。
3. 存活记忆数量与创建数量严格成线性关系（比例约为 5.4%）。

这意味着系统管理员可以直接根据**预期的每日调用量**估算长期稳态存储需求，无需担心非线性增长。

### 5.3 实验三：存活数量的分档比例稳定性

从实验二的数据中提取各档位占存活总量的比例：

| 档位 | 中压 | 高压 | 极限 |
|------|------|------|------|
| T0 占比 | 83.0% | 82.9% | 82.9% |
| T1 占比 | 3.6% | 3.5% | 3.5% |
| T2 占比 | 13.4% | 13.7% | 13.7% |

**分析**：

分档比例在不同压力等级下高度一致（方差 < 0.5%），表明 TMD 算法的行为是**压力无关的稳态系统**。这一性质对生产环境至关重要：参数调优的结论可以在低压环境下得出，然后直接应用到高压场景。

### 5.4 结果汇总：算法目标达成评估

| 设计目标 | 达成情况 | 证据 |
|----------|---------|------|
| 重要记忆可持续累积 | **达成** | T2 存活数随时间和负载线性增长 |
| 低价值记忆高比例驱散 | **达成** | 驱散率稳定在 94.6% |
| 少量参数可控 | **达成** | 核心行为由 $v_c$、$\theta_0$、$\theta_1$、$C_0$ 四个参数决定 |
| 高压场景稳定 | **达成** | 10,000/天场景下行为与 500/天完全一致 |

---

## 6 参数敏感性分析

### 6.1 巩固速度 $v_c$ 的影响

$v_c$ 决定了记忆从 T0 升至 T2 所需的"有用"判定次数：

$$
n_{\text{T0→T1}} = \left\lceil \frac{\theta_0}{v_c} \right\rceil, \quad
n_{\text{T0→T2}} = \left\lceil \frac{\theta_1}{v_c} \right\rceil
$$

| $v_c$ | T0→T1 次数 | T0→T2 次数 | T2 年末存活（中压） |
|-------|-----------|-----------|-------------------|
| 0.5 | 6 | 20 | 极少（< 10） |
| 1.0 | 3 | 10 | 2 |
| 2.5 | 2 | 4 | 1,316 |
| 5.0 | 1 | 2 | 更多（未测） |

$v_c$ 过小导致核心记忆无法有效累积；$v_c$ 过大则降低了"多次验证"的筛选门槛。推荐值 2.5 在两者之间取得平衡：需要 4 次有用判定（≥ 3 次的经验证要求）方可获得永久保护。

### 6.2 衰减周期 $C_0$ 的影响

$C_0$ 控制 T0 记忆的存活窗口。以初始强度 $s_0$ 和 $C_0$ 天为周期，一条从未被判定有用的 T0 记忆的理论最大寿命为：

$$
L_{\max} = s_0 \times C_0 \text{ (天)}
$$

| $s_0$ | $C_0$ | 最大寿命 |
|-------|-------|---------|
| 4 | 3 | 12 天 |
| 6 | 3 | 18 天 |
| 8 | 3 | 24 天 |
| 6 | 7 | 42 天 |

$C_0 = 3$ 天配合 $s_0 = 4 \sim 8$ 的初始强度，提供了 12-24 天的验证窗口。这对于对话系统中"一条记忆是否有价值通常在 1-2 周内可以判明"的假设是合理的。

### 6.3 有用概率 $p_{\text{useful}}$ 的系统影响

$p_{\text{useful}}$ 是环境变量而非算法参数，但它直接影响稳态分布。定义记忆在被删除前获得 $k$ 次有用判定的概率为 $P(K \geq k)$，近似为：

$$
P(K \geq k) \approx 1 - \text{CDF}_{\text{Binomial}}(k-1; \; n_{\text{recalls}}, \; p_{\text{useful}})
$$

其中 $n_{\text{recalls}}$ 是记忆在 T0 存活期内被召回的期望次数。$p_{\text{useful}} = 0.05$ 是保守估计——实际系统中经过向量检索召回的记忆相关性通常更高。

---

## 7 与 Ebbinghaus 遗忘曲线的关系

### 7.1 经典遗忘曲线

Ebbinghaus 遗忘曲线的一般形式为：

$$
R(t) = e^{-t/S}
$$

其中 $R(t)$ 是时刻 $t$ 的记忆保留率，$S$ 是记忆稳定性。间隔重复（Spaced Repetition）通过每次成功回忆增加 $S$ 的值来延长记忆寿命。

### 7.2 TMD 与 Ebbinghaus 的对应

TMD 的离散模型可以看作 Ebbinghaus 曲线的分段线性逼近：

| Ebbinghaus 概念 | TMD 对应 |
|----------------|---------|
| 记忆保留率 $R(t)$ | $s(m) / s_0$（归一化强度） |
| 记忆稳定性 $S$ | 档位 tier($m$) + 剩余强度 |
| 自然遗忘 ($e^{-t/S}$ 衰减) | T0 的周期性 strength-1 |
| 间隔重复增强 $S$ | useful 反馈增加 useful_score，可能升档 |
| 长期记忆固化 | 升入 T2 后永不遗忘 |

关键差异在于：TMD 引入了"被召回但无用"作为额外的负向信号（T1 衰减），这在经典 Ebbinghaus 模型中没有对应——它更接近于"主动回忆失败"（Active Recall Failure）的认知心理学概念。

### 7.3 离散模型的优势

相比连续指数衰减模型，TMD 的离散整数强度模型有以下工程优势：

1. **可解释性**：strength=5 意味着"还能承受 5 个衰减周期"，比 $R = 0.37$ 直观。
2. **确定性**：相同的初始强度和使用模式总是产生相同的存活时间，便于调试。
3. **存储友好**：整数运算避免了浮点精度问题，SQL 批量更新高效。

---

## 8 工程实践考量

### 8.1 数据库迁移兼容性

系统通过 `PRAGMA table_info` 检测已有数据库是否包含新增字段，并使用 `ALTER TABLE ADD COLUMN` 进行在线迁移。已有记忆的新字段默认值为 0，意味着它们初始处于 T0 档——这是保守且安全的：已有记忆需要重新"证明自己"才能获得更高保护级别。

### 8.2 双存储后端一致性

SQL 后端（SQLite）和向量后端（ChromaDB）共享同一个 `MemoryDecayPolicy` 实例，确保档位计算和阈值判断的一致性。但更新路径不同：

- SQL 后端：批量 SQL 语句，一次 IO 完成所有更新
- 向量后端：逐条查询 metadata + 逐条 update，IO 为 O(N)

生产环境推荐优先使用 SQL 后端以获得更好的批量操作性能。

### 8.3 配置覆盖安全性

参数覆盖机制采用"默认关闭"策略（`enabled: false`），并提供以下安全措施：

- `tier1_threshold` 自动校正不小于 `tier0_threshold`
- `forget_speed` 和 `tier0_forget_speed` 强制下限 0.01
- `cycle_tier0_days` 强制下限 1

---

## 9 局限性与未来工作

### 9.1 当前局限

1. **有用概率假设**：仿真中使用固定的 $p_{\text{useful}} = 0.05$，实际系统中该概率可能随时间和上下文变化。上线后应采集真实分布并反向校准。

2. **无降档机制**：`useful_score` 只增不减，一旦升档不可逆。如果一条记忆在很久以前被判定有用但此后再未被召回，它仍然保持高档位。是否需要长期未使用的降档机制值得探讨。

3. **合并后的有用分数策略**：当前采用 `max()` 保留最高值，但 `sum()` 或加权平均可能在某些场景下更合理。

4. **导出-导入场景**：内部字段 `last_decay_at` 不参与导出，数据迁移后可能导致 T0 记忆的一次性补衰。

### 9.2 未来方向

1. **在线学习 $p_{\text{useful}}$**：记录每条记忆的召回次数和有用次数，估计不同记忆类型和标签的真实有用概率。

2. **自适应衰减周期**：根据系统当前记忆总量动态调整 $C_0$，在记忆膨胀时加速清退。

3. **可视化仪表盘**：在调试工具中增加分档分布的时间序列图、月度存活曲线等可视化。

4. **A/B 测试框架**：支持为不同用户组使用不同的衰减参数，观察对对话质量的影响。

---

## 10 结论

本文提出的三档自适应衰减算法（TMD）通过引入 `useful_score` 累积指标和差异化遗忘策略，有效解决了对话式 AI 长期记忆管理中"重要记忆保留"与"噪声记忆清退"的矛盾。通过 1 年周期的离散事件仿真验证，该算法展现出以下核心特性：

1. **高驱散率**：94.6% 的噪声记忆在年内被自动清退
2. **有效累积**：经过验证的核心记忆（T2）持续增长，年末达到存活总量的 ~13.5%
3. **线性可预测**：驱散率和分档比例在 20 倍负载变化下保持恒定
4. **参数简洁**：核心行为由 4 个参数控制，便于理解和调优

该算法已在生产系统中完成实现，支持 SQL 和向量双存储后端，并提供了从配置文件覆盖默认参数的能力。

---

## 附录 A：默认参数汇总

| 参数 | 默认值 | 含义 |
|------|-------|------|
| `tier0_threshold` ($\theta_0$) | 3.0 | T0→T1 升档阈值 |
| `tier1_threshold` ($\theta_1$) | 10.0 | T1→T2 升档阈值 |
| `consolidate_speed` ($v_c$) | 2.5 | 每次有用判定的 useful_score 增量 |
| `cycle_tier0_days` ($C_0$) | 3 | T0 自然衰减基础周期（天） |
| `forget_speed` ($v_f$) | 1.0 | 全局遗忘速度倍率 |
| `tier0_forget_speed` ($v_{f0}$) | 1.0 | T0 档位遗忘速度倍率 |
| `useful_boost` ($\delta_{\text{boost}}$) | 1 | 有用判定的 strength 增量 |

## 附录 B：仿真器用户画像参数

| 画像 | $s_0$ | $p_{\text{start}}$ | $p_{\text{mid}}$ | $p_{\text{end}}$ | 热天数 | 新增概率 | 新增范围 |
|------|-------|-------|--------|--------|--------|---------|---------|
| 短期背书后弃用 | 8 | 0.80 | 0.05 | 0.00 | 60 | 0.30 | 0-2 |
| 日常天天可见 | 6 | 0.35 | 0.35 | 0.35 | 0 | 0.80 | 1-4 |
| 近期高频后消失 | 7 | 0.45 | 0.10 | 0.00 | 180 | 0.45 | 0-3 |
| 每年温习一次 | 6 | — | — | — | — | 0.15 | 0-1 |
| 偶发低频记忆 | 5 | 0.03 | 0.02 | 0.01 | 0 | 0.70 | 1-6 |
| 一次性噪声 | 4 | 0.005 | 0.002 | 0.00 | 0 | 0.95 | 3-10 |

## 附录 C：符号表

| 符号 | 含义 |
|------|------|
| $m$ | 一条记忆实例 |
| $s(m)$ | 记忆 $m$ 的强度 |
| $u_s(m)$ | 记忆 $m$ 的有用分数 |
| $u_c(m)$ | 记忆 $m$ 的有用计数 |
| $\text{tier}(m)$ | 记忆 $m$ 的档位（0, 1, 2） |
| $\theta_0, \theta_1$ | 升档阈值 |
| $v_c$ | 巩固速度 |
| $v_f, v_{f0}$ | 遗忘速度倍率 |
| $C_0$ | T0 基础衰减周期 |
| $\delta_{\text{boost}}$ | 有用判定的强度增量 |
| $p_{\text{useful}}$ | 单条被判定有用的概率 |
