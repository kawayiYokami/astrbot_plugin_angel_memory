# 藏书库头脑风暴

## 核心理念

基于现有向量数据库构建高级信息检索系统，命名为"藏书库"，充分利用四亿文本量的游戏资料库。

## 标签权重系统

### 1. 标题标签（最高权重）
- `# 草史莱姆` → 标签：草史莱姆
- `## 攻击方式` → 标签：攻击方式
- `### 具体描述` → 标签：具体描述

### 2. 加粗文本标签（高权重）
- `**元素属性**: 草` → 标签：元素属性、草
- `**稀有度**: ★★★★` → 标签：稀有度
- 通常是关键数据字段和属性

### 3. 引号文本标签（中高权重）
- `"教父的秘宝就在黑市深处"` → 标签：教父、秘宝、黑市
- `'盗亦有道'` → 标签：盗亦有道
- `「盗亦有道」` → 标签：盗亦有道
- `『教父的秘宝』` → 标签：教父、秘宝
- 重要概念、对话、引用内容

### 4. 文件名标签（最高权重）
- `胡桃-宿雪桃红-504061.md` → 标签：胡桃、宿雪桃红、504061
- `乌髓孑灯-506375.md` → 标签：乌髓孑灯、506375
- `草史莱姆-990.md` → 标签：草史莱姆、990
- 按连字符分割提取核心标识

### 5. 普通正文（基础权重）
- 常规关键词提取
- 上下文关联词

## 目录结构标签自动生成

从文件路径自动提取标签：
- `武器/法器/乌髓孑灯-506375.md` → 标签：武器、法器
- `敌人/草/草史莱姆-990.md` → 标签：敌人、草
- `秘境/圣遗物/椛染之庭-2311.md` → 标签：秘境、圣遗物

## 文档结构分析

### 典型文档类型

#### 装扮文档（如：胡桃-宿雪桃红）
```markdown
# 胡桃「宿雪桃红」
## 简介
## 故事
```

#### 武器文档（如：乌髓孑灯）
```markdown
# 乌髓孑灯
## 基本信息
- **稀有度**: ★★★★
- **描述**: ...
## 武器故事
```

#### 敌人文档（如：草史莱姆）
```markdown
# 草史莱姆
**元素属性**: 草
## 攻击方式
- ...
## 背景故事
```

## 智能分块策略

### 基于标题结构的分块
- 按H1、H2、H3标题自然分块
- 保持每个分块的语义完整性
- 标题作为分块的主要标签

### 内容类型识别
- 游戏数据块（基本信息、属性等）
- 故事叙述块（背景故事、武器故事等）
- 列表数据块（攻击方式、技能列表等）

## 检索增强功能

### 多维度过滤
- 按文档类型（角色、武器、敌人、秘境）
- 按元素属性（草、火、水、雷、风、冰、岩）
- 按稀有度等级
- 按地区/阵营

### 上下文扩展
- 同一角色的其他装扮/武器
- 同一元素的相关角色/敌人
- 同一地区的相关内容

### 关联推荐
- 基于标签相似性推荐
- 基于内容关联性推荐
- 基于用户行为模式推荐

## 🚀 片段+标签联合向量化架构

### 核心设计理念
将片段内容和标签一起向量化，但存储时分别保存内容向量和标签向量，实现语义检索和精确匹配的完美结合。

### 存储结构设计
```python
# ChromaDB存储时，每个文档包含多个向量字段
chromadb.store({
    "id": "doc_123",
    "content": "胡桃的装扮款式...",
    "metadata": {
        "tags": ["胡桃", "宿雪桃红", "装扮"],
        "file_path": "胡桃-宿雪桃红-504061.md"
    },
    "embeddings": {
        "content_vector": [0.1, 0.2, ...],  # 内容向量
        "tag_vector": [0.3, 0.4, ...]       # 标签向量（单独存储）
    }
})
```

### 向量化策略
```python
def create_vector(fragment, tags):
    # 分别存储内容向量和标签向量
    content_vector = sentence_transformer.encode(fragment.content)
    tag_vector = sentence_transformer.encode(f"标签: {', '.join(tags)}")
    
    return {
        "content": fragment.content,
        "tags": tags,
        "content_vector": content_vector,
        "tag_vector": tag_vector
    }
```

### 检索流程优化（两步策略）
```python
def intelligent_search(query):
    # 1. 查询向量化
    query_vector = encode(query)
    
    # 2. 第一步：问题向量 vs 正文向量 → 初步候选
    candidates = chromadb.similarity_search(
        query_vector, 
        vector_field="content_vector"  # 只用正文向量
    )
    
    # 3. 第二步：问题向量 vs 标签向量 → 精确排序
    tag_results = chromadb.similarity_search(
        query_vector,
        vector_field="tag_vector"  # 只用标签向量
    )
    
    # 4. 合并两个结果集
    final_results = merge_and_rank(candidates, tag_results)
    return final_results
```

### 关键理解：向量化本身就是匹配过程
- **不需要二次计算相似度** - 向量数据库返回的就是按相似度排序的结果
- **向量化搜索就是匹配** - cosine_similarity 就是匹配度
- **两个独立的向量空间** - 正文向量和标签向量各自独立检索

### 解决的核心问题
1. **高频词污染**：任务对话中大量"胡桃"不会干扰真正的胡桃介绍
2. **指代缺失**：文档用"胡堂主"指代胡桃，但标签确保"胡桃"不丢失
3. **语义漂移**：标签向量约束语义搜索的方向
4. **精确匹配**：模糊查询+精确匹配的双重保障

### 性能优势
- **零延迟检索**：标签向量预计算，查询时无需额外模型调用
- **纯粹逻辑**：语义筛选 → 标签精排，两步独立
- **语义+精确**：既保持向量搜索的语义理解，又有标签系统的精确性

## 核心设计理念

### 标签即上下文
- 通过标签体系来体现文档块之间的关系，而不是通过内容重叠
- 标签提供完整的文档结构信息和上下文

### 避免内容重叠
- 每个正文块都是独立的，内容纯净
- 上下文信息通过标签承载，不污染正文内容
- 向量化时噪音更少，检索更准确

### 文档处理公式
**一个MD文件 = N个正文块 = N个向量记录**

每个记录包含：
- 纯正文内容
- 完整的标签集合（路径+标题+专有名词）
- 两个独立的向量（正文向量 + 标签向量）

## 文档解析架构优化

### 使用 mistune 替代正则表达式
```python
import mistune

# 创建 Markdown 解析器
md = mistune.create_markdown(renderer='ast')
ast = md.parse(markdown_text)  # 直接得到抽象语法树
```

### 构建文档树状结构
- 使用 mistune 解析 MD 文档为 AST
- 构建文档树状图，记录标题层级关系
- 追踪每个正文块所属的三级标题
- 按标题结构自然分割文档块

### 文档处理流程
```python
def process_markdown_file(file_path):
    # 1. 解析文档
    ast = mistune.parse(file_content)
    
    # 2. 构建文档树
    doc_tree = build_document_tree(ast)
    
    # 3. 切割成块
    blocks = split_into_blocks(doc_tree)
    
    # 4. 为每个块提取标签
    for block in blocks:
        block['tags'] = extract_tags(block, file_path)
    
    return blocks
```

### 标签提取优化
```python
def extract_tags(block, file_path):
    tags = []
    
    # 1. 路径标签
    path_parts = file_path.replace('\\', '/').split('/')
    for part in path_parts:
        if part:
            clean_part = part.replace('.md', '').replace('.txt', '')
            tags.append(clean_part)
    
    # 2. 标题标签（当前所属的三级标题）
    tags.extend(block['headers'])
    
    # 3. 专有名词标签（统一提取）
    proper_noun_patterns = [
        r'"([^"]+)"',      # 半角双引号
        r'"([^"]+)"',      # 全角双引号  
        r'"([^"]+)"',      # 竖版双引号
        r"'([^']+)'",      # 竖版单引号
        r'《([^》]+)》',    # 书名号
        r'〈([^〉]+)〉',    # 尖括号
    ]
    
    for pattern in proper_noun_patterns:
        matches = re.findall(pattern, block['content'])
        tags.extend(matches)
    
    return list(set(tags))  # 去重
```

## 技术实现要点

### 标签提取算法
1. **使用 mistune 解析 Markdown 标题结构** - 稳定可靠
2. **构建文档树状图** - 追踪三级标题关系
3. **统一提取专有名词** - 引号、书名号等不区分类型
4. **从文件路径生成标签** - 包含完整层级信息
5. **按标题结构自然分块** - 保持语义完整性

### 数据块结构
```python
data_block = {
    'content': '正文内容',
    'tags': [
        # 路径标签
        'docs', '藏书库的头脑风暴',
        # 标题标签  
        '核心理念', '标签权重系统',
        # 专有名词标签
        '向量数据库', '四亿文本量'
    ],
    'headers': ['藏书库头脑风暴', '核心理念'],  # 所属三级标题
    'block_id': 'block_001'
}
```

### 向量存储结构
- **双向量存储**：content_vector + tag_vector
- **两步检索**：问题向量 vs 正文向量 → 问题向量 vs 标签向量
- **标签索引**：支持按标签类型精确过滤

### 索引结构
- 主向量索引（语义检索）
- 标签向量索引（精确匹配）
- 分类索引（类型过滤）

## 用户体验优化

### 智能搜索建议
- 输入时自动补全标签
- 搜索历史记录
- 热门搜索推荐

### 结果展示优化
- 按权重排序
- 高亮匹配的标签
- 提供相关文档推荐

### 个性化服务
- 记录用户搜索偏好
- 学习用户兴趣模式
- 定制化推荐算法

---

*头脑风暴记录 - 2025年10月5日*