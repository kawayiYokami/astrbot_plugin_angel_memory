{
  "provider_id": {
    "type": "string",
    "description": "[核心模型设置] 用于记忆整理的LLM提供商ID",
    "_special": "select_provider",
    "default": "",
    "hint": "建议为拥有思考能力的模型。留空则只使用基础记忆功能。"
  },
  "retrieval": {
    "type": "object",
    "description": "[向量化检索] 检索模型与重排配置",
    "hint": "检索会按能力自动选择三档策略（BM25直出 / 向量融合 / 候选重排）。即使不使用向量化模型，也能获得非常好的体验，向量并非必须。",
    "items": {
      "embedding_provider_id": {
        "type": "string",
        "description": "用于向量化的嵌入模型提供商ID（可选）",
        "default": "",
        "hint": "并非必须；本项目已内置强关键词检索与精准生成链路，实测向量带来的额外提升通常较小。"
      },
      "rerank_provider_id": {
        "type": "string",
        "description": "用于检索重排的提供商ID（推荐）",
        "default": "",
        "hint": "推荐使用，检索效果提升明显；不依赖嵌入模型，BM25 候选也可以直接重排。留空则自动尝试复用 provider_id，若不可用则降级为非重排策略。"
      },
      "enable_local_embedding": {
        "type": "bool",
        "description": "启用本地嵌入模型支持",
        "default": false,
        "hint": "开启后将使用本地嵌入模型（BAAI/bge-small-zh-v1.5）。并非必须，实测整体提升有限。"
      }
    }
  },
  "conversation_scope_map": {
    "type": "text",
    "description": "[记忆分类] 文本键到记忆分类域的映射（人格名优先，其次会话ID）",
    "default": "{}",
    "editor_mode": true,
    "editor_language": "json",
    "editor_theme": "vs-dark",
    "hint": "JSON格式配置，键可为人格名或会话ID，值为记忆分类域。匹配顺序：先人格名（secretary_decision.persona_name），后会话ID（unified_msg_origin）。示例：{\"女友\":\"恋爱\",\"aiocqhttp:group:12345\":\"家人\"}。未命中默认 public。scope 名仅允许字母/数字/中文/下划线/短横线。"
  },
  "memory_behavior": {
    "type": "object",
    "description": "[记忆行为参数] 记忆系统的行为配置",
    "hint": "控制记忆处理的各种参数，影响记忆的生成、保存和巩固。",
    "items": {
      "default_passive_strength": {
        "type": "int",
        "description": "被动记忆的初始强度值",
        "default": 10,
        "hint": "此数值影响被动记忆在遗忘过程中的存活能力，推荐范围10-50。主动记忆不受此影响。"
      },
      "min_message_length": {
        "type": "int",
        "description": "触发记忆处理的最小消息字符数",
        "default": 5,
        "hint": "过滤过短的消息，以提高记忆质量。"
      },
      "short_term_memory_capacity": {
        "type": "int",
        "description": "短期记忆通道的容量倍数",
        "default": 1,
        "hint": "设置为2则容量翻倍，设置为3则容量变为3倍。"
      },
      "sleep_interval": {
        "type": "int",
        "description": "记忆巩固（睡眠）的执行间隔（秒）",
        "default": 3600,
        "hint": "默认1小时执行一次。设置为0则禁用定期睡眠。"
      },
      "decay_policy_override": {
        "type": "object",
        "description": "【可选高级项】遗忘/巩固参数覆盖",
        "hint": "默认参数经过复杂测试，能兼顾长期记忆积累与垃圾记忆清退。若没有相当信心，请不要修改。仅当 enabled=true 时生效。",
        "items": {
          "enabled": {
            "type": "bool",
            "description": "启用自定义遗忘策略参数",
            "default": false,
            "hint": "关闭时完全使用系统默认参数。"
          },
          "tier0_threshold": {
            "type": "float",
            "description": "T0->T1 升档阈值（useful_score）",
            "default": 3.0,
            "hint": "达到该分数后，记忆从自然遗忘档升到召回判定档。"
          },
          "tier1_threshold": {
            "type": "float",
            "description": "T1->T2 升档阈值（useful_score）",
            "default": 10.0,
            "hint": "达到该分数后进入长期保留档。建议不小于 tier0_threshold。"
          },
          "consolidate_speed": {
            "type": "float",
            "description": "每次被判定有用时 useful_score 增量",
            "default": 2.5,
            "hint": "值越大，记忆升档越快。建议范围 0.5-5.0，必须 > 0。"
          },
          "forget_speed": {
            "type": "float",
            "description": "全局遗忘速度倍率",
            "default": 1.0,
            "hint": "值越大，整体遗忘越快。建议范围 0.5-3.0。"
          },
          "tier0_forget_speed": {
            "type": "float",
            "description": "T0（自然遗忘档）遗忘速度倍率",
            "default": 1.0,
            "hint": "与 forget_speed 相乘后作用于 T0 自然衰减周期。"
          },
          "cycle_tier0_days": {
            "type": "int",
            "description": "T0 自然遗忘基础周期（天）",
            "default": 3,
            "hint": "实际周期会按 forget_speed 与 tier0_forget_speed 调整。"
          }
        }
      }
    }
  },
  "note_topk": {
    "type": "object",
    "description": "[笔记Top-K] 笔记注入数量限制",
    "hint": "top_k 控制实际注入LLM的笔记数量。候选检索数量固定为 top_k 的 7 倍。",
    "items": {
      "top_k": {
        "type": "int",
        "description": "注入LLM的笔记数量上限",
        "default": 8,
        "hint": "控制实际注入给应答模型的笔记条数。建议 3-20。"
      }
    }
  },
  "enable_soul_system": {
    "type": "object",
    "description": "[灵魂系统] 灵魂状态系统配置",
    "hint": "启用后会根据AI的精神状态动态调整行为参数（检索量、记忆量、发言长度、创造性）。关闭则使用固定参数，不会在上下文中注入灵魂仪表盘。",
    "items": {
      "enabled": {
        "type": "bool",
        "description": "启用灵魂系统",
        "default": true,
        "hint": "是否启用灵魂状态系统"
      },
      "recall_depth_mid": {
        "type": "int",
        "description": "社交倾向-回归值 (建议检索记忆数)",
        "default": 7,
        "hint": "决定内向|外向人格的基准值，影响检索记忆的数量。范围：3-20（系统自动限制）"
      },
      "impression_depth_mid": {
        "type": "int",
        "description": "对话姿态-回归值 (建议生成记忆数)",
        "default": 3,
        "hint": "决定指导|好奇人格的基准值，影响生成新记忆的数量。范围：1-10（系统自动限制）"
      },
      "expression_desire_mid": {
        "type": "float",
        "description": "健谈程度-回归值 (归一化)",
        "default": 0.5,
        "hint": "决定话少|话多人格的基准值，影响发言长度。范围：0.0-1.0（系统自动限制）"
      },
      "creativity_mid": {
        "type": "float",
        "description": "创造性-回归值 (归一化)",
        "default": 0.7,
        "hint": "决定严肃|调皮人格的基准值，影响LLM温度参数。范围：0.0-1.0（系统自动限制）"
      }
    }
  },
  "research_assistant": {
    "type": "object",
    "description": "[研究助手] 深度研究功能配置(测试，不稳定，请多反馈)",
    "hint": "配置用于执行深度研究任务的设置。该功能允许AI自主搜索、阅读和内化知识。",
    "items": {
      "persona_id": {
        "type": "string",
        "description": "研究人格名称",
        "default": "",
        "hint": "填写专用研究人格名称。系统会将人格的提示词补充到内置研究提示词中，并使用人格配置的工具集。建议提示词仅补充领域知识或特定要求，不必重复说明研究流程。"
      },
      "provider_id": {
        "type": "string",
        "description": "[核心模型设置] 用于研究助手的LLM提供商ID",
        "_special": "select_provider",
        "default": "",
        "hint": "指定用于执行研究任务的 LLM 提供商 ID。留空则使用当前会话的提供商。推荐使用 DeepSeek V3.2 或 Gemini pro 等推理能力强的模型。"
      },
      "start_messages": {
         "type": "string",
         "description": "研究任务启动时发送的可爱提示",
         "hint": "用 | 分隔多条消息，启动时会随机选择一条发送。留空则不发送。",
         "default": "请稍等，我这就去把知识都抓回来！(ง •̀_•́)ง|好嘞！研究任务启动，我开始工作啦！|收到，正在开启深度研究模式... ✨"
      }
    }
  }
}
